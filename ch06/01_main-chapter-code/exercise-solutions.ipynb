{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch06/01_main-chapter-code/exercise-solutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba450fb1-8a26-4894-ab7a-5d7bfefe90ce",
      "metadata": {
        "id": "ba450fb1-8a26-4894-ab7a-5d7bfefe90ce"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
        "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51c9672d-8d0c-470d-ac2d-1271f8ec3f14",
      "metadata": {
        "id": "51c9672d-8d0c-470d-ac2d-1271f8ec3f14"
      },
      "source": [
        "# 6장 연습문제 솔루션\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5fea8be3-30a1-4623-a6d7-b095c6c1092e",
      "metadata": {
        "id": "5fea8be3-30a1-4623-a6d7-b095c6c1092e"
      },
      "source": [
        "## 연습문제 6.1: 문맥 길이 늘리기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5860ba9f-2db3-4480-b96b-4be1c68981eb",
      "metadata": {
        "id": "5860ba9f-2db3-4480-b96b-4be1c68981eb"
      },
      "source": [
        "모델이 지원하는 최대 토큰 수로 입력을 패딩하려면 `max_length`를 1024로 설정합니다.\n",
        "\n",
        "```python\n",
        "max_length = 1024\n",
        "\n",
        "train_dataset = SpamDataset(base_path / \"train.csv\", max_length=max_length, tokenizer=tokenizer)\n",
        "val_dataset = SpamDataset(base_path / \"validation.csv\", max_length=max_length, tokenizer=tokenizer)\n",
        "test_dataset = SpamDataset(base_path / \"test.csv\", max_length=max_length, tokenizer=tokenizer)\n",
        "```\n",
        "\n",
        "또는 동일하게 다음과 같이 `max_length`를 정의할 수 있습니다.\n",
        "\n",
        "```python\n",
        "max_length = model.pos_emb.weight.shape[0]\n",
        "```\n",
        "\n",
        "또는\n",
        "\n",
        "```python\n",
        "max_length = BASE_CONFIG[\"context_length\"]\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2b0f4d5d-17fd-4265-93d8-ea08a22fdaf8",
      "metadata": {
        "id": "2b0f4d5d-17fd-4265-93d8-ea08a22fdaf8"
      },
      "source": [
        "편의상 다음과 같이 실험을 실행할 수 있습니다.\n",
        "\n",
        "```bash\n",
        "python additional_experiments.py --context_length \"model_context_length\"\n",
        "```\n",
        "\n",
        "[../02_bonus_additional-experiments](../02_bonus_additional-experiments) 폴더에 있는 코드를 사용하면 테스트 정확도가 78.33%로 (본문의 95.67%와 비교하여) 크게 떨어집니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a780455-f52a-48d1-ab82-6afd40bcad8b",
      "metadata": {
        "id": "5a780455-f52a-48d1-ab82-6afd40bcad8b"
      },
      "source": [
        "## 연습문제 6.2: 전체 모델 미세 튜닝\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56aa5208-aa29-4165-a0ec-7480754e2a18",
      "metadata": {
        "id": "56aa5208-aa29-4165-a0ec-7480754e2a18"
      },
      "source": [
        "마지막 트랜스포머 블록만 미세 조정하는 대신, 코드에서 다음 라인을 제거하여 전체 모델을 미세 튜닝할 수 있습니다.\n",
        "\n",
        "```python\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "```\n",
        "\n",
        "다음과 같이 이 실험을 실행할 수 있습니다.\n",
        "\n",
        "```bash\n",
        "python additional_experiments.py --trainable_layers all\n",
        "```\n",
        "\n",
        "[../02_bonus_additional-experiments](../02_bonus_additional-experiments) 폴더에 있는 코드를 사용하면 본문의 95.67%에 비해 1% 향상된 96.67%의 테스트 정확도를 얻을 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2269bce3-f2b5-4a76-a692-5977c75a57b6",
      "metadata": {
        "id": "2269bce3-f2b5-4a76-a692-5977c75a57b6"
      },
      "source": [
        "## 연습문제 6.3: 첫 번째 토큰 vs 마지막 토큰 미세 튜닝\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7418a629-51b6-4aa2-83b7-bc0261bc370f",
      "metadata": {
        "id": "7418a629-51b6-4aa2-83b7-bc0261bc370f"
      },
      "source": [
        "마지막 출력 토큰을 미세 튜닝하는 대신, 다음 코드를\n",
        "\n",
        "```python\n",
        "model(input_batch)[:, -1, :]\n",
        "```\n",
        "\n",
        "에서\n",
        "\n",
        "```python\n",
        "model(input_batch)[:, 0, :]\n",
        "```\n",
        "\n",
        "으로 변경하여 첫 번째 출력 토큰을 미세 튜닝할 수 있습니다.\n",
        "\n",
        "[../02_bonus_additional-experiments](../02_bonus_additional-experiments) 폴더에 있는 코드를 사용하여 다음과 같이 이 실험을 실행할 수 있습니다.\n",
        "\n",
        "```\n",
        "python additional_experiments.py --trainable_token first\n",
        "```\n",
        "\n",
        "이렇게 하면 테스트 정확도가 75.00%로 크게 떨어집니다(본문에서는 95.67%).\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}