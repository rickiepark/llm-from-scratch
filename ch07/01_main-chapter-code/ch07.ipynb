{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch07/01_main-chapter-code/ch07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12e91914-5f51-43fa-b65b-625e73b4d17b",
      "metadata": {
        "id": "12e91914-5f51-43fa-b65b-625e73b4d17b"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
        "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf",
      "metadata": {
        "id": "c2520ec3-722f-4f44-bdd1-885b13e7afbf"
      },
      "source": [
        "# 7장: 지시를 따르도록 미세 튜닝하기\u001f\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e19327b-6c02-4881-ad02-9b6d3ec0b1b4",
        "outputId": "048014a6-4ecf-4606-b311-dec687e34ec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numpy 버전: 2.0.2\n",
            "matplotlib 버전: 3.10.0\n",
            "tiktoken 버전: 0.12.0\n",
            "torch 버전: 2.8.0+cu126\n",
            "tqdm 버전: 4.67.1\n",
            "tensorflow 버전: 2.19.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\n",
        "    \"numpy\",       # 파이토치와 텐서플로 의존성\n",
        "    \"matplotlib\",  # 그래프 라이브러리\n",
        "    \"tiktoken\",    # 토크나이저\n",
        "    \"torch\",       # 딥러닝 라이브러리\n",
        "    \"tqdm\",        # 진행 표시줄\n",
        "    \"tensorflow\",  # OpenAI에서 사전 훈련된 가중치를 로드하기 위해\n",
        "]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} 버전: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264fca98-2f9a-4193-b435-2abfa3b4142f",
      "metadata": {
        "id": "264fca98-2f9a-4193-b435-2abfa3b4142f"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/01.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813",
      "metadata": {
        "id": "8bbc68e9-75b3-41f1-ac2c-e071c3cd0813"
      },
      "source": [
        "## 7.1 지시 미세 튜닝 소개\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab",
      "metadata": {
        "id": "53dba24a-6805-496c-9a7f-c75e2d3527ab"
      },
      "source": [
        "- 5장에서, 우리는 LLM 사전 훈련이 한 번에 한 단어씩 생성하는 것을 배우는 것임을 보았습니다.\n",
        "- 따라서 사전 훈련된 LLM은 텍스트 완성에는 능숙하지만 지시 사항을 따르는 데는 능숙하지 않습니다.\n",
        "- 이 장에서는 LLM이 지시 사항을 더 잘 따르도록 가르칩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18dc0535-0904-44ed-beaf-9b678292ef35",
      "metadata": {
        "id": "18dc0535-0904-44ed-beaf-9b678292ef35"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/02.webp\" width=600px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8",
      "metadata": {
        "id": "b4698b23-12e0-4bd7-a140-ccb3dd71d4e8"
      },
      "source": [
        "- 이 장에서 다루는 주제는 아래 그림에 요약되어 있습니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/03.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86",
      "metadata": {
        "id": "5384f0cf-ef3c-4436-a5fa-59bd25649f86"
      },
      "source": [
        "## 7.2 지도 학습 미세 튜닝을 위한 데이터셋 준비하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8b34ff8-619f-4e89-bd03-ce513269760d",
      "metadata": {
        "id": "f8b34ff8-619f-4e89-bd03-ce513269760d"
      },
      "source": [
        "- 이 장을 위해 준비한 지시 데이터셋을 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0G3axLw6kY1N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0G3axLw6kY1N",
        "outputId": "fedf7cef-4fdb-4e5c-f907-4597cfd0f68d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플 개수: 1100\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import os\n",
        "import requests\n",
        "\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "    if not os.path.exists(file_path):\n",
        "        response = requests.get(url, timeout=30)\n",
        "        response.raise_for_status()\n",
        "        text_data = response.text\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\n",
        "# 책에서는 다음 코드를 사용했지만 VPN을 사용하는 경우 urllib가 문제를 일으킬 수 있습니다.\n",
        "# 따라서 더 안정적인 `requests` 패키지를 사용합니다.\n",
        "\n",
        "\"\"\"\n",
        "import urllib\n",
        "\n",
        "def download_and_load_file(file_path, url):\n",
        "\n",
        "    if not os.path.exists(file_path):\n",
        "        with urllib.request.urlopen(url) as response:\n",
        "            text_data = response.read().decode(\"utf-8\")\n",
        "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
        "            file.write(text_data)\n",
        "\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    return data\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "file_path = \"instruction-data.json\"\n",
        "url = (\n",
        "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
        "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
        ")\n",
        "\n",
        "data = download_and_load_file(file_path, url)\n",
        "print(\"샘플 개수:\", len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7af8176-4255-4e92-8c7d-998771733eb8",
      "metadata": {
        "id": "d7af8176-4255-4e92-8c7d-998771733eb8"
      },
      "source": [
        "- 위 JSON 파일에서 로드한 `data` 리스트의 각 항목은 다음 형식의 딕셔너리입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "-LiuBMsHkzQV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LiuBMsHkzQV",
        "outputId": "bf6e7807-72db-46ef-aeb8-2e0db5e7494a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "샘플 예시:\n",
            " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"샘플 예시:\\n\", data[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46",
      "metadata": {
        "id": "c5a32b34-485a-4816-a77a-da14f9fe6e46"
      },
      "source": [
        "- `'input'` 필드는 비어 있을 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "uFInFxDDk2Je",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFInFxDDk2Je",
        "outputId": "d44e4d81-6586-448e-b297-2361ed0f7e77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "다른 샘플:\n",
            " {'instruction': \"What is an antonym of 'complicated'?\", 'input': '', 'output': \"An antonym of 'complicated' is 'simple'.\"}\n"
          ]
        }
      ],
      "source": [
        "print(\"다른 샘플:\\n\", data[999])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f034799a-6575-45fd-98c9-9d1012d0fd58",
      "metadata": {
        "id": "f034799a-6575-45fd-98c9-9d1012d0fd58"
      },
      "source": [
        "- 지시 미세 튜닝은 입력-출력 쌍이 명시적으로 제공되는 데이터셋에서 모델을 학습시키기 때문에 종종 \"지도 학습 지시 미세 튜닝\"이라고 합니다.\n",
        "- LLM에 입력으로 항목을 포맷하는 다양한 방법이 있습니다. 아래 그림은 각각 알파카(https://crfm.stanford.edu/2023/03/13/alpaca.html) 및 Phi-3(https://arxiv.org/abs/2404.14219) LLM 훈련에 사용된 두 가지 예시 형식을 보여줍니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10",
      "metadata": {
        "id": "dffa4f70-44d4-4be4-89a9-2159f4885b10"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/04.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6",
      "metadata": {
        "id": "dd79a74e-befb-491c-be49-f777a6a5b6a6"
      },
      "source": [
        "- 이 장에서는 지시 미세 튜닝을 위한 초기 프롬프트 템플릿인 알파카 스타일 프롬프트 형식을 사용합니다.\n",
        "- 아래에서는 LLM에 입력으로 전달할 입력을 포맷팅합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "Jhk37nnJnkBh",
      "metadata": {
        "id": "Jhk37nnJnkBh"
      },
      "outputs": [],
      "source": [
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6",
      "metadata": {
        "id": "011e78b4-e89a-4653-a2ee-7b2739ca04d6"
      },
      "source": [
        "- 입력 필드가 있는 경우의 출력은 아래와 같습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "F9UQRfjzo4Js",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9UQRfjzo4Js",
        "outputId": "a769d01b-5dcf-4fd9-da9b-03bdf86e88c3",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Identify the correct spelling of the following word.\n",
            "\n",
            "### Input:\n",
            "Ocassion\n",
            "\n",
            "### Response:\n",
            "The correct spelling is 'Occasion.'\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[50])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[50]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4dc93ddf-431c-49c0-96f2-fb3a79c4d94c",
      "metadata": {
        "id": "4dc93ddf-431c-49c0-96f2-fb3a79c4d94c"
      },
      "source": [
        "- 입력 필드가 없는 경우는 다음과 같습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "a3891fa9-f738-41cd-946c-80ef9a99c346",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3891fa9-f738-41cd-946c-80ef9a99c346",
        "outputId": "045fbac5-3651-4479-e9bb-82b7d7fed6fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What is an antonym of 'complicated'?\n",
            "\n",
            "### Response:\n",
            "An antonym of 'complicated' is 'simple'.\n"
          ]
        }
      ],
      "source": [
        "model_input = format_input(data[999])\n",
        "desired_response = f\"\\n\\n### Response:\\n{data[999]['output']}\"\n",
        "\n",
        "print(model_input + desired_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4aa8afd5-2a21-49a5-90c3-6a03865a4771",
      "metadata": {
        "id": "4aa8afd5-2a21-49a5-90c3-6a03865a4771"
      },
      "source": [
        "- 마지막으로 다음 절에서 파이토치 데이터 로더를 준비하기 전에 데이터 세트를 훈련, 검증 및 테스트 세트로 나눕니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "aFZVopbIlNfx",
      "metadata": {
        "id": "aFZVopbIlNfx"
      },
      "outputs": [],
      "source": [
        "train_portion = int(len(data) * 0.85)  # 훈련을 위한 85%\n",
        "test_portion = int(len(data) * 0.1)    # 테스트를 위한 10%\n",
        "val_portion = len(data) - train_portion - test_portion  # 나머지 5%는 검증용\n",
        "\n",
        "train_data = data[:train_portion]\n",
        "test_data = data[train_portion:train_portion + test_portion]\n",
        "val_data = data[train_portion + test_portion:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "-zf6oht6bIUQ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zf6oht6bIUQ",
        "outputId": "ba57113e-2448-42f1-b2ac-735e7f564603"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 길이: 935\n",
            "검증 세트 길이: 55\n",
            "테스트 세트 길이: 110\n"
          ]
        }
      ],
      "source": [
        "print(\"훈련 세트 길이:\", len(train_data))\n",
        "print(\"검증 세트 길이:\", len(val_data))\n",
        "print(\"테스트 세트 길이:\", len(test_data))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcaaf606-f913-4445-8301-632ae10d387d",
      "metadata": {
        "id": "fcaaf606-f913-4445-8301-632ae10d387d"
      },
      "source": [
        "## 7.3 훈련 배치 만들기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "233f63bd-9755-4d07-8884-5e2e5345cf27",
      "metadata": {
        "id": "233f63bd-9755-4d07-8884-5e2e5345cf27"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/05.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c",
      "metadata": {
        "id": "c149fc1a-7757-4ec8-80cb-e2a3fb007a2c"
      },
      "source": [
        "- 다음 그림에 요약된 것처럼 여러 단계로 이 데이터셋 배치를 처리합니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/06.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9af423f-aad9-4b3c-bea5-153021c04862",
      "metadata": {
        "id": "b9af423f-aad9-4b3c-bea5-153021c04862"
      },
      "source": [
        "- 먼저, 6장의 `SpamDataset`과 유사하게 데이터셋의 모든 입력을 토큰화하는 `InstructionDataset` 클래스를 구현합니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/07.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb",
      "metadata": {
        "id": "adc29dc4-f1c7-4c71-937b-95119d6239bb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class InstructionDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer):\n",
        "        self.data = data\n",
        "\n",
        "        # 텍스트 토큰화\n",
        "        self.encoded_texts = []\n",
        "        for entry in data:\n",
        "            instruction_plus_input = format_input(entry)\n",
        "            response_text = f\"\\n\\n### Response:\\n{entry['output']}\"\n",
        "            full_text = instruction_plus_input + response_text\n",
        "            self.encoded_texts.append(\n",
        "                tokenizer.encode(full_text)\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.encoded_texts[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "384f0e69-4b22-41c0-a25d-f077527eddd1",
      "metadata": {
        "id": "384f0e69-4b22-41c0-a25d-f077527eddd1"
      },
      "source": [
        "- 6장과 유사하게, 훈련 속도를 높이기 위해 배치 단위로 여러 훈련 샘플을 묶습니다. 이를 위해서는 모든 입력을 비슷한 길이로 패딩해야 합니다.\n",
        "- 또한 이전 장과 마찬가지로 `<|endoftext|>` 토큰을 패딩 토큰으로 사용합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "ff24fe1a-5746-461c-ad3d-b6d84a1a7c96",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff24fe1a-5746-461c-ad3d-b6d84a1a7c96",
        "outputId": "50362e4e-b195-4c0c-e529-e2d5ca93cfa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427",
      "metadata": {
        "id": "9e5bd7bc-f347-4cf8-a0c2-94cb8799e427"
      },
      "source": [
        "- 6장에서는 데이터셋의 모든 샘플을 같은 길이로 패딩했습니다.\n",
        "  - 여기서는 더 정교한 접근 방식을 취하고 데이터 로더에 전달할 수 있는 사용자 지정 콜레이트 함수를 개발합니다.\n",
        "  - 이 사용자 지정 콜레이트 함수는 각 배치의 훈련 샘플을 동일한 길이로 패딩합니다(단, 배치마다 길이가 다를 수 있음).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3",
      "metadata": {
        "id": "65c4d943-4aa8-4a44-874e-05bc6831fbd3"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/08.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca",
      "metadata": {
        "id": "eb4c77dd-c956-4a1b-897b-b466909f18ca"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_1(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # 배치에서 가장 긴 시퀀스 찾기\n",
        "    # 그리고 최대 길이를 +1씩 증가시켜 아래에서 패딩 토큰을 하나 추가합니다.\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # 입력 패딩 및 준비\n",
        "    inputs_lst = []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # <|endoftext|> 토큰 추가\n",
        "        new_item += [pad_token_id]\n",
        "        # batch_max_length까지 시퀀스 패딩\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        # padded[:-1]를 통해 batch_max_length의 +1 설정을 통해 추가된\n",
        "        # 추가 패딩 토큰을 제거합니다.\n",
        "        # (추가 패딩 토큰은 이후 코드에서 관련이 있습니다)\n",
        "        inputs = torch.tensor(padded[:-1])\n",
        "        inputs_lst.append(inputs)\n",
        "\n",
        "    # 입력 리스트를 텐서로 변환하고 타깃 장치로 전송\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    return inputs_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fb02373-59b3-4f3a-b1d1-8181a2432645",
        "outputId": "b67c5fe4-671d-44a6-cdeb-0dbe2e037650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs_1 = [0, 1, 2, 3, 4]\n",
        "inputs_2 = [5, 6]\n",
        "inputs_3 = [7, 8, 9]\n",
        "\n",
        "batch = (\n",
        "    inputs_1,\n",
        "    inputs_2,\n",
        "    inputs_3\n",
        ")\n",
        "\n",
        "print(custom_collate_draft_1(batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b",
      "metadata": {
        "id": "c46832ab-39b7-45f8-b330-ac9adfa10d1b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/09.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17769a19-b961-4213-92ef-34f441b2d1d6",
      "metadata": {
        "id": "17769a19-b961-4213-92ef-34f441b2d1d6"
      },
      "source": [
        "- 위에서는 LLM에 대한 입력만 반환했습니다. 그러나 LLM 훈련을 위해서는 타깃 값도 필요합니다.\n",
        "- LLM 사전 훈련과 유사하게, 타깃은 입력을 오른쪽으로 1 위치씩 이동한 것이므로 LLM은 다음 토큰을 예측하는 방법을 학습할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef",
      "metadata": {
        "id": "0386b6fe-3455-4e70-becd-a5a4681ba2ef"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/10.webp\" width=600px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc",
      "metadata": {
        "id": "74af192e-757c-4c0a-bdf9-b7eb25bf6ebc"
      },
      "outputs": [],
      "source": [
        "def custom_collate_draft_2(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # 배치에서 가장 긴 시퀀스 찾기\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # 입력 및 타깃 준비\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # <|endoftext|> 토큰 추가\n",
        "        new_item += [pad_token_id]\n",
        "        # 시퀀스를 max_length까지 패딩\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # 입력을 위해 마지막 토큰 자르기\n",
        "        targets = torch.tensor(padded[1:])  # 타깃을 위해 오른쪽으로 +1 이동\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # 입력 리스트를 텐서로 변환하고 타깃 장치로 전송\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eb2bce3-28a7-4f39-9d4b-5e972d69066c",
        "outputId": "10c26824-4566-43e4-87fb-e8eec952b359"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256, 50256, 50256, 50256],\n",
            "        [    8,     9, 50256, 50256, 50256]])\n"
          ]
        }
      ],
      "source": [
        "inputs, targets = custom_collate_draft_2(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15",
      "metadata": {
        "id": "3bf85703-a0e0-42aa-8f29-cbc28dbf4e15"
      },
      "source": [
        "- 다음으로, 모든 패딩 토큰 ID를 `ignore_index`에 지정한 값으로 바꿉니다. 이 `ignore_index`의 목적은 손실 함수에서 패딩 값을 무시할 수 있도록 하는 것입니다(자세한 내용은 나중에 설명).\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/11.webp\" width=700px>\n",
        "\n",
        "- 구체적으로, 아래 그림과 같이 `50256`에 해당하는 토큰 ID를 `-100`으로 바꿉니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd4bed33-956e-4b3f-a09c-586d8203109a",
      "metadata": {
        "id": "bd4bed33-956e-4b3f-a09c-586d8203109a"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/12.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5346513e-c3f4-44fe-af22-4ebd36497728",
      "metadata": {
        "id": "5346513e-c3f4-44fe-af22-4ebd36497728"
      },
      "source": [
        "- (또한, 샘플의 길이를 제한하고 싶은 경우를 위해 `allowed_max_length`를 사용했습니다. GPT-2 모델에서 지원하는 1024 토큰 문맥 크기보다 긴 데이터셋으로 작업하려는 경우 유용합니다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2",
      "metadata": {
        "id": "41ec6e2d-9eb2-4124-913e-d2af39be4cf2"
      },
      "outputs": [],
      "source": [
        "def custom_collate_fn(\n",
        "    batch,\n",
        "    pad_token_id=50256,\n",
        "    ignore_index=-100,\n",
        "    allowed_max_length=None,\n",
        "    device=\"cpu\"\n",
        "):\n",
        "    # 배치에서 가장 긴 시퀀스 찾기\n",
        "    batch_max_length = max(len(item)+1 for item in batch)\n",
        "\n",
        "    # 입력과 타깃 패딩 및 준비\n",
        "    inputs_lst, targets_lst = [], []\n",
        "\n",
        "    for item in batch:\n",
        "        new_item = item.copy()\n",
        "        # <|endoftext|> 토큰 추가\n",
        "        new_item += [pad_token_id]\n",
        "        # 시퀀스를 max_length까지 패딩\n",
        "        padded = (\n",
        "            new_item + [pad_token_id] *\n",
        "            (batch_max_length - len(new_item))\n",
        "        )\n",
        "        inputs = torch.tensor(padded[:-1])  # 입력을 위해 마지막 토큰 자르기\n",
        "        targets = torch.tensor(padded[1:])  # 목표를 위해 오른쪽으로 +1 이동\n",
        "\n",
        "        # 새로 추가: 목표에서 첫 번째 패딩 토큰을 제외한 모든 토큰을 ignore_index로 바꾸기\n",
        "        mask = targets == pad_token_id\n",
        "        indices = torch.nonzero(mask).squeeze()\n",
        "        if indices.numel() > 1:\n",
        "            targets[indices[1:]] = ignore_index\n",
        "\n",
        "        # 새로 추가: 최대 시퀀스 길이로 자르기 (선택 사항)\n",
        "        if allowed_max_length is not None:\n",
        "            inputs = inputs[:allowed_max_length]\n",
        "            targets = targets[:allowed_max_length]\n",
        "\n",
        "        inputs_lst.append(inputs)\n",
        "        targets_lst.append(targets)\n",
        "\n",
        "    # 입력 및 타깃 리스트를 텐서로 변환하고 타깃 장치로 전송\n",
        "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
        "    targets_tensor = torch.stack(targets_lst).to(device)\n",
        "\n",
        "    return inputs_tensor, targets_tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdf5eec4-9ebe-4be0-9fca-9a47bee88fdc",
        "outputId": "00a47541-857e-4823-fadf-be502e5fea88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[    0,     1,     2,     3,     4],\n",
            "        [    5,     6, 50256, 50256, 50256],\n",
            "        [    7,     8,     9, 50256, 50256]])\n",
            "tensor([[    1,     2,     3,     4, 50256],\n",
            "        [    6, 50256,  -100,  -100,  -100],\n",
            "        [    8,     9, 50256,  -100,  -100]])\n"
          ]
        }
      ],
      "source": [
        "inputs, targets = custom_collate_fn(batch)\n",
        "print(inputs)\n",
        "print(targets)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7",
      "metadata": {
        "id": "26727c90-0d42-43b3-af21-0a66ad4fbbc7"
      },
      "source": [
        "- -100으로 대체하면 어떻게 되는지 살펴보겠습니다.\n",
        "- 설명을 위해 6장과 유사하게 클래스 레이블이 0과 1인 2개의 작은 분류 작업이 있다고 가정해 보겠습니다.\n",
        "- 다음과 같은 로짓 값(모델 마지막 층의 출력)이 있는 경우 다음과 같은 손실을 계산합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "W2jvh-OP9MFV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2jvh-OP9MFV",
        "outputId": "70454b1e-e543-4137-b78d-e3db8099bc68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n"
          ]
        }
      ],
      "source": [
        "logits_1 = torch.tensor(\n",
        "    [[-1.0, 1.0],  # 첫 번째 훈련 샘플\n",
        "     [-0.5, 1.5]]  # 두 번째 훈련 샘플\n",
        ")\n",
        "targets_1 = torch.tensor([0, 1])\n",
        "\n",
        "\n",
        "loss_1 = torch.nn.functional.cross_entropy(logits_1, targets_1)\n",
        "print(loss_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5edd3244-8886-4505-92e9-367d28529e1e",
      "metadata": {
        "id": "5edd3244-8886-4505-92e9-367d28529e1e"
      },
      "source": [
        "- 이제, 예상대로 하나의 훈련 샘플을 더 추가하면 손실에 영향을 미칩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "nvVMuil89v9N",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nvVMuil89v9N",
        "outputId": "2b0be7ca-f33b-407d-ec83-2144a9de76d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(0.7936)\n"
          ]
        }
      ],
      "source": [
        "logits_2 = torch.tensor(\n",
        "    [[-1.0, 1.0],\n",
        "     [-0.5, 1.5],\n",
        "     [-0.5, 1.5]]  # 새로운 세 번째 훈련 샘플\n",
        ")\n",
        "targets_2 = torch.tensor([0, 1, 1])\n",
        "\n",
        "loss_2 = torch.nn.functional.cross_entropy(logits_2, targets_2)\n",
        "print(loss_2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "54dca331-40e0-468b-b690-189fe156ba8f",
      "metadata": {
        "id": "54dca331-40e0-468b-b690-189fe156ba8f"
      },
      "source": [
        "- 한 샘플의 클래스 레이블을 -100으로 바꾸면 어떻게 되는지 봅시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "RTyB1vah9p56",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTyB1vah9p56",
        "outputId": "04ef8e6e-031f-4dc8-f640-438dd9a5447c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1269)\n",
            "loss_1 == loss_3: tensor(True)\n"
          ]
        }
      ],
      "source": [
        "targets_3 = torch.tensor([0, 1, -100])\n",
        "\n",
        "loss_3 = torch.nn.functional.cross_entropy(logits_2, targets_3)\n",
        "print(loss_3)\n",
        "print(\"loss_1 == loss_3:\", loss_1 == loss_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cef09d21-b652-4760-abea-4f76920e6a25",
      "metadata": {
        "id": "cef09d21-b652-4760-abea-4f76920e6a25"
      },
      "source": [
        "- 여기서 볼 수 있듯이, 3개의 훈련 샘플에 대한 손실은 2개의 훈련 샘플에서 계산한 손실과 동일합니다. 이는 크로스 엔트로피 손실 함수가 -100 레이블이 있는 훈련 샘플을 무시했음을 의미합니다.\n",
        "- 기본적으로 파이토치는 레이블 -100에 해당하는 샘플을 무시하도록 `cross_entropy(..., ignore_index=-100)` 설정을 사용합니다.\n",
        "- -100인 `ignore_index`를 사용하여 훈련 샘플을 동일한 길이로 채우는 데 사용했던 배치의 추가적인 텍스트 끝(패딩) 토큰을 무시할 수 있습니다.\n",
        "- 그러나 텍스트 끝(패딩) 토큰(50256)의 첫 번째는 LLM에 응답이 완료되었음을 알리는 데 도움이 될 수 있으므로 무시하고 싶지 않습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524",
      "metadata": {
        "id": "6a4e9c5f-7c49-4321-9f1b-a50468a84524"
      },
      "source": [
        "- 실제로 아래 그림과 같이 지시 사항에 해당하는 대상 토큰 ID를 마스킹하는 것이 일반적입니다(이 장을 끝낸 독자를 위해 연습문제 남겨 놓겠습니다).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39",
      "metadata": {
        "id": "fab8f0ed-80e8-4fd9-bf84-e5d0e0bc0a39"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/13.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96",
      "metadata": {
        "id": "bccaf048-ec95-498c-9155-d5b3ccba6c96"
      },
      "source": [
        "## 7.4 지시 데이터셋을 위한 데이터 로더 만들기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50",
      "metadata": {
        "id": "e6b8e656-3af3-4db6-8dde-d8c216a12f50"
      },
      "source": [
        "- 이 절에서는 `InstructionDataset` 클래스와 `custom_collate_fn` 함수를 사용하여 훈련, 검증 및 테스트 데이터 로더를 만듭니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fffe390-b226-4d5c-983f-9f4da773cb82",
      "metadata": {
        "id": "9fffe390-b226-4d5c-983f-9f4da773cb82"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/14.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "932677e9-9317-42e8-b461-7b0269518f97",
      "metadata": {
        "id": "932677e9-9317-42e8-b461-7b0269518f97"
      },
      "source": [
        "- 이전 `custom_collate_fn` 함수의 또 다른 추가 세부 사항은 메인 학습 루프에서 데이터를 처리하지 않고 타깃 장치(예: GPU)로 직접 이동한다는 것입니다. `custom_collate_fn`을 데이터 로더의 일부로 사용할 때 백그라운드 프로세스로 수행할 수 있으므로 효율성이 향상됩니다.\n",
        "- 파이썬의 표준 라이브러리 `functools`의 `partial` 함수를 사용하여 원본 함수에서 `device` 매개변수가 미리 채워진 새 함수를 만듭니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "etpqqWh8phKc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etpqqWh8phKc",
        "outputId": "b766bbcb-5b8a-4035-8bcd-6fa0ceb0979a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "장치: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 참고:\n",
        "# 다음 줄의 주석을 제거하면 코드가 애플 실리콘 칩에서 실행될 수 있습니다.\n",
        "# 애플 CPU보다 훨씬 빠릅니다(M3 맥북 에어에서 측정한 결과).\n",
        "# 하지만 결과 손실 값이 약간 다를 수 있습니다.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "\n",
        "print(\"장치:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c",
      "metadata": {
        "id": "4e47fb30-c2c6-4e6d-a64c-76cc65be4a2c"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "customized_collate_fn = partial(\n",
        "    custom_collate_fn,\n",
        "    device=device,\n",
        "    allowed_max_length=1024\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a",
      "metadata": {
        "id": "8ff42c29-8b81-45e5-ae8d-b97cd1cf447a"
      },
      "source": [
        "- 다음으로, 이전 장과 유사하게 데이터 로더의 인스턴스를 만들지만 이제는 배치 처리를 위해 자체 콜레이트 함수를 전달합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "BtWkgir6Hlpe",
      "metadata": {
        "id": "BtWkgir6Hlpe"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_dataset = InstructionDataset(train_data, tokenizer)\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=True,\n",
        "    drop_last=True,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1d097dc8-ad34-4f05-b435-e4147965f532",
      "metadata": {
        "id": "1d097dc8-ad34-4f05-b435-e4147965f532"
      },
      "outputs": [],
      "source": [
        "val_dataset = InstructionDataset(val_data, tokenizer)\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "test_dataset = InstructionDataset(test_data, tokenizer)\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    collate_fn=customized_collate_fn,\n",
        "    shuffle=False,\n",
        "    drop_last=False,\n",
        "    num_workers=num_workers\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0",
      "metadata": {
        "id": "3f67c147-b1a2-4a95-9807-e2d0de0324c0"
      },
      "source": [
        "- 만들어진 입력 및 타깃 배치의 차원이 어떻게 되는지 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "GGs1AI3vHpnX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGs1AI3vHpnX",
        "outputId": "e7b94118-b6e5-47a8-b9cd-f870f7578ffc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터 로더:\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 73]) torch.Size([8, 73])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 79]) torch.Size([8, 79])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 89]) torch.Size([8, 89])\n",
            "torch.Size([8, 59]) torch.Size([8, 59])\n",
            "torch.Size([8, 88]) torch.Size([8, 88])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 76]) torch.Size([8, 76])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 58]) torch.Size([8, 58])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 87]) torch.Size([8, 87])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 71]) torch.Size([8, 71])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 65]) torch.Size([8, 65])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 60]) torch.Size([8, 60])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 57]) torch.Size([8, 57])\n",
            "torch.Size([8, 72]) torch.Size([8, 72])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 62]) torch.Size([8, 62])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 70]) torch.Size([8, 70])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 80]) torch.Size([8, 80])\n",
            "torch.Size([8, 81]) torch.Size([8, 81])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 82]) torch.Size([8, 82])\n",
            "torch.Size([8, 63]) torch.Size([8, 63])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 68]) torch.Size([8, 68])\n",
            "torch.Size([8, 67]) torch.Size([8, 67])\n",
            "torch.Size([8, 77]) torch.Size([8, 77])\n",
            "torch.Size([8, 91]) torch.Size([8, 91])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 61]) torch.Size([8, 61])\n",
            "torch.Size([8, 75]) torch.Size([8, 75])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 78]) torch.Size([8, 78])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 64]) torch.Size([8, 64])\n",
            "torch.Size([8, 83]) torch.Size([8, 83])\n",
            "torch.Size([8, 66]) torch.Size([8, 66])\n",
            "torch.Size([8, 74]) torch.Size([8, 74])\n",
            "torch.Size([8, 69]) torch.Size([8, 69])\n"
          ]
        }
      ],
      "source": [
        "print(\"훈련 데이터 로더:\")\n",
        "for inputs, targets in train_loader:\n",
        "    print(inputs.shape, targets.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657",
      "metadata": {
        "id": "0c8e8dd7-d46a-4cc3-8a7e-c1d31e1b4657"
      },
      "source": [
        "- 위 출력 결과에서 볼 수 있듯이, 모든 배치의 크기는 8이지만 예상대로 길이는 다릅니다.\n",
        "- `inputs` 배치의 첫 번째 훈련 샘플을 출력하여 입력에 토큰 ID 50256에 해당하는 `<|endoftext|>` 패딩 토큰이 포함되어 있는지 다시 한번 확인해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21b8fd02-014f-4481-9b71-5bfee8f9dfcd",
        "outputId": "ae6e4253-4024-46d2-8773-baa4160d68da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
            "          257,  2882,   326, 20431, 32543,   262,  2581,    13,   198,   198,\n",
            "        21017, 46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,\n",
            "          985,   576,    13,   198,   198, 21017, 23412,    25,   198,   464,\n",
            "         5156,   318,   845, 13779,    13,   198,   198, 21017, 18261,    25,\n",
            "          198,   464,  5156,   318,   355, 13779,   355,   257,  4936,    13,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(inputs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360",
      "metadata": {
        "id": "5f1f3647-8971-4006-89e0-6a2a1ec1d360"
      },
      "source": [
        "- 마찬가지로, 타깃에 플레이스홀더인 -100 토큰이 포함되어 있는지 다시 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51649ab4-1a7e-4a9e-92c5-950a24fde211",
        "outputId": "bfbf9eda-e07f-463d-f5ba-59de7b888620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
            "         2882,   326, 20431, 32543,   262,  2581,    13,   198,   198, 21017,\n",
            "        46486,    25,   198, 30003,  6525,   262,  6827,  1262,   257,   985,\n",
            "          576,    13,   198,   198, 21017, 23412,    25,   198,   464,  5156,\n",
            "          318,   845, 13779,    13,   198,   198, 21017, 18261,    25,   198,\n",
            "          464,  5156,   318,   355, 13779,   355,   257,  4936,    13, 50256,\n",
            "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100],\n",
            "       device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(targets[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6aad445-8f19-4238-b9bf-db80767fb91a",
      "metadata": {
        "id": "d6aad445-8f19-4238-b9bf-db80767fb91a"
      },
      "source": [
        "## 7.5 사전 훈련된 LLM 로드하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b",
      "metadata": {
        "id": "5a5c07d1-4fc9-4846-94cf-b11a085a667b"
      },
      "source": [
        "- 이 절에서는 5장 5.5절과 6장 6.4절에서 사용했던 것과 동일한 코드를 사용하여 사전 훈련된 GPT 모델을 로드합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4",
      "metadata": {
        "id": "8d1b438f-88af-413f-96a9-f059c6c55fc4"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/15.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2",
      "metadata": {
        "id": "8c68eda7-e02e-4caa-846b-ca6dbd396ca2"
      },
      "source": [
        "- 하지만 1억 2,400만 개의 파라미터를 가진 가장 작은 모델을 로드하는 대신, 3억 5,500만 개의 파라미터를 가진 중간 버전을 로드합니다. 1억 2,400만 개의 파라미터 모델은 지시 미세 튜닝을 통해 합리적인 품질을 얻기에는 너무 작기 때문입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "M7ENdy6_aX--",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7ENdy6_aX--",
        "outputId": "f64200d8-6c12-4492-f910-e87550856e59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-10 06:28:18--  https://bit.ly/3FQ2wXM\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch07/01_main-chapter-code/gpt_download.py [following]\n",
            "--2025-11-10 06:28:18--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch07/01_main-chapter-code/gpt_download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4687 (4.6K) [text/plain]\n",
            "Saving to: ‘gpt_download.py’\n",
            "\n",
            "gpt_download.py     100%[===================>]   4.58K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-10 06:28:18 (50.0 MB/s) - ‘gpt_download.py’ saved [4687/4687]\n",
            "\n",
            "--2025-11-10 06:28:18--  https://bit.ly/4egJDdd\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.10, 67.199.248.11\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch07/01_main-chapter-code/previous_chapters.py [following]\n",
            "--2025-11-10 06:28:18--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch07/01_main-chapter-code/previous_chapters.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18236 (18K) [text/plain]\n",
            "Saving to: ‘previous_chapters.py’\n",
            "\n",
            "previous_chapters.p 100%[===================>]  17.81K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-11-10 06:28:19 (48.2 MB/s) - ‘previous_chapters.py’ saved [18236/18236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 코랩의 경우 gpt_download.py와 previous_chapter.py 파일을 다운로드합니다.\n",
        "!wget https://bit.ly/3FQ2wXM -O gpt_download.py\n",
        "!wget https://bit.ly/4egJDdd -O previous_chapters.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "0d249d67-5eba-414e-9bd2-972ebf01329d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0d249d67-5eba-414e-9bd2-972ebf01329d",
        "outputId": "a135affb-eb2d-4f66-9e00-94064e79430e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 252kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 713kiB/s]\n",
            "hparams.json: 100%|██████████| 91.0/91.0 [00:00<00:00, 207kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 1.42G/1.42G [12:45<00:00, 1.85MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 10.4k/10.4k [00:00<00:00, 12.6MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 927k/927k [00:01<00:00, 498kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 362kiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from previous_chapters import GPTModel, load_weights_into_gpt\n",
        "\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # 어휘사전 크기\n",
        "    \"context_length\": 1024,  # 문맥 길이\n",
        "    \"drop_rate\": 0.0,        # 드롭아웃 비율\n",
        "    \"qkv_bias\": True         # 쿼리-키-값 편향\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "CHOOSE_MODEL = \"gpt2-medium (355M)\"\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(\n",
        "    model_size=model_size,\n",
        "    models_dir=\"gpt2\"\n",
        ")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5",
      "metadata": {
        "id": "dbf3afed-bc8e-4d3a-ad9d-eb6f57bb7af5"
      },
      "source": [
        "- 다음 절에서 모델 미세 튜닝을 시작하기 전에 유효성 검사 작업의 하나로 모델의 성능을 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bd32b7c-5b44-4d25-a09f-46836802ca74",
        "outputId": "70d476c8-65ba-437c-9aa6-08afb5a85f89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "input_text = format_input(val_data[0])\n",
        "print(input_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa",
      "metadata": {
        "id": "2e3e68e0-2627-4c65-b4e7-1e0667e4f6fa"
      },
      "outputs": [],
      "source": [
        "from previous_chapters import (\n",
        "    generate,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "\n",
        "token_ids = generate(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(input_text, tokenizer),\n",
        "    max_new_tokens=35,\n",
        "    context_size=BASE_CONFIG[\"context_length\"],\n",
        "    eos_id=50256,\n",
        ")\n",
        "generated_text = token_ids_to_text(token_ids, tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e2fda5-f796-4954-8f72-1dd1123e3344",
      "metadata": {
        "id": "36e2fda5-f796-4954-8f72-1dd1123e3344"
      },
      "source": [
        "- 이전 장에서 사용했던 `generate` 함수는 입력과 출력 텍스트를 결합하여 반환합니다. 이는 이전 절에서 읽기 쉬운 텍스트를 생성하는 데 편리했습니다.\n",
        "- 응답을 분리하기 위해 `generated_text`의 시작 부분에서 지시의 길이를 뺄 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba4a55bf-a245-48d8-beda-2838a58fb5ba",
        "outputId": "dae1f87a-8618-446c-e1a4-c6f7ab0411e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The chef cooks the meal every day.\n",
            "\n",
            "### Instruction:\n",
            "\n",
            "Convert the active sentence to passive: 'The chef cooks the\n"
          ]
        }
      ],
      "source": [
        "response_text = (\n",
        "    generated_text[len(input_text):]\n",
        "    .replace(\"### Response:\", \"\")\n",
        "    .strip()\n",
        ")\n",
        "print(response_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d44080b2-a4c5-4520-a797-549519f66a3e",
      "metadata": {
        "id": "d44080b2-a4c5-4520-a797-549519f66a3e"
      },
      "source": [
        "- 모델이 아직 지시를 따르지 못하는 것을 볼 수 있습니다. \"Response\" 섹션을 만들지만 원래 입력 문장과 지시를 그대로 반복합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "70d27b9d-a942-4cf5-b797-848c5f01e723",
      "metadata": {
        "id": "70d27b9d-a942-4cf5-b797-848c5f01e723"
      },
      "source": [
        "## 7.6 지시 데이터에서 LLM 미세 튜닝하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a",
      "metadata": {
        "id": "314b2a39-88b4-44d8-8c85-1c5b0cd6cc4a"
      },
      "source": [
        "- 이 절에서는 모델을 미세 튜닝\u001f합니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/16.webp\" width=800px>\n",
        "\n",
        "- 이전 장에서 사용했던 손실 계산 및 학습 함수를 모두 재사용할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "65444865-df87-4d98-9faf-875e1c4be860",
      "metadata": {
        "id": "65444865-df87-4d98-9faf-875e1c4be860"
      },
      "outputs": [],
      "source": [
        "from previous_chapters import (\n",
        "    calc_loss_loader,\n",
        "    train_model_simple\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00",
      "metadata": {
        "id": "00083059-aa41-4d37-8a17-1c72d1b1ca00"
      },
      "source": [
        "- 훈련을 시작하기 전에 초기 훈련 및 검증 세트 손실을 계산해 보겠습니다(이전 장에서와 같이 목표는 손실을 최소화하는 것입니다).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d99fc6f8-63b2-43da-adbb-a7b6b92c8dd5",
        "outputId": "ee32a532-18a9-490f-d72e-18675bdc2af5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 손실: 3.825909376144409\n",
            "검증 손실: 3.7619347095489504\n"
          ]
        }
      ],
      "source": [
        "model.to(device)\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "\n",
        "print(\"훈련 손실:\", train_loss)\n",
        "print(\"검증 손실:\", val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9",
      "metadata": {
        "id": "12a6da8f-15b3-42b0-a136-619b7a35c3e9"
      },
      "source": [
        "- 이전 장보다 더 큰 모델(1억 2,400만 개가 아닌 3억 5,500만 개의 매개변수)을 사용하기 때문에 훈련에 드는 비용이 약간 더 높다는 점에 유의하세요.\n",
        "- 다양한 기기의 실행 시간은 아래 표를 참고하세요(호환되는 GPU 기기에서 이 노트북을 실행하는 데 코드를 변경할 필요가 없습니다).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "db4b57fb-e689-4550-931c-6d34a932487c",
      "metadata": {
        "id": "db4b57fb-e689-4550-931c-6d34a932487c"
      },
      "source": [
        "<div style=\"text-align: left;\">\n",
        "    \n",
        "| 모델              | 기기                | 2 에포크 실행 시간 |\n",
        "|--------------------|-----------------------|----------------------|\n",
        "| gpt2-medium (355M) | CPU (M3 MacBook Air)  | 15.78분        |\n",
        "| gpt2-medium (355M) | GPU (M3 MacBook Air)  | 10.77분        |\n",
        "| gpt2-medium (355M) | GPU (L4)              | 1.83분         |\n",
        "| gpt2-medium (355M) | GPU (A100)            | 0.86분         |\n",
        "| gpt2-small (124M)  | CPU (M3 MacBook Air)  | 5.74분         |\n",
        "| gpt2-small (124M)  | GPU (M3 MacBook Air)  | 3.73분         |\n",
        "| gpt2-small (124M)  | GPU (L4)              | 0.69분         |\n",
        "| gpt2-small (124M)  | GPU (A100)            | 0.39분         |\n",
        "\n",
        "</div>\n",
        "\n",
        "- 이 노트북은 `\"gpt2-medium (355M)\"` 모델을 사용하여 실행했습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78bcf83a-1fff-4540-97c1-765c4016d5e3",
        "outputId": "aa53354c-c6e0-4fd6-b837-2be9df0bb278"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 2.637, Val loss 2.626\n",
            "Ep 1 (Step 000005): Train loss 1.174, Val loss 1.103\n",
            "Ep 1 (Step 000010): Train loss 0.872, Val loss 0.944\n",
            "Ep 1 (Step 000015): Train loss 0.857, Val loss 0.906\n",
            "Ep 1 (Step 000020): Train loss 0.776, Val loss 0.881\n",
            "Ep 1 (Step 000025): Train loss 0.754, Val loss 0.859\n",
            "Ep 1 (Step 000030): Train loss 0.799, Val loss 0.836\n",
            "Ep 1 (Step 000035): Train loss 0.714, Val loss 0.808\n",
            "Ep 1 (Step 000040): Train loss 0.672, Val loss 0.806\n",
            "Ep 1 (Step 000045): Train loss 0.633, Val loss 0.789\n",
            "Ep 1 (Step 000050): Train loss 0.663, Val loss 0.783\n",
            "Ep 1 (Step 000055): Train loss 0.760, Val loss 0.763\n",
            "Ep 1 (Step 000060): Train loss 0.719, Val loss 0.743\n",
            "Ep 1 (Step 000065): Train loss 0.653, Val loss 0.735\n",
            "Ep 1 (Step 000070): Train loss 0.533, Val loss 0.729\n",
            "Ep 1 (Step 000075): Train loss 0.568, Val loss 0.729\n",
            "Ep 1 (Step 000080): Train loss 0.604, Val loss 0.725\n",
            "Ep 1 (Step 000085): Train loss 0.509, Val loss 0.710\n",
            "Ep 1 (Step 000090): Train loss 0.563, Val loss 0.691\n",
            "Ep 1 (Step 000095): Train loss 0.502, Val loss 0.681\n",
            "Ep 1 (Step 000100): Train loss 0.504, Val loss 0.677\n",
            "Ep 1 (Step 000105): Train loss 0.565, Val loss 0.670\n",
            "Ep 1 (Step 000110): Train loss 0.554, Val loss 0.666\n",
            "Ep 1 (Step 000115): Train loss 0.508, Val loss 0.663\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
            "Ep 2 (Step 000120): Train loss 0.435, Val loss 0.671\n",
            "Ep 2 (Step 000125): Train loss 0.451, Val loss 0.687\n",
            "Ep 2 (Step 000130): Train loss 0.447, Val loss 0.682\n",
            "Ep 2 (Step 000135): Train loss 0.405, Val loss 0.682\n",
            "Ep 2 (Step 000140): Train loss 0.410, Val loss 0.681\n",
            "Ep 2 (Step 000145): Train loss 0.369, Val loss 0.681\n",
            "Ep 2 (Step 000150): Train loss 0.382, Val loss 0.675\n",
            "Ep 2 (Step 000155): Train loss 0.414, Val loss 0.675\n",
            "Ep 2 (Step 000160): Train loss 0.412, Val loss 0.684\n",
            "Ep 2 (Step 000165): Train loss 0.379, Val loss 0.686\n",
            "Ep 2 (Step 000170): Train loss 0.322, Val loss 0.680\n",
            "Ep 2 (Step 000175): Train loss 0.338, Val loss 0.667\n",
            "Ep 2 (Step 000180): Train loss 0.392, Val loss 0.656\n",
            "Ep 2 (Step 000185): Train loss 0.414, Val loss 0.657\n",
            "Ep 2 (Step 000190): Train loss 0.340, Val loss 0.648\n",
            "Ep 2 (Step 000195): Train loss 0.328, Val loss 0.633\n",
            "Ep 2 (Step 000200): Train loss 0.309, Val loss 0.633\n",
            "Ep 2 (Step 000205): Train loss 0.353, Val loss 0.631\n",
            "Ep 2 (Step 000210): Train loss 0.364, Val loss 0.630\n",
            "Ep 2 (Step 000215): Train loss 0.393, Val loss 0.634\n",
            "Ep 2 (Step 000220): Train loss 0.297, Val loss 0.644\n",
            "Ep 2 (Step 000225): Train loss 0.342, Val loss 0.658\n",
            "Ep 2 (Step 000230): Train loss 0.294, Val loss 0.656\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is cooked every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: What is the capital of the United Kingdom\n",
            "훈련 소요 시간: 3.27분\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 2\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
        "    start_context=format_input(val_data[0]), tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Ise3wGjlB-iq",
      "metadata": {
        "id": "Ise3wGjlB-iq"
      },
      "source": [
        "- 위 출력 결과를 바탕으로, 훈련 손실 및 검증 손실 값이 감소하고 있으므로 모델이 잘 훈련되고 있음을 알 수 있습니다.\n",
        "- 또한 각 에포크 이후 출력된 응답 텍스트를 기반으로, 모델이 입력 문장 `'The chef cooks the meal every day.'` 를 수동태 `'The meal is cooked every day by the chef.'` 로 올바르게 변환하는 지시를 따르고 있음을 확인할 수 있습니다. (응답에 대한 적절한 포맷 및 평가는 이후 절에서 다루겠습니다)\n",
        "- 마지막으로 훈련 및 검증 손실 곡선을 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4acd368b-1403-4807-a218-9102e35bfdbb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "4acd368b-1403-4807-a218-9102e35bfdbb",
        "outputId": "64b799e8-0a85-4a5a-fd4b-df77abfa7242"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "from previous_chapters import plot_losses\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0",
      "metadata": {
        "id": "6777e0c4-d82c-46d8-84fb-1376c4f8bae0"
      },
      "source": [
        "- 처음 에포크가 시작될 때 손실이 급격히 감소하는 것을 볼 수 있는데, 이는 모델이 빠르게 학습하기 시작했음을 의미합니다.\n",
        "- 1 훈련 에포크가 지나면 약간의 과적합이 발생하는 것을 알 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3",
      "metadata": {
        "id": "87b79a47-13f9-4d1f-87b1-3339bafaf2a3"
      },
      "source": [
        "## 7.7 응답 추출하여 저장하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49",
      "metadata": {
        "id": "5a25cc88-1758-4dd0-b8bf-c044cbf2dd49"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/18.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427",
      "metadata": {
        "id": "17510e9d-7727-4d58-ba9a-d82ec23c1427"
      },
      "source": [
        "- 이 절에서는 다음 절에서 점수를 매기기 위해 테스트 세트 응답을 저장합니다.\n",
        "- 또한 나중에 사용할 수 있도록 모델의 복사본을 저장합니다.\n",
        "- 하지만 먼저, 미세 튜닝된 모델에서 생성된 응답을 간략하게 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "VQ2NZMbfucAc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQ2NZMbfucAc",
        "outputId": "361c1c82-480d-4b6b-b1ed-22114734e49b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Rewrite the sentence using a simile.\n",
            "\n",
            "### Input:\n",
            "The car is very fast.\n",
            "\n",
            "올바른 응답:\n",
            ">> The car is as fast as lightning.\n",
            "\n",
            "모델 응답:\n",
            ">> The car is as fast as a bullet.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "What type of cloud is typically associated with thunderstorms?\n",
            "\n",
            "올바른 응답:\n",
            ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
            "\n",
            "모델 응답:\n",
            ">> The type of cloud associated with thunderstorms is a cumulus cloud.\n",
            "-------------------------------------\n",
            "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Name the author of 'Pride and Prejudice'.\n",
            "\n",
            "올바른 응답:\n",
            ">> Jane Austen.\n",
            "\n",
            "모델 응답:\n",
            ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
            "-------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "\n",
        "for entry in test_data[:3]:\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = (\n",
        "        generated_text[len(input_text):]\n",
        "        .replace(\"### Response:\", \"\")\n",
        "        .strip()\n",
        "    )\n",
        "\n",
        "    print(input_text)\n",
        "    print(f\"\\n올바른 응답:\\n>> {entry['output']}\")\n",
        "    print(f\"\\n모델 응답:\\n>> {response_text.strip()}\")\n",
        "    print(\"-------------------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49ab64c1-586f-4939-8def-23feeb1b3599",
      "metadata": {
        "id": "49ab64c1-586f-4939-8def-23feeb1b3599"
      },
      "source": [
        "- 테스트 세트 지시와 정답 및 모델의 응답을 기반으로 볼 때 모델은 비교적 잘 수행됩니다.\n",
        "- 첫 번째 및 마지막 지시에 대한 답변은 명확하게 정확합니다.\n",
        "- 두 번째 답변은 거의 정확합니다. 모델은 \"cumulonimbus\" 대신 \"cumulus cloud\"으로 답합니다(그러나 적운은 천둥번개를 일으킬 수 있는 적란운으로 발전할 수 있습니다).\n",
        "- 가장 중요한 것은 이전 장에서 정확히 맞은 스팸/스팸아닌 클래스 레이블의 비율을 계산하여 분류 정확도를 얻었던 것처럼 모델 평가가 간단하지 않다는 것입니다.\n",
        "- 실제로 챗봇과 같은 지시 미세 튜닝 LLM은 여러 접근 방식을 통해 평가됩니다.\n",
        "  - 모델의 지식을 테스트하는 MMLU(\"Measuring Massive Multitask Language Understanding\", [https://arxiv.org/abs/2009.03300](https://arxiv.org/abs/2009.03300))와 같은 짧은 답변 및 선다형 벤치마크\n",
        "  - LMSYS 챗봇 아레나([https://arena.lmsys.org](https://arena.lmsys.org))와 같은 여러 LLM에 대한 인간의 선호도 비교\n",
        "  - AlpacaEval([https://tatsu-lab.github.io/alpaca_eval/](https://tatsu-lab.github.io/alpaca_eval/))과 같이 GPT-4와 같은 다른 LLM을 사용하여 응답을 평가하는 자동화된 대화 벤치마크\n",
        "\n",
        "- 다음 절에서는 AlpacaEval과 유사한 접근 방식을 사용해 다른 LLM으로 모델의 응답을 평가합니다. 그러나 공개적으로 사용 가능한 벤치마크 데이터셋을 사용하는 대신 자체 테스트 세트를 사용합니다.\n",
        "- 이를 위해 모델 응답을 `test_data` 딕셔너리에 추가하고 기록 보관을 위해 `\"instruction-data-with-response.json\"` 파일로 저장하여 필요한 경우 별도의 파이썬 세션에서 로드하고 분석할 수 있도록 합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "-PNGKzY4snKP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PNGKzY4snKP",
        "outputId": "6ae7f5b2-5774-4b2a-81c3-d7e79025ff78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [01:09<00:00,  1.59it/s]\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "for i, entry in tqdm(enumerate(test_data), total=len(test_data)):\n",
        "\n",
        "    input_text = format_input(entry)\n",
        "\n",
        "    token_ids = generate(\n",
        "        model=model,\n",
        "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
        "        max_new_tokens=256,\n",
        "        context_size=BASE_CONFIG[\"context_length\"],\n",
        "        eos_id=50256\n",
        "    )\n",
        "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    response_text = generated_text[len(input_text):].replace(\"### Response:\", \"\").strip()\n",
        "\n",
        "    test_data[i][\"model_response\"] = response_text\n",
        "\n",
        "\n",
        "with open(\"instruction-data-with-response.json\", \"w\") as file:\n",
        "    json.dump(test_data, file, indent=4)  # 미려한 출력을 위해 \"indent\" 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "228d6fa7-d162-44c3-bef1-4013c027b155",
      "metadata": {
        "id": "228d6fa7-d162-44c3-bef1-4013c027b155"
      },
      "source": [
        "- `test_data` 딕셔너리에 응답이 제대로 추가되었는지 확인하기 위해 항목 중 하나를 다시 확인해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "u-AvCCMTnPSE",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-AvCCMTnPSE",
        "outputId": "65be944a-e9ea-443a-dca3-d5310bd26672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'instruction': 'Rewrite the sentence using a simile.', 'input': 'The car is very fast.', 'output': 'The car is as fast as lightning.', 'model_response': 'The car is as fast as a bullet.'}\n"
          ]
        }
      ],
      "source": [
        "print(test_data[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a",
      "metadata": {
        "id": "c1b2f3f6-8569-405a-9db6-d47cba65608a"
      },
      "source": [
        "- 마지막으로, 나중에 재사용할 수 있도록 모델을 저장합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "8cBU0iHmVfOI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cBU0iHmVfOI",
        "outputId": "0843dbdb-9811-4b32-e0a2-d6f82a1ba8ab",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "모델이 gpt2-medium355M-sft.pth에 저장되었습니다.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "\n",
        "file_name = f\"{re.sub(r'[ ()]', '', CHOOSE_MODEL) }-sft.pth\"\n",
        "torch.save(model.state_dict(), file_name)\n",
        "print(f\"모델이 {file_name}에 저장되었습니다.\")\n",
        "\n",
        "# 모델 로드 방법:\n",
        "# model.load_state_dict(torch.load(\"gpt2-medium355M-sft.pth\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "obgoGI89dgPm",
      "metadata": {
        "id": "obgoGI89dgPm"
      },
      "source": [
        "## 7.8 미세 튜닝된 LLM 평가하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XWo200KTfDfE",
      "metadata": {
        "id": "XWo200KTfDfE"
      },
      "source": [
        "**이 절은 로컬에서 Ollama를 설치한 후 주피터 노트북에서 이어서 실행할 수 있습니다**"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "805b9d30-7336-499f-abb5-4a21be3129f5",
      "metadata": {
        "id": "805b9d30-7336-499f-abb5-4a21be3129f5"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/19.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1",
      "metadata": {
        "id": "68d2b9d3-b6ff-4533-a89d-7b66079b4fd1"
      },
      "source": [
        "- 이 절에서는 더 큰 다른 LLM을 사용하여 미세 튜닝된 LLM의 응답 평가를 자동화합니다.\n",
        "- 특히, ollama([https://ollama.com](https://ollama.com))를 통해 로컬에서 실행할 수 있는 메타 AI에서 만든 지시 미세 튜닝된 80억 매개변수의 Llama 3 모델을 사용합니다.\n",
        "- (또는 오픈AI API를 통해 GPT-4와 같이 더욱 강력한 LLM을 사용하려는 경우 [llm-instruction-eval-openai.ipynb](../03_model-evaluation/llm-instruction-eval-openai.ipynb) 노트북을 참조하세요.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9",
      "metadata": {
        "id": "ea427a30-36ba-44e3-bb1f-eb0d7008d6e9"
      },
      "source": [
        "- Ollama는 LLM을 효율적으로 실행하기 위한 애플리케이션입니다.\n",
        "- 순수 C/C++로 LLM을 구현하여 효율성을 극대화하는 llama.cpp ([https://github.com/ggerganov/llama.cpp](https://github.com/ggerganov/llama.cpp))의 래퍼입니다.\n",
        "- LLM을 사용하여 텍스트를 생성(추론)하는 도구이며, LLM을 학습하거나 미세 튜닝하는 도구가 아닙니다.\n",
        "- 아래 코드를 실행하기 전에 [https://ollama.com](https://ollama.com)을 방문하여 지침(예: \"다운로드\" 버튼을 클릭하고 운영 체제에 맞는 ollama 애플리케이션 다운로드)에 따라 ollama를 설치하세요.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822",
      "metadata": {
        "id": "747a2fc7-282d-47ec-a987-ed0a23ed6822"
      },
      "source": [
        "- macOS 및 윈도 사용자의 경우 다운로드한 ollama 애플리케이션을 클릭합니다. 명령줄 사용 설치를 묻는 메시지가 표시되면 \"yes\"라고 답합니다.\n",
        "- 리눅스 사용자는 ollama 웹사이트에 제공된 설치 명령을 사용할 수 있습니다.\n",
        "\n",
        "- 일반적으로 명령줄에서 ollama를 사용하려면 먼저 ollama 애플리케이션을 시작하거나 별도의 터미널에서 `ollama serve`를 실행해야 합니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/20.webp\" width=800px>\n",
        "\n",
        "---\n",
        "**노트**:\n",
        "- 앞에서 언급한대로 터미널에서 `ollama serve`를 실행할 때 `Error: listen tcp 127.0.0.1:11434: bind: address already in use`와 같은 오류 메시지를 만날 수 있습니다.\n",
        "- 이런 경우에는 `OLLAMA_HOST=127.0.0.1:11435 ollama serve` 명령을 시도해 보세요(같은 오류가 나오면 빈 포트 번호를 찾을 때까지 증가시키세요).\n",
        "---\n",
        "\n",
        "- 다른 터미널에서 ollama 애플리케이션 또는 `ollama serve`를 실행한 상태에서 명령줄에서 다음 명령을 실행하여 80억 매개변수 Llama 3 모델을 사용해 보세요(4.7GB의 저장 공간을 차지하는 이 모델은 이 명령을 처음 실행할 때 자동으로 다운로드됩니다).\n",
        "\n",
        "```bash\n",
        "# 8B 모델\n",
        "ollama run llama3\n",
        "```\n",
        "\n",
        "\n",
        "출력은 다음과 같습니다.\n",
        "\n",
        "```\n",
        "$ ollama run llama3\n",
        "pulling manifest\n",
        "pulling 6a0746a1ec1a... 100% ▕████████████████▏ 4.7 GB\n",
        "pulling 4fa551d4f938... 100% ▕████████████████▏  12 KB\n",
        "pulling 8ab4849b038c... 100% ▕████████████████▏  254 B\n",
        "pulling 577073ffcc6c... 100% ▕████████████████▏  110 B\n",
        "pulling 3f8eb4da87fa... 100% ▕████████████████▏  485 B\n",
        "verifying sha256 digest\n",
        "writing manifest\n",
        "removing any unused layers\n",
        "success\n",
        "```\n",
        "\n",
        "- `llama3`는 지시 미세 튜닝된 80억 매개변수 Llama 3 모델을 나타냅니다.\n",
        "\n",
        "- `\"llama3\"` 모델(8B 매개변수 모델)로 ollama를 사용하려면 16GB의 RAM이 필요합니다. 머신에서 이를 지원하지 않는 경우 `model = \"phi-3\"`를 설정하여 8GB의 RAM만 필요한 3.8B 매개변수 phi-3 모델과 같은 더 작은 모델을 사용해 볼 수 있습니다.\n",
        "\n",
        "- 또는 머신에서 지원하는 경우 `llama3`를 `llama3:70b`로 바꿔 더 큰 700억 매개변수 Llama 3 모델을 사용할 수도 있습니다.\n",
        "\n",
        "- 다운로드가 완료되면 모델과 채팅할 수 있는 명령줄 프롬프트가 표시됩니다.\n",
        "\n",
        "- \"What do llamas eat?\"와 같은 프롬프트를 시도해 보세요. 다음과 같은 출력이 반환됩니다.\n",
        "\n",
        "```\n",
        ">>> What do llamas eat?\n",
        "Llamas are ruminant animals, which means they have a four-chambered\n",
        "stomach and eat plants that are high in fiber. In the wild, llamas\n",
        "typically feed on:\n",
        "1. Grasses: They love to graze on various types of grasses, including tall\n",
        "grasses, wheat, oats, and barley.\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4",
      "metadata": {
        "id": "7b7b341c-ba0e-40bb-a52c-cb328bbd1fe4"
      },
      "source": [
        "- `/bye` 입력을 사용하여 세션을 종료할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3",
      "metadata": {
        "id": "faaf3e02-8ca0-4edf-be23-60625a5b14e3"
      },
      "source": [
        "- 다음 코드는 이전 절에서 생성한 테스트 세트 응답을 평가하기 위해 ollama를 사용하기 전에 ollama 세션이 올바르게 실행되고 있는지 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "026e8570-071e-48a2-aa38-64d7be35f288",
      "metadata": {
        "id": "026e8570-071e-48a2-aa38-64d7be35f288",
        "outputId": "43b822a1-e5a3-4691-e3f9-abd4a4abd133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Ollama가 실행 중이 아닙니다. 먼저 Ollama를 실행하세요.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3896353979.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mollama_running\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ollama가 실행 중이 아닙니다. 먼저 Ollama를 실행하세요.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Ollama 실행:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_if_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ollama\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Ollama가 실행 중이 아닙니다. 먼저 Ollama를 실행하세요."
          ]
        }
      ],
      "source": [
        "import psutil\n",
        "\n",
        "def check_if_running(process_name):\n",
        "    running = False\n",
        "    for proc in psutil.process_iter([\"name\"]):\n",
        "        if process_name in proc.info[\"name\"]:\n",
        "            running = True\n",
        "            break\n",
        "    return running\n",
        "\n",
        "ollama_running = check_if_running(\"ollama\")\n",
        "\n",
        "if not ollama_running:\n",
        "    raise RuntimeError(\"Ollama가 실행 중이 아닙니다. 먼저 Ollama를 실행하세요.\")\n",
        "print(\"Ollama 실행:\", check_if_running(\"ollama\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0",
      "metadata": {
        "id": "723c9b00-e3cd-4092-83c3-6e48b5cf65b0"
      },
      "outputs": [],
      "source": [
        "# 이 셀은 선택 사항입니다. 노트북을 다시 시작했을 때 이전 코드를 다시 실행하지 않고 섹션 7.7만 실행할 수 있습니다.\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "file_path = \"instruction-data-with-response.json\"\n",
        "\n",
        "with open(file_path, \"r\") as file:\n",
        "    test_data = json.load(file)\n",
        "\n",
        "\n",
        "def format_input(entry):\n",
        "    instruction_text = (\n",
        "        f\"Below is an instruction that describes a task. \"\n",
        "        f\"Write a response that appropriately completes the request.\"\n",
        "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
        "    )\n",
        "\n",
        "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
        "\n",
        "    return instruction_text + input_text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3464705-d026-4594-977f-fb357e51c3a9",
      "metadata": {
        "id": "b3464705-d026-4594-977f-fb357e51c3a9"
      },
      "source": [
        "- 이전에 모델과 상호 작용하기 위해 사용했던 `ollama run` 명령 대신 파이썬에서 REST API를 통해 다음 함수를 사용할 수 있습니다.\n",
        "- 이 노트북의 다음 셀을 실행하기 전에 ollama가 여전히 실행 중인지 확인하세요 (이전 코드 셀에서 `\"Ollama 실행: True\"`가 출력되어야 함).\n",
        "- 다음으로, 다음 코드 셀을 실행하여 모델에 쿼리를 전달합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f",
      "metadata": {
        "id": "e3ae0e10-2b28-42ce-8ea2-d9366a58088f"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "# import urllib.request\n",
        "\n",
        "def query_model(\n",
        "    prompt,\n",
        "    model=\"llama3\",\n",
        "    # OLLAMA_HOST=127.0.0.1:11435 ollama serve 명령을 사용했다면\n",
        "    # 포트 번호를 11434에서 11435로 수정하세요.\n",
        "    url=\"http://localhost:11434/api/chat\"\n",
        "):\n",
        "    # 데이터 페이로드를 딕셔너리로 생성\n",
        "    data = {\n",
        "        \"model\": model,\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": prompt}\n",
        "        ],\n",
        "        \"options\": {     # 아래 설정은 결정론적인 응답에 필요합니다.\n",
        "            \"seed\": 123,\n",
        "            \"temperature\": 0,\n",
        "            \"num_ctx\": 2048\n",
        "        }\n",
        "    }\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    # 딕셔너리를 JSON 형식의 문자열로 변환하고 바이트로 인코딩\n",
        "    payload = json.dumps(data).encode(\"utf-8\")\n",
        "\n",
        "    # 요청 객체를 생성하고, 메서드를 POST로 설정하고 필요한 헤더를 추가\n",
        "    request = urllib.request.Request(\n",
        "        url,\n",
        "        data=payload,\n",
        "        method=\"POST\"\n",
        "    )\n",
        "    request.add_header(\"Content-Type\", \"application/json\")\n",
        "\n",
        "    # 요청을 보내고 응답을 받음\n",
        "    response_data = \"\"\n",
        "    with urllib.request.urlopen(request) as response:\n",
        "        # 응답을 읽고 디코딩\n",
        "        while True:\n",
        "            line = response.readline().decode(\"utf-8\")\n",
        "            if not line:\n",
        "                break\n",
        "            response_json = json.loads(line)\n",
        "            response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "    \"\"\"\n",
        "\n",
        "    # 책에서는 앞의 코드를 사용했지만 VPN을 사용하는 경우 urllib가 문제를 일으킬 수 있습니다.\n",
        "    # 따라서 더 안정적인 `requests` 패키지를 사용합니다.\n",
        "\n",
        "    # POST 요청을 보냅니다.\n",
        "    with requests.post(url, json=data, stream=True, timeout=30) as r:\n",
        "        r.raise_for_status()\n",
        "        response_data = \"\"\n",
        "        for line in r.iter_lines(decode_unicode=True):\n",
        "            if not line:\n",
        "                continue\n",
        "            response_json = json.loads(line)\n",
        "            if \"message\" in response_json:\n",
        "                response_data += response_json[\"message\"][\"content\"]\n",
        "\n",
        "    return response_data\n",
        "\n",
        "\n",
        "model = \"llama3\"\n",
        "result = query_model(\"What do Llamas eat?\", model)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc",
      "metadata": {
        "id": "207ae28f-0f8c-4fda-aeef-e7e3046249cc"
      },
      "source": [
        "- 이제 위에서 정의한 `query_model` 함수를 사용하여 미세 튜닝된 모델의 응답을 평가할 수 있습니다. 이전 절에서 살펴본 처음 3개의 테스트 샘플 응답에 대해 시도해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86b839d4-064d-4178-b2d7-01691b452e5e",
      "metadata": {
        "id": "86b839d4-064d-4178-b2d7-01691b452e5e"
      },
      "outputs": [],
      "source": [
        "for entry in test_data[:3]:\n",
        "    prompt = (\n",
        "        f\"Given the input `{format_input(entry)}` \"\n",
        "        f\"and correct output `{entry['output']}`, \"\n",
        "        f\"score the model response `{entry['model_response']}`\"\n",
        "        f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "    )\n",
        "    print(\"\\n데이터셋 응답:\")  # Dataset response\n",
        "    print(\">>\", entry['output'])\n",
        "    print(\"\\n모델 응답:\")  # Model response\n",
        "    print(\">>\", entry[\"model_response\"])\n",
        "    print(\"\\n점수:\")  # Score\n",
        "    print(\">>\", query_model(prompt))\n",
        "    print(\"\\n-------------------------\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24fec453-631f-4ff5-a922-44c3c451942d",
      "metadata": {
        "id": "24fec453-631f-4ff5-a922-44c3c451942d"
      },
      "source": [
        "---\n",
        "\n",
        "**참고: 더 나은 평가 프롬프트**\n",
        "\n",
        "- [한 독자(Ayoosh Kathuria)가 제안한](https://github.com/rasbt/LLMs-from-scratch/discussions/449) 더 길고 개선된 프롬프트는 1에서 100까지가 아닌 1에서 5까지의 척도로 응답을 평가하고 채점 기준표를 사용하여 더 정확하고 잡음이 적은 평가를 제공합니다.\n",
        "\n",
        "```\n",
        "prompt = \"\"\"\n",
        "You are a fair judge assistant tasked with providing clear, objective feedback based on specific criteria, ensuring each assessment reflects the absolute standards set for performance.\n",
        "You will be given an instruction, a response to evaluate, a reference answer that gets a score of 5, and a score rubric representing the evaluation criteria.\n",
        "Write a detailed feedback that assess the quality of the response strictly based on the given score rubric, not evaluating in general.\n",
        "Please do not generate any other opening, closing, and explanations.\n",
        "\n",
        "Here is the rubric you should use to build your answer:\n",
        "1: The response fails to address the instructions, providing irrelevant, incorrect, or excessively verbose information that detracts from the user's request.\n",
        "2: The response partially addresses the instructions but includes significant inaccuracies, irrelevant details, or excessive elaboration that detracts from the main task.\n",
        "3: The response follows the instructions with some minor inaccuracies or omissions. It is generally relevant and clear, but may include some unnecessary details or could be more concise.\n",
        "4: The response adheres to the instructions, offering clear, accurate, and relevant information in a concise manner, with only occasional, minor instances of excessive detail or slight lack of clarity.\n",
        "5: The response fully adheres to the instructions, providing a clear, accurate, and relevant answer in a concise and efficient manner. It addresses all aspects of the request without unnecessary details or elaboration\n",
        "\n",
        "Provide your feedback as follows:\n",
        "\n",
        "Feedback:::\n",
        "Evaluation: (your rationale for the rating, as a text)\n",
        "Total rating: (your rating, as a number between 1 and 5)\n",
        "\n",
        "You MUST provide values for 'Evaluation:' and 'Total rating:' in your answer.\n",
        "\n",
        "Now here is the instruction, the reference answer, and the response.\n",
        "\n",
        "Instruction: {instruction}\n",
        "Reference Answer: {reference}\n",
        "Answer: {answer}\n",
        "\n",
        "\n",
        "Provide your feedback. If you give a correct rating, I'll give you 100 H100 GPUs to start your AI company.\n",
        "Feedback:::\n",
        "Evaluation: \"\"\"\n",
        "```\n",
        "\n",
        "- 자세한 내용은 [깃허브 토론](https://github.com/rasbt/LLMs-from-scratch/discussions/449)을 참조하십시오.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3",
      "metadata": {
        "id": "b114fd65-9cfb-45f6-ab74-8331da136bf3"
      },
      "source": [
        "- Llama 3 모델은 합리적인 평가를 제공하며, \"적운(cumulus cloud)\" 답변에서 볼 수 있듯이 모델이 완전히 정확하지 않은 경우에도 부분 점수를 부여합니다.\n",
        "- 이전 프롬프트는 매우 자세한 평가를 반환합니다. 프롬프트를 수정하여 모델의 평균 점수를 계산하기 위해 0에서 100 사이의 정수 응답(100이 가장 좋음)을 생성할 수 있습니다.\n",
        "- 테스트 세트의 110개 항목 평가는 M3 맥북 에어 노트북에서 약 1분 정도 소요됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb",
      "metadata": {
        "id": "9d7bca69-97c4-47a5-9aa0-32f116fa37eb"
      },
      "outputs": [],
      "source": [
        "def generate_model_scores(json_data, json_key, model=\"llama3\"):\n",
        "    scores = []\n",
        "    for entry in tqdm(json_data, desc=\"점수 입력\"):  # Scoring entries\n",
        "        prompt = (\n",
        "            f\"Given the input `{format_input(entry)}` \"\n",
        "            f\"and correct output `{entry['output']}`, \"\n",
        "            f\"score the model response `{entry[json_key]}`\"\n",
        "            f\" on a scale from 0 to 100, where 100 is the best score. \"\n",
        "            f\"Respond with the integer number only.\"\n",
        "        )\n",
        "        score = query_model(prompt, model)\n",
        "        try:\n",
        "            scores.append(int(score))\n",
        "        except ValueError:\n",
        "            print(f\"점수로 변환할 수 없습니다: {score}\")  # Could not convert score: {score}\n",
        "            continue\n",
        "\n",
        "    return scores\n",
        "\n",
        "\n",
        "scores = generate_model_scores(test_data, \"model_response\")\n",
        "print(f\"평가 횟수: {len(test_data)}개 중 {len(scores)}개\")\n",
        "print(f\"평균 점수: {sum(scores)/len(scores):.2f}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2",
      "metadata": {
        "id": "407f08d5-9ada-4301-9ebc-f0533c76d3f2"
      },
      "source": [
        "- 이 모델은 평균 50점 이상을 달성했으며, 이는 다른 모델과 비교하거나 모델을 개선하기 위해 다른 훈련 설정을 시도해 볼 수 있는 기준점으로 사용할 수 있습니다.\n",
        "- ollama는 (이 글을 쓰는 시점에서) 여러 운영 체제에 걸쳐 완전히 결정론적이지 않으므로, 여러분이 얻는 수치는 위에 표시된 것과 약간 다를 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94",
      "metadata": {
        "id": "6408768b-2784-44f1-b48e-aed0c1eb9b94"
      },
      "source": [
        "- 참고로 원본\n",
        "  - Llama 3 8B 기본 모델은 58.51점을 달성했습니다.\n",
        "  - Llama 3 8B 지시 모델은 82.65점을 달성했습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "412d7325-284a-446c-92a1-5aa8acc52dee",
      "metadata": {
        "id": "412d7325-284a-446c-92a1-5aa8acc52dee"
      },
      "source": [
        "## 7.9 결론\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tIbNMluCDjVM",
      "metadata": {
        "id": "tIbNMluCDjVM"
      },
      "source": [
        "### 7.9.1 다음 단계는?\n",
        "\n",
        "- 이 장은 이 책의 마지막 장입니다.\n",
        "- LLM 개발 사이클의 주요 단계인 LLM 구조 구현, LLM 사전 훈련 및 미세 튜닝을 다루었습니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch07_compressed/21.webp\" width=800px>\n",
        "\n",
        "- 이 장에서 설명한 지시 미세 튜닝 후에 수행되는 선택적 단계는 선호도 미세 튜닝입니다.\n",
        "- 선호도 미세 튜닝 프로세스는 특정 사용자 선호도에 맞게 모델을 커스터마이징하는 데 특히 유용할 수 있습니다. 관심 있는 경우 [../04_preference-tuning-with-dpo](../04_preference-tuning-with-dpo) 폴더를 참조하세요.\n",
        "\n",
        "- 이 깃허브 저장소에는 다양한 추가 보너스 자료가 포함되어 있습니다. 자세한 내용은 이 저장소의 README 페이지에 있는 [보너스 자료](https://github.com/rickiepark/llm-from-scratch?tab=readme-ov-file#bonus-material) 섹션을 참조하세요.\n",
        "\n",
        "### 7.9.2 빠르게 변화하는 분야의 최신 정보 얻기\n",
        "\n",
        "- 이 섹션에는 코드가 없습니다.\n",
        "\n",
        "### 7.9.3 맺음말\n",
        "\n",
        "- 처음부터 LLM을 구현하고 사전 훈련 및 미세 튜닝 함수를 코딩하는 이 여정을 즐겼기를 바랍니다.\n",
        "- 제 생각에는 처음부터 LLM을 구현하는 것이 LLM의 작동 방식을 이해하는 가장 좋은 방법입니다. 이 접근 방식을 통해 더 잘 이해했기를 바랍니다.\n",
        "- 이 책은 교육 목적을 위해 작성되었지만 실제 애플리케이션을 위해 더 강력한 다른 LLM을 사용하는 데 관심이 있을 수 있습니다.\n",
        "  - 이를 위해 axolotl([https://github.com/OpenAccess-AI-Collective/axolotl](https://github.com/OpenAccess-AI-Collective/axolotl)) 또는 제가 개발을 돕고 있는 LitGPT([https://github.com/Lightning-AI/litgpt](https://github.com/Lightning-AI/litgpt))와 같은 인기 있는 도구를 고려할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9853e7f-a81a-4806-9728-be1690807185",
      "metadata": {
        "id": "f9853e7f-a81a-4806-9728-be1690807185"
      },
      "source": [
        "## 요약\n",
        "\n",
        "- 독립적인 지시 미세 튜닝 스크립트는 [./gpt_instruction_finetuning.py](./gpt_instruction_finetuning.py)를 참조하세요.\n",
        "- [./ollama_evaluate.py](./ollama_evaluate.py)는 7.8절을 기반으로 \"output\" 및 \"response\" 키가 포함된 JSON 파일을 Ollama 및 Llama 3를 통해 평가하는 독립형 스크립트입니다.\n",
        "- [./load-finetuned-model.ipynb](./load-finetuned-model.ipynb) 노트북은 새로운 세션에서 미세 튜닝된 모델을 로드하는 방법을 보여줍니다.\n",
        "- [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에서 연습 문제 솔루션을 확인할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9cc51ec-e06c-4470-b626-48401a037851",
      "metadata": {
        "id": "b9cc51ec-e06c-4470-b626-48401a037851"
      },
      "source": [
        "## 이어서 볼 만한 자료\n",
        "\n",
        "- 책을 완료하신 것을 축하드립니다. 추가 자료를 찾고 계신 경우를 대비하여, 이 깃허브 저장소에 흥미로울 만한 몇 가지 보너스 섹션을 추가했습니다.\n",
        "- 보너스 자료의 전체 목록은 메인 README의 [보너스 자료](https://github.com/rickiepark/llm-from-scratch?tab=readme-ov-file#bonus-material) 섹션에서 볼 수 있습니다.\n",
        "- 제가 좋아하는 몇 가지를 강조하자면 다음과 같습니다.\n",
        "  1. [(밑바닥부터) LLM 정렬을 위한 DPO](../04_preference-tuning-with-dpo/dpo-from-scratch.ipynb)는 이 장의 모델을 인간의 선호도에 더 가깝게 정렬하기 위한 인기 있는 선호도 튜닝 메커니즘을 구현합니다.\n",
        "  2. [처음부터 Llama 3.2(독립형 노트북)](../../ch05/07_gpt_to_llama/standalone-llama32.ipynb)는 공식 사전 훈련된 가중치 로드를 포함하여 메타 AI의 인기 있는 Llama 3.2를 처음부터 구현한 것입니다. 추가 실험을 하고 싶다면 각 장의 `GPTModel` 모델을 `Llama3Model` 클래스로 대체할 수 있습니다.\n",
        "  3. [GPT를 Llama로 변환](../../ch05/07_gpt_to_llama)에는 GPT-2와 다양한 Llama 모델 간의 차이점을 설명하는 단계별 가이드가 포함된 코드가 있습니다.\n",
        "  4. [임베딩 층과 선형 층의 차이점 이해](../../ch02/03_bonus_embedding-vs-matmul/embeddings-and-linear-layers.ipynb)는 LLM의 입력 단계에서 사용하는 파이토치의 `Embedding` 층이 수학적으로 원-핫 인코딩된 데이터에 적용된 선형 층과 동일하다는 것을 보여주는 개념적 설명입니다.\n",
        "- 더 즐거운 시간이 되시기 바랍니다!\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}