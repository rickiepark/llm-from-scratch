{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickiepark/llm-from-scratch/blob/main/ch06/01_main-chapter-code/ch06.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b",
      "metadata": {
        "id": "c024bfa4-1a7a-4751-b5a1-827225a3478b"
      },
      "source": [
        "<table style=\"width:100%\">\n",
        "<tr>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<font size=\"2\">\n",
        "세바스찬 라시카(Sebastian Raschka)가 쓴 <a href=\"http://mng.bz/orYv\">Build a Large Language Model From Scratch</a>의 번역서 <br><<b><a href=\"<a href=\"http://tensorflow.blog/llm-from-scratch\">밑바닥부터 만들면서 배우는 LLM</a></b>>의 예제 코드입니다.<br>\n",
        "<br>코드 저장소: <a href=\"https://github.com/rickiepark/llm-from-scratch\">https://github.com/rickiepark/llm-from-scratch</a>\n",
        "</font>\n",
        "</td>\n",
        "<td style=\"vertical-align:middle; text-align:left;\">\n",
        "<a href=\"http://tensorflow.blog/llm-from-scratch\"><img src=\"https://tensorflowkorea.wordpress.com/wp-content/uploads/2025/09/ebb091ebb094eb8ba5llm_ebb3b8ecb185_ec959eeba9b4.jpg\" width=\"100px\"></a>\n",
        "</td>\n",
        "</tr>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bfabadb8-5935-45ff-b39c-db7a29012129",
      "metadata": {
        "id": "bfabadb8-5935-45ff-b39c-db7a29012129"
      },
      "source": [
        "# 챕터 6: 텍스트 분류를 위한 미세 튜닝\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5b7e01c2-1c84-4f2a-bb51-2e0b74abda90",
        "outputId": "27e5d9e6-2f81-47ac-834a-3d8ab76fd12d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "matplotlib 버전: 3.10.0\n",
            "numpy 버전: 2.0.2\n",
            "tiktoken 버전: 0.12.0\n",
            "torch 버전: 2.8.0+cu126\n",
            "tensorflow 버전: 2.19.0\n",
            "pandas 버전: 2.2.2\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "\n",
        "pkgs = [\"matplotlib\",  # 그래프 라이브러리\n",
        "        \"numpy\",       # 파이토치와 텐서플로의 종속성\n",
        "        \"tiktoken\",    # 토크나이저\n",
        "        \"torch\",       # 딥러닝 라이브러리\n",
        "        \"tensorflow\",  # OpenAI의 사전 훈련된 가중치를 위해서\n",
        "        \"pandas\"       # 데이터셋 로딩을 위해\n",
        "       ]\n",
        "for p in pkgs:\n",
        "    print(f\"{p} 버전: {version(p)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d",
      "metadata": {
        "id": "a445828a-ff10-4efa-9f60-a2e2aed4c87d"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/01.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c",
      "metadata": {
        "id": "3a84cf35-b37f-4c15-8972-dfafc9fadc1c"
      },
      "source": [
        "## 6.1 여러 가지 미세 튜닝 방법\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ede3d731-5123-4f02-accd-c670ce50a5a3",
      "metadata": {
        "id": "ede3d731-5123-4f02-accd-c670ce50a5a3"
      },
      "source": [
        "- 이 절에는 코드가 없습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac45579d-d485-47dc-829e-43be7f4db57b",
      "metadata": {
        "id": "ac45579d-d485-47dc-829e-43be7f4db57b"
      },
      "source": [
        "- 가장 일반적인 언어 모델 미세 튜닝 방법은 지시 미세 조정 및 분류 미세 튜닝입니다.\n",
        "- 아래에 나타난 지시 미세 튜닝은 다음 장의 주제입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4",
      "metadata": {
        "id": "6c29ef42-46d9-43d4-8bb4-94974e1665e4"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/02.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd",
      "metadata": {
        "id": "a7f60321-95b8-46a9-97bf-1d07fda2c3dd"
      },
      "source": [
        "- 이 장의 주제인 분류 미세 튜닝(Classification finetuning)은 머신 러닝에 대한 배경 지식이 있다면 이미 익숙할 수 있는 절차입니다. 예를 들어, 손글씨 숫자를 분류하기 위해 합성곱 신경망을 훈련하는 것과 유사합니다.\n",
        "- 분류 미세 튜닝에서는 모델이 출력할 수 있는 특정 개수의 클래스 레이블(예: \"스팸\" 및 \"스팸아님\")이 있습니다.\n",
        "- 분류 미세 튜닝된 모델은 훈련 중에 본 클래스(예: \"스팸\" 또는 \"스팸아님\")만 예측할 수 있는 반면, 지시 미세 튜닝된 모델은 일반적으로 많은 작업을 수행할 수 있습니다.\n",
        "- 분류 미세 튜닝된 모델을 매우 특수화된 모델로 생각할 수 있습니다. 실제로는 다양한 작업에서 잘 수행되는 일반 모델보다 특수 모델을 만드는 것이 훨씬 쉽습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3",
      "metadata": {
        "id": "0b37a0c4-0bb1-4061-b1fe-eaa4416d52c3"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/03.webp\" width=600px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf",
      "metadata": {
        "id": "8c7017a2-32aa-4002-a2f3-12aac293ccdf"
      },
      "source": [
        "## 6.2 데이터셋 준비\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067",
      "metadata": {
        "id": "5f628975-d2e8-4f7f-ab38-92bb868b7067"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/04.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d",
      "metadata": {
        "id": "9fbd459f-63fa-4d8c-8499-e23103156c7d"
      },
      "source": [
        "- 이 섹션에서는 분류 미세 튜닝에 사용할 데이터셋을 준비합니다.\n",
        "- 스팸 및 스팸아님 텍스트 메시지로 구성된 데이터셋을 분류하기 위해 LLM을 미세 튜닝합니다.\n",
        "- 먼저 데이터셋을 다운로드하고 압축을 풉니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 189
        },
        "id": "def7c09b-af9c-4216-90ce-5e67aed1065c",
        "outputId": "0f18fc5c-273e-4172-9807-6639699920a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파일이 다운로드되어 sms_spam_collection/SMSSpamCollection.tsv에 저장되었습니다.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nimport urllib.request\\nimport zipfile\\nimport os\\nfrom pathlib import Path\\n\\nurl = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\\nzip_path = \"sms_spam_collection.zip\"\\nextracted_path = \"sms_spam_collection\"\\ndata_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\\n\\ndef download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\\n    if data_file_path.exists():\\n        print(f\"{data_file_path}가 이미 있어 다운로드 및 압축 해제를 건너뜁니다.\")\\n        return\\n\\n    # 파일을 다운로드 합니다.\\n    with urllib.request.urlopen(url) as response:\\n        with open(zip_path, \"wb\") as out_file:\\n            out_file.write(response.read())\\n\\n    # 파일 압축을 풉니다.\\n    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\\n        zip_ref.extractall(extracted_path)\\n\\n    # .tsv 파일 확장자를 추가합니다.\\n    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\\n    os.rename(original_file_path, data_file_path)\\n    print(f\"파일이 다운로드되어 {data_file_path}에 저장되었습니다.\")\\n\\ntry:\\n    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\\nexcept (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\\n    print(f\"기본 URL 실패: {e}. 백업 URL을 시도합니다...\")\\n    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\\n    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path}가 이미 있어 다운로드 및 압축 해제를 건너뜁니다.\")\n",
        "        return\n",
        "\n",
        "    # 파일을 다운로드 합니다.\n",
        "    response = requests.get(url, stream=True, timeout=60)\n",
        "    response.raise_for_status()\n",
        "    with open(zip_path, \"wb\") as out_file:\n",
        "        for chunk in response.iter_content(chunk_size=8192):\n",
        "            if chunk:\n",
        "                out_file.write(chunk)\n",
        "\n",
        "    # 파일 압축을 풉니다.\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # .tsv 파일 확장자를 추가합니다.\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"파일이 다운로드되어 {data_file_path}에 저장되었습니다.\")\n",
        "\n",
        "try:\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "except (requests.exceptions.RequestException, TimeoutError) as e:\n",
        "    print(f\"기본 URL 실패: {e}. 백업 URL을 시도합니다...\")\n",
        "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "\n",
        "\n",
        "# 책에서는 다음 코드를 사용했지만 VPN을 사용하는 경우 urllib가 문제를 일으킬 수 있습니다.\n",
        "# 따라서 더 안정적인 `requests` 패키지를 사용합니다.\n",
        "\n",
        "\"\"\"\n",
        "import urllib.request\n",
        "import zipfile\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
        "zip_path = \"sms_spam_collection.zip\"\n",
        "extracted_path = \"sms_spam_collection\"\n",
        "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\"\n",
        "\n",
        "def download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path):\n",
        "    if data_file_path.exists():\n",
        "        print(f\"{data_file_path}가 이미 있어 다운로드 및 압축 해제를 건너뜁니다.\")\n",
        "        return\n",
        "\n",
        "    # 파일을 다운로드 합니다.\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        with open(zip_path, \"wb\") as out_file:\n",
        "            out_file.write(response.read())\n",
        "\n",
        "    # 파일 압축을 풉니다.\n",
        "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extracted_path)\n",
        "\n",
        "    # .tsv 파일 확장자를 추가합니다.\n",
        "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
        "    os.rename(original_file_path, data_file_path)\n",
        "    print(f\"파일이 다운로드되어 {data_file_path}에 저장되었습니다.\")\n",
        "\n",
        "try:\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "except (urllib.error.HTTPError, urllib.error.URLError, TimeoutError) as e:\n",
        "    print(f\"기본 URL 실패: {e}. 백업 URL을 시도합니다...\")\n",
        "    url = \"https://f001.backblazeb2.com/file/LLMs-from-scratch/sms%2Bspam%2Bcollection.zip\"\n",
        "    download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1",
      "metadata": {
        "id": "6aac2d19-06d0-4005-916b-0bd4b1ee50d1"
      },
      "source": [
        "- 데이터셋은 탭으로 구분된 텍스트 파일로 저장되며, 판다스 DataFrame으로 로드할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "da0ed4da-ac31-4e4d-8bdd-2153be4656a4",
        "outputId": "a0c1257e-3481-4769-a1a3-58b03e3425ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Label                                               Text\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham               Will ü b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c977a6fe-080d-438f-a5b6-060673169c51\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will ü b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c977a6fe-080d-438f-a5b6-060673169c51')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c977a6fe-080d-438f-a5b6-060673169c51 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c977a6fe-080d-438f-a5b6-060673169c51');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d54ee19c-2961-4f12-a960-a7783035a7ed\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d54ee19c-2961-4f12-a960-a7783035a7ed')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d54ee19c-2961-4f12-a960-a7783035a7ed button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_662210d4-3831-494b-a1bb-79d3ef5b02e3\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_662210d4-3831-494b-a1bb-79d3ef5b02e3 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 5572,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"spam\",\n          \"ham\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5169,\n        \"samples\": [\n          \"K, makes sense, btw carlos is being difficult so you guys are gonna smoke while I go pick up the second batch and get gas\",\n          \"URGENT! Your mobile No *********** WON a \\u00a32,000 Bonus Caller Prize on 02/06/03! This is the 2nd attempt to reach YOU! Call 09066362220 ASAP! BOX97N7QP, 150ppm\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109",
      "metadata": {
        "id": "e7b6e631-4f0b-4aab-82b9-8898e6663109"
      },
      "source": [
        "- 클래스 분포를 확인해 보면, 데이터에 \"스팸\"보다 \"햄\"(즉, \"스팸아님\")이 훨씬 더 많이 포함되어 있음을 알 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "495a5280-9d7c-41d4-9719-64ab99056d4c",
        "outputId": "43112c20-4568-4e6a-e1b4-d7a3345c6e09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     4825\n",
            "spam     747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f773f054-0bdc-4aad-bbf6-397621bf63db",
      "metadata": {
        "id": "f773f054-0bdc-4aad-bbf6-397621bf63db"
      },
      "source": [
        "- 간단하게 하기 위해, 그리고 교육 목적으로 작은 데이터셋을 선호하기 때문에 (LLM을 더 빠르게 미세 튜닝할 수 있음), 각 클래스마다 747개의 샘플이 포함되도록 데이터 세트를 서브샘플링(언더샘플링)합니다.\n",
        "- (언더샘플링 외에도 클래스 불균형을 처리하는 여러 가지 다른 방법이 있지만 LLM에 관한 책의 범위를 벗어납니다. [`imbalanced-learn` 사용자 가이드](https://imbalanced-learn.org/stable/user_guide.html)에서 예제와 자세한 정보를 찾을 수 있습니다.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "7be4a0a2-9704-4a96-b38f-240339818688",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7be4a0a2-9704-4a96-b38f-240339818688",
        "outputId": "73bc2378-dc70-4cd4-afb3-ba5fbaf224da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label\n",
            "ham     747\n",
            "spam    747\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "def create_balanced_dataset(df):\n",
        "\n",
        "    # \"스팸\" 샘플 개수 세기\n",
        "    num_spam = df[df[\"Label\"] == \"spam\"].shape[0]\n",
        "\n",
        "    # \"스팸\" 샘플 개수와 일치하도록 \"햄\" 샘플을 무작위로 샘플링\n",
        "    ham_subset = df[df[\"Label\"] == \"ham\"].sample(num_spam, random_state=123)\n",
        "\n",
        "    # \"햄\"과 \"스팸\"을 합침\n",
        "    balanced_df = pd.concat([ham_subset, df[df[\"Label\"] == \"spam\"]])\n",
        "\n",
        "    return balanced_df\n",
        "\n",
        "\n",
        "balanced_df = create_balanced_dataset(df)\n",
        "print(balanced_df[\"Label\"].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6",
      "metadata": {
        "id": "d3fd2f5a-06d8-4d30-a2e3-230b86c559d6"
      },
      "source": [
        "- 다음으로, 문자열 클래스 레이블 \"ham\"과 \"spam\"을 정수 클래스 레이블 0과 1로 변경합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd",
      "metadata": {
        "id": "c1b10c3d-5d57-42d0-8de8-cf80a06f5ffd"
      },
      "outputs": [],
      "source": [
        "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "e6f7f062-ef4e-4020-8275-71990cab4414",
        "outputId": "728518ef-d441-422e-f538-eee0e21fb8ef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Label                                               Text\n",
              "4307      0  Awww dat is sweet! We can think of something t...\n",
              "4138      0                             Just got to  &lt;#&gt;\n",
              "4831      0  The word \"Checkmate\" in chess comes from the P...\n",
              "4461      0  This is wishing you a great day. Moji told me ...\n",
              "5440      0      Thank you. do you generally date the brothas?\n",
              "...     ...                                                ...\n",
              "5537      1  Want explicit SEX in 30 secs? Ring 02073162414...\n",
              "5540      1  ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...\n",
              "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
              "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
              "5567      1  This is the 2nd time we have tried 2 contact u...\n",
              "\n",
              "[1494 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6fdc4bde-5abc-48fa-b317-3473872aeacf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4307</th>\n",
              "      <td>0</td>\n",
              "      <td>Awww dat is sweet! We can think of something t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4138</th>\n",
              "      <td>0</td>\n",
              "      <td>Just got to  &amp;lt;#&amp;gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4831</th>\n",
              "      <td>0</td>\n",
              "      <td>The word \"Checkmate\" in chess comes from the P...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4461</th>\n",
              "      <td>0</td>\n",
              "      <td>This is wishing you a great day. Moji told me ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5440</th>\n",
              "      <td>0</td>\n",
              "      <td>Thank you. do you generally date the brothas?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5537</th>\n",
              "      <td>1</td>\n",
              "      <td>Want explicit SEX in 30 secs? Ring 02073162414...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5540</th>\n",
              "      <td>1</td>\n",
              "      <td>ASKED 3MOBILE IF 0870 CHATLINES INCLU IN FREE ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5547</th>\n",
              "      <td>1</td>\n",
              "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5566</th>\n",
              "      <td>1</td>\n",
              "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>1</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1494 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6fdc4bde-5abc-48fa-b317-3473872aeacf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6fdc4bde-5abc-48fa-b317-3473872aeacf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6fdc4bde-5abc-48fa-b317-3473872aeacf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-47e22e60-00d5-45f2-a834-be66ba11c00c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-47e22e60-00d5-45f2-a834-be66ba11c00c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-47e22e60-00d5-45f2-a834-be66ba11c00c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_f74afaf5-b43c-4a6b-a015-8f83bb29ac8c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('balanced_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_f74afaf5-b43c-4a6b-a015-8f83bb29ac8c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('balanced_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "balanced_df",
              "summary": "{\n  \"name\": \"balanced_df\",\n  \"rows\": 1494,\n  \"fields\": [\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1388,\n        \"samples\": [\n          \"chile, please! It's only a  &lt;DECIMAL&gt;  hour drive for me. I come down all the time and will be subletting feb-april for audition season.\",\n          \"I only haf msn. It's yijue@hotmail.com\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "balanced_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f",
      "metadata": {
        "id": "5715e685-35b4-4b45-a86c-8a8694de9d6f"
      },
      "source": [
        "- 데이터셋을 훈련 세트, 검증 세트, 테스트 세트로 무작위 분할하는 함수를 정의해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "uQl0Psdmx15D",
      "metadata": {
        "id": "uQl0Psdmx15D"
      },
      "outputs": [],
      "source": [
        "def random_split(df, train_frac, validation_frac):\n",
        "    # 데이터프레임 전체 섞기\n",
        "    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
        "\n",
        "    # 분할 인덱스 계산\n",
        "    train_end = int(len(df) * train_frac)\n",
        "    validation_end = train_end + int(len(df) * validation_frac)\n",
        "\n",
        "    # 데이터프레임 분할\n",
        "    train_df = df[:train_end]\n",
        "    validation_df = df[train_end:validation_end]\n",
        "    test_df = df[validation_end:]\n",
        "\n",
        "    return train_df, validation_df, test_df\n",
        "\n",
        "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
        "# 테스트 크기는 나머지에 해당하는 0.2입니다.\n",
        "\n",
        "train_df.to_csv(\"train.csv\", index=None)\n",
        "validation_df.to_csv(\"validation.csv\", index=None)\n",
        "test_df.to_csv(\"test.csv\", index=None)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094",
      "metadata": {
        "id": "a8d7a0c5-1d5f-458a-b685-3f49520b0094"
      },
      "source": [
        "## 6.3 데이터 로더 만들기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c",
      "metadata": {
        "id": "7126108a-75e7-4862-b0fb-cbf59a18bb6c"
      },
      "source": [
        "- 텍스트 메시지의 길이가 다르다는 점에 유의하세요. 배치에 여러 훈련 샘플을 결합하려면 다음 중 하나를 수행해야 합니다.\n",
        "  1. 데이터셋 또는 배치에서 가장 짧은 메시지 길이로 모든 메시지를 자릅니다.\n",
        "  2. 데이터셋 또는 배치에서 가장 긴 메시지 길이로 모든 메시지에 패딩을 추가합니다.\n",
        "\n",
        "- 옵션 2를 선택하고 데이터셋에서 가장 긴 메시지에 맞춰 모든 메시지에 패딩을 추가합니다.\n",
        "- 이를 위해 2장에서 설명한 대로 `<|endoftext|>`를 패딩 토큰으로 사용합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0829f33f-1428-4f22-9886-7fee633b3666",
      "metadata": {
        "id": "0829f33f-1428-4f22-9886-7fee633b3666"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/06.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74c3c463-8763-4cc0-9320-41c7eaad8ab7",
        "outputId": "6b6654b6-51d4-4813-81dc-f363642d7d4e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[50256]\n"
          ]
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04f582ff-68bf-450e-bd87-5fb61afe431c",
      "metadata": {
        "id": "04f582ff-68bf-450e-bd87-5fb61afe431c"
      },
      "source": [
        "- `SpamDataset` 클래스는 학습 데이터셋에서 가장 긴 시퀀스를 식별하고 다른 시퀀스에 패딩 토큰을 추가하여 해당 길이에 맞춥니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "d7791b52-af18-4ac4-afa9-b921068e383e",
      "metadata": {
        "id": "d7791b52-af18-4ac4-afa9-b921068e383e"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class SpamDataset(Dataset):\n",
        "    def __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "\n",
        "        # 텍스트 토큰화\n",
        "        self.encoded_texts = [\n",
        "            tokenizer.encode(text) for text in self.data[\"Text\"]\n",
        "        ]\n",
        "\n",
        "        if max_length is None:\n",
        "            self.max_length = self._longest_encoded_length()\n",
        "        else:\n",
        "            self.max_length = max_length\n",
        "            # max_length보다 긴 시퀀스 자르기\n",
        "            self.encoded_texts = [\n",
        "                encoded_text[:self.max_length]\n",
        "                for encoded_text in self.encoded_texts\n",
        "            ]\n",
        "\n",
        "        # 가장 긴 시퀀스에 맞춰 패딩하기\n",
        "        self.encoded_texts = [\n",
        "            encoded_text + [pad_token_id] * (self.max_length - len(encoded_text))\n",
        "            for encoded_text in self.encoded_texts\n",
        "        ]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        encoded = self.encoded_texts[index]\n",
        "        label = self.data.iloc[index][\"Label\"]\n",
        "        return (\n",
        "            torch.tensor(encoded, dtype=torch.long),\n",
        "            torch.tensor(label, dtype=torch.long)\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def _longest_encoded_length(self):\n",
        "        max_length = 0\n",
        "        for encoded_text in self.encoded_texts:\n",
        "            encoded_length = len(encoded_text)\n",
        "            if encoded_length > max_length:\n",
        "                max_length = encoded_length\n",
        "        return max_length\n",
        "        # 참고: 이 메서드를 구현하는 더 파이썬적인 버전은\n",
        "        # 다음과 같으며, 다음 장에서도 사용됩니다.\n",
        "        # return max(len(encoded_text) for encoded_text in self.encoded_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "uzj85f8ou82h",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzj85f8ou82h",
        "outputId": "81c26405-10df-4fce-f727-b009511193ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120\n"
          ]
        }
      ],
      "source": [
        "train_dataset = SpamDataset(\n",
        "    csv_file=\"train.csv\",\n",
        "    max_length=None,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "print(train_dataset.max_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60",
      "metadata": {
        "id": "15bdd932-97eb-4b88-9cf9-d766ea4c3a60"
      },
      "source": [
        "- 또한 검증 세트와 테스트 세트를 가장 긴 훈련 시퀀스에 맞춰 패딩합니다.\n",
        "- 검증 세트와 테스트 세트 샘플 중 가장 긴 훈련 세트 샘플보다 긴 샘플은 `SpamDataset` 코드에서 `encoded_text[:self.max_length]`를 통해 잘린다는 점에 유의하세요.\n",
        "- 이 동작은 완전히 선택 사항이며, 검증 세트와 테스트 세트의 경우 모두 `max_length=None`으로 설정해도 잘 작동합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e",
      "metadata": {
        "id": "bb0c502d-a75e-4248-8ea0-196e2b00c61e"
      },
      "outputs": [],
      "source": [
        "val_dataset = SpamDataset(\n",
        "    csv_file=\"validation.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "test_dataset = SpamDataset(\n",
        "    csv_file=\"test.csv\",\n",
        "    max_length=train_dataset.max_length,\n",
        "    tokenizer=tokenizer\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20170d89-85a0-4844-9887-832f5d23432a",
      "metadata": {
        "id": "20170d89-85a0-4844-9887-832f5d23432a"
      },
      "source": [
        "- 다음으로, 데이터셋을 사용하여 데이터 로더를 만듭니다. 이는 이전 장에서 데이터 로더를 생성하는 것과 유사합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64bcc349-205f-48f8-9655-95ff21f5e72f",
      "metadata": {
        "id": "64bcc349-205f-48f8-9655-95ff21f5e72f"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/07.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542",
      "metadata": {
        "id": "8681adc0-6f02-4e75-b01a-a6ab75d05542"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "num_workers = 0\n",
        "batch_size = 8\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    dataset=train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=True,\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    dataset=val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    dataset=test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=num_workers,\n",
        "    drop_last=False,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57",
      "metadata": {
        "id": "ab7335db-e0bb-4e27-80c5-eea11e593a57"
      },
      "source": [
        "- 검증 단계로서, 데이터 로더를 반복하고 각 배치에 120개의 토큰으로 구성된 8개의 훈련 샘플이 포함되어 있는지 확인합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dee6882-4c3a-4964-af15-fa31f86ad047",
        "outputId": "7fa8f811-05b3-471e-ff93-df9eaa217b1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 세트 로더:\n",
            "입력 배치 차원: torch.Size([8, 120])\n",
            "레이블 배치 차원 torch.Size([8])\n"
          ]
        }
      ],
      "source": [
        "print(\"훈련 세트 로더:\")\n",
        "for input_batch, target_batch in train_loader:\n",
        "    pass\n",
        "\n",
        "print(\"입력 배치 차원:\", input_batch.shape)\n",
        "print(\"레이블 배치 차원\", target_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1",
      "metadata": {
        "id": "5cdd7947-7039-49bf-8a5e-c0a2f4281ca1"
      },
      "source": [
        "- 마지막으로, 각 데이터셋의 총 배치 수를 출력해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "IZfw-TYD2zTj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZfw-TYD2zTj",
        "outputId": "0f9ab651-0670-42a0-de6f-0b8ecf72c2fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "130개 훈련 배치\n",
            "19개 검증 배치\n",
            "38개 테스트 배치\n"
          ]
        }
      ],
      "source": [
        "print(f\"{len(train_loader)}개 훈련 배치\")\n",
        "print(f\"{len(val_loader)}개 검증 배치\")\n",
        "print(f\"{len(test_loader)}개 테스트 배치\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c",
      "metadata": {
        "id": "d1c4f61a-5f5d-4b3b-97cf-151b617d1d6c"
      },
      "source": [
        "## 6.4 사전 훈련된 가중치로 모델 초기화하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208",
      "metadata": {
        "id": "97e1af8b-8bd1-4b44-8b8b-dc031496e208"
      },
      "source": [
        "- 이 섹션에서는 이전 챕터에서 작업했던 사전 훈련된 모델을 초기화합니다.\n",
        "\n",
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/08.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2992d779-f9fb-4812-a117-553eb790a5a9",
      "metadata": {
        "id": "2992d779-f9fb-4812-a117-553eb790a5a9"
      },
      "outputs": [],
      "source": [
        "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
        "INPUT_PROMPT = \"Every effort moves\"\n",
        "\n",
        "BASE_CONFIG = {\n",
        "    \"vocab_size\": 50257,     # 어휘사전 크기\n",
        "    \"context_length\": 1024,  # 문맥 길이\n",
        "    \"drop_rate\": 0.0,        # 드롭아웃 비율\n",
        "    \"qkv_bias\": True         # 쿼리-키-값 편향\n",
        "}\n",
        "\n",
        "model_configs = {\n",
        "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
        "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
        "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
        "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
        "}\n",
        "\n",
        "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
        "\n",
        "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
        "    f\"데이터셋 길이 {train_dataset.max_length}가 모델의 문맥 \"\n",
        "    f\"길이 {BASE_CONFIG['context_length']}를 초과합니다. `max_length={BASE_CONFIG['context_length']}`로 \"\n",
        "    f\"데이터 셋을 다시 초기화하십시오.\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "81MBJyHfTl0a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81MBJyHfTl0a",
        "outputId": "6cc21674-8b50-4f6a-e6af-a788025f96a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-30 02:29:32--  https://bit.ly/4jZL2Gr\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch06/01_main-chapter-code/gpt_download.py [following]\n",
            "--2025-10-30 02:29:32--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch06/01_main-chapter-code/gpt_download.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6333 (6.2K) [text/plain]\n",
            "Saving to: ‘gpt_download.py’\n",
            "\n",
            "gpt_download.py     100%[===================>]   6.18K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-30 02:29:33 (76.8 MB/s) - ‘gpt_download.py’ saved [6333/6333]\n",
            "\n",
            "--2025-10-30 02:29:33--  https://bit.ly/4esl8dj\n",
            "Resolving bit.ly (bit.ly)... 67.199.248.11, 67.199.248.10\n",
            "Connecting to bit.ly (bit.ly)|67.199.248.11|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch06/01_main-chapter-code/previous_chapters.py [following]\n",
            "--2025-10-30 02:29:33--  https://raw.githubusercontent.com/rickiepark/llm-from-scratch/refs/heads/main/ch06/01_main-chapter-code/previous_chapters.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 12067 (12K) [text/plain]\n",
            "Saving to: ‘previous_chapters.py’\n",
            "\n",
            "previous_chapters.p 100%[===================>]  11.78K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-10-30 02:29:33 (132 MB/s) - ‘previous_chapters.py’ saved [12067/12067]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://bit.ly/4jZL2Gr -O gpt_download.py\n",
        "!wget https://bit.ly/4esl8dj -O previous_chapters.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "022a649a-44f5-466c-8a8e-326c063384f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "022a649a-44f5-466c-8a8e-326c063384f5",
        "outputId": "c58f8412-edc7-43ba-eb63-439a61c6c384"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "checkpoint: 100%|██████████| 77.0/77.0 [00:00<00:00, 56.3kiB/s]\n",
            "encoder.json: 100%|██████████| 1.04M/1.04M [00:01<00:00, 619kiB/s]\n",
            "hparams.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 254kiB/s]\n",
            "model.ckpt.data-00000-of-00001: 100%|██████████| 498M/498M [02:31<00:00, 3.29MiB/s]\n",
            "model.ckpt.index: 100%|██████████| 5.21k/5.21k [00:00<00:00, 8.92MiB/s]\n",
            "model.ckpt.meta: 100%|██████████| 471k/471k [00:01<00:00, 381kiB/s]\n",
            "vocab.bpe: 100%|██████████| 456k/456k [00:01<00:00, 438kiB/s]\n"
          ]
        }
      ],
      "source": [
        "from gpt_download import download_and_load_gpt2\n",
        "from previous_chapters import GPTModel, load_weights_into_gpt\n",
        "\n",
        "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
        "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
        "\n",
        "model = GPTModel(BASE_CONFIG)\n",
        "load_weights_into_gpt(model, params)\n",
        "model.eval();"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ab8e056c-abe0-415f-b34d-df686204259e",
      "metadata": {
        "id": "ab8e056c-abe0-415f-b34d-df686204259e"
      },
      "source": [
        "- 모델이 제대로 로드되었는지 확인하기 위해 일관된 텍스트를 생성하는지 다시 한번 확인해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8ac25ff-74b1-4149-8dc5-4c429d464330",
        "outputId": "58fdaddc-543c-406b-a99c-3da81f4760cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Every effort moves you forward.\n",
            "\n",
            "The first step is to understand the importance of your work\n"
          ]
        }
      ],
      "source": [
        "from previous_chapters import (\n",
        "    generate_text_simple,\n",
        "    text_to_token_ids,\n",
        "    token_ids_to_text\n",
        ")\n",
        "\n",
        "\n",
        "text_1 = \"Every effort moves you\"\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_1, tokenizer),\n",
        "    max_new_tokens=15,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69162550-6a02-4ece-8db1-06c71d61946f",
      "metadata": {
        "id": "69162550-6a02-4ece-8db1-06c71d61946f"
      },
      "source": [
        "- 모델을 분류기로 미세 튜닝하기 전에 프롬프트를 통해 스팸 메시지를 분류할 수 있는지 확인해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94224aa9-c95a-4f8a-a420-76d01e3a800c",
        "outputId": "165aea67-dff3-4d60-beb2-25311f8a5be4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.'\n",
            "\n",
            "The following text 'spam'? Answer with 'yes' or 'no': 'You are a winner\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
        "    \" 'You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
        ")\n",
        "\n",
        "token_ids = generate_text_simple(\n",
        "    model=model,\n",
        "    idx=text_to_token_ids(text_2, tokenizer),\n",
        "    max_new_tokens=23,\n",
        "    context_size=BASE_CONFIG[\"context_length\"]\n",
        ")\n",
        "\n",
        "print(token_ids_to_text(token_ids, tokenizer))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016",
      "metadata": {
        "id": "1ce39ed0-2c77-410d-8392-dd15d4b22016"
      },
      "source": [
        "- 보시다시피, 이 모델은 지시 사항을 잘 따르지 못합니다.\n",
        "- 이는 모델이 사전 학습만 되었고 지시 미세 튜닝되지 않았기 때문에 예상되는 결과입니다 (지시 미세 튜닝은 다음 장에서 다룹니다).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522",
      "metadata": {
        "id": "4c9ae440-32f9-412f-96cf-fd52cc3e2522"
      },
      "source": [
        "## 6.5 분류 헤드 추가하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0",
      "metadata": {
        "id": "d6e9d66f-76b2-40fc-9ec5-3f972a8db9c0"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/09.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "217bac05-78df-4412-bd80-612f8061c01d",
      "metadata": {
        "id": "217bac05-78df-4412-bd80-612f8061c01d"
      },
      "source": [
        "- 이 절에서는 사전 훈련된 LLM을 분류 미세 튜닝에 사용할 수 있도록 수정합니다.\n",
        "- 먼저 모델 구조를 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b23aff91-6bd0-48da-88f6-353657e6c981",
        "outputId": "05d7672b-17f0-4422-b0d1-35956a333b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPTModel(\n",
            "  (tok_emb): Embedding(50257, 768)\n",
            "  (pos_emb): Embedding(1024, 768)\n",
            "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
            "  (trf_blocks): Sequential(\n",
            "    (0): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (1): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (2): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (3): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (4): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (5): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (6): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (7): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (8): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (9): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (10): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "    (11): TransformerBlock(\n",
            "      (att): MultiHeadAttention(\n",
            "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (dropout): Dropout(p=0.0, inplace=False)\n",
            "      )\n",
            "      (ff): FeedForward(\n",
            "        (layers): Sequential(\n",
            "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (1): GELU()\n",
            "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "        )\n",
            "      )\n",
            "      (norm1): LayerNorm()\n",
            "      (norm2): LayerNorm()\n",
            "      (drop_resid): Dropout(p=0.0, inplace=False)\n",
            "    )\n",
            "  )\n",
            "  (final_norm): LayerNorm()\n",
            "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d",
      "metadata": {
        "id": "3f640a76-dd00-4769-9bc8-1aed0cec330d"
      },
      "source": [
        "- 위에서 4장에서 구현한 구조가 깔끔하게 정리되어 있는 것을 볼 수 있습니다.\n",
        "- 목표는 출력 층 교체하고 미세 튜닝하는 것입니다.\n",
        "- 이를 위해 먼저 모델을 동결합니다. 즉, 모든 층을 훈련 불가능하게 만듭니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "fkMWFl-0etea",
      "metadata": {
        "id": "fkMWFl-0etea"
      },
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72155f83-87d9-476a-a978-a15aa2d44147",
      "metadata": {
        "id": "72155f83-87d9-476a-a978-a15aa2d44147"
      },
      "source": [
        "- 그런 다음 출력 층(`model.out_head`)을 교체합니다. 이 층은 입력을 50,257차원(어휘사전 크기)으로 매핑합니다.\n",
        "- 이진 분류(\"스팸\" 및 \"스팸아님\"의 두 클래스 예측)를 위해 모델을 미세 튜닝하기 때문에 아래와 같이 출력 층를 교체할 수 있으며 기본적으로 학습 가능합니다.\n",
        "- 아래 코드를 더 일반적으로 유지하기 위해 `BASE_CONFIG[\"emb_dim\"]`(\"gpt2-small (124M)\" 모델에서 768과 같음)을 사용하는 것에 유의하세요.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb",
      "metadata": {
        "id": "7e759fa0-0f69-41be-b576-17e5f20e04cb"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(123)\n",
        "\n",
        "num_classes = 2\n",
        "model.out_head = torch.nn.Linear(in_features=BASE_CONFIG[\"emb_dim\"], out_features=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30be5475-ae77-4f97-8f3e-dec462b1339f",
      "metadata": {
        "id": "30be5475-ae77-4f97-8f3e-dec462b1339f"
      },
      "source": [
        "- 기술적으로 출력 층만 훈련하는 것으로 충분합니다.\n",
        "- 하지만, [대규모 언어 모델 미세 튜닝](https://magazine.sebastianraschka.com/p/finetuning-large-language-models)에서 확인했듯이, 실험 결과 추가 층을 미세 튜닝하면 성능이 눈에 띄게 향상되는 것으로 나타났습니다.\n",
        "- 따라서 마지막 트랜스포머 블록과 마지막 트랜스포머 블록을 출력 층에 연결하는 최종 `LayerNorm` 모듈도 훈련 가능하도록 설정합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10",
      "metadata": {
        "id": "0be7c1eb-c46c-4065-8525-eea1b8c66d10"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/10.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7",
      "metadata": {
        "id": "2aedc120-5ee3-48f6-92f2-ad9304ebcdc7"
      },
      "outputs": [],
      "source": [
        "for param in model.trf_blocks[-1].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.final_norm.parameters():\n",
        "    param.requires_grad = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e",
      "metadata": {
        "id": "f012b899-8284-4d3a-97c0-8a48eb33ba2e"
      },
      "source": [
        "- 이전 장에서처럼 이 모델을 비슷하게 사용할 수 있습니다.\n",
        "- 예를 들어, 텍스트 입력을 제공해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f645c06a-7df6-451c-ad3f-eafb18224ebc",
        "outputId": "1311d536-1a89-4197-be16-40969a36071d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "입력: tensor([[5211,  345,  423,  640]])\n",
            "입력 차원: torch.Size([1, 4])\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.encode(\"Do you have time\")\n",
        "inputs = torch.tensor(inputs).unsqueeze(0)\n",
        "print(\"입력:\", inputs)\n",
        "print(\"입력 차원:\", inputs.shape) # shape: (배치 크기, 토큰 수)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b",
      "metadata": {
        "id": "fbbf8481-772d-467b-851c-a62b86d0cb1b"
      },
      "source": [
        "- 이전 장과 다른 점은 출력 차원이 50,257개가 아니라 2개라는 것입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48dc84f1-85cc-4609-9cee-94ff539f00f4",
        "outputId": "d8e2edf6-2a23-44ea-cac1-9b7a30d0fdfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "출력:\n",
            " tensor([[[-1.5854,  0.9904],\n",
            "         [-3.7235,  7.4548],\n",
            "         [-2.2661,  6.6049],\n",
            "         [-3.5983,  3.9902]]])\n",
            "출력 차원: torch.Size([1, 4, 2])\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad():\n",
        "    outputs = model(inputs)\n",
        "\n",
        "print(\"출력:\\n\", outputs)\n",
        "print(\"출력 차원:\", outputs.shape) # shape: (배치 크기, 토큰 수, 클래스 수)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "75430a01-ef9c-426a-aca0-664689c4f461",
      "metadata": {
        "id": "75430a01-ef9c-426a-aca0-664689c4f461"
      },
      "source": [
        "- 이전 장에서 논의했듯이 각 입력 토큰에 대해 하나의 출력 벡터가 있습니다.\n",
        "- 모델에 4개의 입력 토큰이 있는 텍스트 샘플을 제공했으므로 출력은 2차원 출력 벡터 4개로 구성됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b",
      "metadata": {
        "id": "7df9144f-6817-4be4-8d4b-5d4dadfe4a9b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/11.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a",
      "metadata": {
        "id": "e3bb8616-c791-4f5c-bac0-5302f663e46a"
      },
      "source": [
        "- 3장에서는 각 입력 토큰을 다른 모든 입력 토큰에 연결하는 어텐션 메커니즘에 대해 논의했습니다.\n",
        "- 3장에서는 GPT와 같은 모델에 사용되는 코잘 어텐션 마스크도 소개했습니다. 코잘 마스크는 현재 토큰이 현재 및 이전 토큰 위치만 참조하도록 만듭니다.\n",
        "- 코잘 어텐션 메커니즘을 기반으로, 4번째 (마지막) 토큰이 다른 모든 토큰에 대한 정보를 포함하는 유일한 토큰이기 때문에 모든 토큰 중에서 가장 많은 정보를 담고 있습니다.\n",
        "- 따라서 우리는 이 마지막 토큰에 특히 관심이 있으며, 스팸 분류 작업을 위해 미세 튜닝할 것입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49383a8c-41d5-4dab-98f1-238bca0c2ed7",
        "outputId": "85be878b-e93e-467b-fd88-2c74489b491e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "마지막 출력 토큰: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"마지막 출력 토큰:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b",
      "metadata": {
        "id": "8df08ae0-e664-4670-b7c5-8a2280d9b41b"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/12.webp\" width=400px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c",
      "metadata": {
        "id": "32aa4aef-e1e9-491b-9adf-5aa973e59b8c"
      },
      "source": [
        "## 6.6 분류 손실과 정확도 계산하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33",
      "metadata": {
        "id": "669e1fd1-ace8-44b4-b438-185ed0ba8b33"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/13.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3",
      "metadata": {
        "id": "7a7df4ee-0a34-4a4d-896d-affbbf81e0b3"
      },
      "source": [
        "- 손실 계산을 설명하기 전에 모델 출력이 어떻게 클래스 레이블로 변환되는지 간략하게 살펴보겠습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e",
      "metadata": {
        "id": "557996dd-4c6b-49c4-ab83-f60ef7e1d69e"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/14.webp\" width=800px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c77faab1-3461-4118-866a-6171f2b89aa0",
        "outputId": "87887d76-5fe7-45a5-a582-d292da6bd5b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "마지막 출력 토큰: tensor([[-3.5983,  3.9902]])\n"
          ]
        }
      ],
      "source": [
        "print(\"마지막 출력 토큰:\", outputs[:, -1, :])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d",
      "metadata": {
        "id": "7edd71fa-628a-4d00-b81d-6d8bcb2c341d"
      },
      "source": [
        "- 5장과 유사하게, `softmax` 함수를 통해 출력(로짓)을 확률 점수로 변환한 다음 `argmax` 함수를 통해 가장 큰 확률 값의 인덱스를 얻습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b81efa92-9be1-4b9e-8790-ce1fc7b17f01",
        "outputId": "bc3e82f5-3b3e-4c6a-c1e3-6b814601a716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 레이블: 1\n"
          ]
        }
      ],
      "source": [
        "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
        "label = torch.argmax(probas)\n",
        "print(\"클래스 레이블:\", label.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "414a6f02-307e-4147-a416-14d115bf8179",
      "metadata": {
        "id": "414a6f02-307e-4147-a416-14d115bf8179"
      },
      "source": [
        "- 5장에서 설명했듯이 소프트맥스 함수는 여기서는 선택 사항입니다. 가장 큰 출력이 가장 큰 확률 점수에 해당하기 때문입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9f9ad66-4969-4501-8239-3ccdb37e71a2",
        "outputId": "89d3f068-e461-454d-d969-f12131feac98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "클래스 레이블: 1\n"
          ]
        }
      ],
      "source": [
        "logits = outputs[:, -1, :]\n",
        "label = torch.argmax(logits)\n",
        "print(\"클래스 레이블:\", label.item())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505",
      "metadata": {
        "id": "dcb20d3a-cbba-4ab1-8584-d94e16589505"
      },
      "source": [
        "- 이 개념을 적용하여 소위 분류 정확도를 계산할 수 있습니다. 분류 정확도는 주어진 데이터셋에서 정확하게 예측한 백분율입니다.\n",
        "- 분류 정확도를 계산하기 위해 앞서 설명한 `argmax` 기반 예측 코드를 데이터셋에 있는 모든 샘플에 적용하고 다음과 같이 정확한 예측의 비율을 계산할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23",
      "metadata": {
        "id": "3ecf9572-aed0-4a21-9c3b-7f9f2aec5f23"
      },
      "outputs": [],
      "source": [
        "def calc_accuracy_loader(data_loader, model, device, num_batches=None):\n",
        "    model.eval()\n",
        "    correct_predictions, num_examples = 0, 0\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                logits = model(input_batch)[:, -1, :]  # 마지막 출력 토큰의 로짓\n",
        "            predicted_labels = torch.argmax(logits, dim=-1)\n",
        "\n",
        "            num_examples += predicted_labels.shape[0]\n",
        "            correct_predictions += (predicted_labels == target_batch).sum().item()\n",
        "        else:\n",
        "            break\n",
        "    return correct_predictions / num_examples"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7165fe46-a284-410b-957f-7524877d1a1a",
      "metadata": {
        "id": "7165fe46-a284-410b-957f-7524877d1a1a"
      },
      "source": [
        "- 여러 데이터셋에 대한 분류 정확도를 계산하기 위해 함수를 적용해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "390e5255-8427-488c-adef-e1c10ab4fb26",
        "outputId": "51d53890-ae1d-4c10-cfba-c01e421f3a96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 정확도: 46.25%\n",
            "검증 정확도: 45.00%\n",
            "테스트 정확도: 48.75%\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# 참고:\n",
        "# 다음 줄의 주석 처리를 제거하면 코드가 애플 실리콘 칩에서 실행할 수 있습니다.\n",
        "# 애플 CPU보다 약 2배 빠릅니다(M3 맥북 에어에서 측정).\n",
        "# 이 글을 쓰는 시점에서 파이토치 2.4에서는 CPU와 MPS를 통해 얻은 결과가 동일했습니다.\n",
        "# 그러나 이전 버전의 파이토치에서는 MPS를 사용할 때 다른 결과가 나타날 수 있습니다.\n",
        "\n",
        "#if torch.cuda.is_available():\n",
        "#    device = torch.device(\"cuda\")\n",
        "#elif torch.backends.mps.is_available():\n",
        "#    device = torch.device(\"mps\")\n",
        "#else:\n",
        "#    device = torch.device(\"cpu\")\n",
        "#print(f\"실행 장치: {device}\")\n",
        "\n",
        "model.to(device) # nn.Module 클래스의 경우 model = model.to(device) 할당문이 필요하지 않습니다.\n",
        "\n",
        "torch.manual_seed(123) # 데이터 로더에서 셔플링하기 때문에 재현성을 위해\n",
        "\n",
        "train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=10)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=10)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device, num_batches=10)\n",
        "\n",
        "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
        "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
        "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30345e2a-afed-4d22-9486-f4010f90a871",
      "metadata": {
        "id": "30345e2a-afed-4d22-9486-f4010f90a871"
      },
      "source": [
        "- 예상대로 모델을 미세 튜닝하지 않았기 때문에 예측 정확도가 그리 좋지 않습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328",
      "metadata": {
        "id": "4f4a9d15-8fc7-48a2-8734-d92a2f265328"
      },
      "source": [
        "- 미세 튜닝(훈련)을 시작하기 전에 먼저 훈련 중에 최적화하려는 손실 함수를 정의해야 합니다.\n",
        "- 목표는 모델의 스팸 분류 정확도를 최대화하는 것이지만 분류 정확도는 미분 가능한 함수가 아닙니다.\n",
        "- 따라서 분류 정확도를 최대화하는 대신, 크로스 엔트로피 손실을 최소화합니다 (무료 강의 [Introduction to Deep Learning](https://sebastianraschka.com/blog/2021/dl-course.html#l08-multinomial-logistic-regression--softmax-regression) 8강에서 이 주제에 대해 자세히 알아볼 수 있습니다)\n",
        "\n",
        "- `calc_loss_batch` 함수는 5장과 동일하지만 모든 토큰 `model(input_batch)` 대신 마지막 토큰 `model(input_batch)[:, -1, :]`을 최적화하는 데에만 관심이 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4",
      "metadata": {
        "id": "2f1e9547-806c-41a9-8aba-3b2822baabe4"
      },
      "outputs": [],
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "    input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "    logits = model(input_batch)[:, -1, :]  # 마지막 출력 토큰의 로짓\n",
        "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a013aab9-f854-4866-ad55-5b8350adb50a",
      "metadata": {
        "id": "a013aab9-f854-4866-ad55-5b8350adb50a"
      },
      "source": [
        "`calc_loss_loader`는 5장과 완전히 동일합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "b7b83e10-5720-45e7-ac5e-369417ca846b",
      "metadata": {
        "id": "b7b83e10-5720-45e7-ac5e-369417ca846b"
      },
      "outputs": [],
      "source": [
        "# 5장과 동일\n",
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "    total_loss = 0.\n",
        "    if len(data_loader) == 0:\n",
        "        return float(\"nan\")\n",
        "    elif num_batches is None:\n",
        "        num_batches = len(data_loader)\n",
        "    else:\n",
        "        # num_batches가 데이터 로더의 배치 수를 초과하는 경우\n",
        "        # 데이터 로더의 총 배치 수와 일치하도록 배치 수를 줄입니다.\n",
        "        num_batches = min(num_batches, len(data_loader))\n",
        "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "        if i < num_batches:\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            total_loss += loss.item()\n",
        "        else:\n",
        "            break\n",
        "    return total_loss / num_batches"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "56826ecd-6e74-40e6-b772-d3541e585067",
      "metadata": {
        "id": "56826ecd-6e74-40e6-b772-d3541e585067"
      },
      "source": [
        "- `calc_closs_loader`를 사용하여 훈련을 시작하기 전 초기 훈련, 검증 및 테스트 세트 손실을 계산합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6f00e53-5beb-4e64-b147-f26fd481c6ff",
        "outputId": "56e5b0e2-978e-4ced-f28e-08082e5a0704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 손실: 2.453\n",
            "검증 손실: 2.583\n",
            "테스트 손실: 2.322\n"
          ]
        }
      ],
      "source": [
        "with torch.no_grad(): # 효율성을 위해 그레이디언트 추적을 비활성화합니다. 아직 훈련하지 않기 때문입니다.\n",
        "    train_loss = calc_loss_loader(train_loader, model, device, num_batches=5)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
        "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
        "\n",
        "print(f\"훈련 손실: {train_loss:.3f}\")\n",
        "print(f\"검증 손실: {val_loss:.3f}\")\n",
        "print(f\"테스트 손실: {test_loss:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d",
      "metadata": {
        "id": "e04b980b-e583-4f62-84a0-4edafaf99d5d"
      },
      "source": [
        "- 다음 섹션에서는 손실 값과 결과적으로 분류 정확도를 개선하기 위해 모델을 훈련합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "456ae0fd-6261-42b4-ab6a-d24289953083",
      "metadata": {
        "id": "456ae0fd-6261-42b4-ab6a-d24289953083"
      },
      "source": [
        "## 6.7 지도 학습 데이터로 모델 미세 튜닝하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a9b099b-0829-4f72-8a2b-4363e3497026",
      "metadata": {
        "id": "6a9b099b-0829-4f72-8a2b-4363e3497026"
      },
      "source": [
        "- 이 절에서는 모델의 분류 정확도를 향상시키기 위한 훈련 함수를 정의하고 사용합니다.\n",
        "- 아래 `train_classifier_simple` 함수는 5장에서 모델 사전 훈련에 사용했던 `train_model_simple` 함수와 거의 동일합니다.\n",
        "- 단 두 가지 차이점은 다음과 같습니다.\n",
        "  1. 토큰 수 대신 학습된 샘플 수(`examples_seen`)를 추적합니다.\n",
        "  2. 각 에포크 다음에 샘플 텍스트를 출력하는 대신 정확도를 계산합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12",
      "metadata": {
        "id": "979b6222-1dc2-4530-9d01-b6b04fe3de12"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/15.webp\" width=600px>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "Csbr60to50FL",
      "metadata": {
        "id": "Csbr60to50FL"
      },
      "outputs": [],
      "source": [
        "# 5장의 `train_model_simple`과 전체적으로 동일\n",
        "def train_classifier_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                            eval_freq, eval_iter):\n",
        "    # 손실 및 처리한 샘플 수를 위한 리스트 초기화\n",
        "    train_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
        "    examples_seen, global_step = 0, -1\n",
        "\n",
        "    # 메인 학습 루프\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # 모델을 훈련 모드로 설정\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # 이전 배치 반복에서 얻은 손실의 그레이디언트 재설정\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # 손실 그레이디언트 계산\n",
        "            optimizer.step() # 손실 그레이디언트를 사용하여 모델 가중치 업데이트\n",
        "            examples_seen += input_batch.shape[0] # 새로 추가: 토큰 대신 샘플 추적\n",
        "            global_step += 1\n",
        "\n",
        "            # 선택적 평가 단계\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                print(f\"에포크 {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"훈련 손실 {train_loss:.3f}, 검증 손실 {val_loss:.3f}\")\n",
        "\n",
        "        # 각 에포크 후 정확도 계산\n",
        "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "        print(f\"훈련 정확도: {train_accuracy*100:.2f}% | \", end=\"\")\n",
        "        print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
        "        train_accs.append(train_accuracy)\n",
        "        val_accs.append(val_accuracy)\n",
        "\n",
        "    return train_losses, val_losses, train_accs, val_accs, examples_seen"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9624cb30-3e3a-45be-b006-c00475b58ae8",
      "metadata": {
        "id": "9624cb30-3e3a-45be-b006-c00475b58ae8"
      },
      "source": [
        "- `evaluate_model` 함수는 `train_classifier_simple` 에서 사용되며 5장에서 사용한 것과 동일합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab",
      "metadata": {
        "id": "bcc7bc04-6aa6-4516-a147-460e2f466eab"
      },
      "outputs": [],
      "source": [
        "# 5장과 동일\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9",
      "metadata": {
        "id": "e807bfe9-364d-46b2-9e25-3b000c3ef6f9"
      },
      "source": [
        "- M3 맥북 에어 노트북 컴퓨터에서는 훈련 시간이 약 5분 정도 소요되며 V100 또는 A100 GPU에서는 30초 미만이 소요됩니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "X7kU3aAj7vTJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7kU3aAj7vTJ",
        "outputId": "0dbbcd69-32df-4f47-90f1-1beb0d2d8f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "에포크 1 (Step 000000): 훈련 손실 2.153, 검증 손실 2.392\n",
            "에포크 1 (Step 000050): 훈련 손실 0.617, 검증 손실 0.637\n",
            "에포크 1 (Step 000100): 훈련 손실 0.523, 검증 손실 0.557\n",
            "훈련 정확도: 70.00% | 검증 정확도: 72.50%\n",
            "에포크 2 (Step 000150): 훈련 손실 0.561, 검증 손실 0.489\n",
            "에포크 2 (Step 000200): 훈련 손실 0.419, 검증 손실 0.397\n",
            "에포크 2 (Step 000250): 훈련 손실 0.409, 검증 손실 0.353\n",
            "훈련 정확도: 82.50% | 검증 정확도: 85.00%\n",
            "에포크 3 (Step 000300): 훈련 손실 0.333, 검증 손실 0.320\n",
            "에포크 3 (Step 000350): 훈련 손실 0.340, 검증 손실 0.306\n",
            "훈련 정확도: 90.00% | 검증 정확도: 90.00%\n",
            "에포크 4 (Step 000400): 훈련 손실 0.136, 검증 손실 0.200\n",
            "에포크 4 (Step 000450): 훈련 손실 0.153, 검증 손실 0.132\n",
            "에포크 4 (Step 000500): 훈련 손실 0.222, 검증 손실 0.137\n",
            "훈련 정확도: 100.00% | 검증 정확도: 97.50%\n",
            "에포크 5 (Step 000550): 훈련 손실 0.207, 검증 손실 0.143\n",
            "에포크 5 (Step 000600): 훈련 손실 0.083, 검증 손실 0.074\n",
            "훈련 정확도: 100.00% | 검증 정확도: 97.50%\n",
            "훈련 소요 시간: 1.00분\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
        "\n",
        "num_epochs = 5\n",
        "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=50, eval_iter=5,\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "execution_time_minutes = (end_time - start_time) / 60\n",
        "print(f\"훈련 소요 시간: {execution_time_minutes:.2f}분\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1261bf90-3ce7-4591-895a-044a05538f30",
      "metadata": {
        "id": "1261bf90-3ce7-4591-895a-044a05538f30"
      },
      "source": [
        "- 5장과 유사하게, 맷플롯립을 사용하여 훈련 및 검증 세트에 대한 손실 함수를 그립니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "cURgnDqdCeka",
      "metadata": {
        "id": "cURgnDqdCeka"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "\n",
        "    # 훈련 및 검증 손실을 에포크에 따라 그립니다.\n",
        "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
        "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(label.capitalize())\n",
        "    ax1.legend()\n",
        "\n",
        "    # 처리한 샘플 수를 위해 두 번째 x축을 만듭니다.\n",
        "    ax2 = ax1.twiny()  # 동일한 y축을 공유하는 두 번째 x축을 만듭니다.\n",
        "    ax2.plot(examples_seen, train_values, alpha=0)  # 눈금 정렬을 위한 보이지 않는 그래프\n",
        "    ax2.set_xlabel(\"Examples seen\")\n",
        "\n",
        "    fig.tight_layout()  # 공간을 확보하기 위해 레이아웃을 조정합니다.\n",
        "    plt.savefig(f\"{label}-plot.pdf\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "OIqRt466DiGk",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "OIqRt466DiGk",
        "outputId": "69efd5bf-a740-4e6a-d766-cbc397d91a8a"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc",
      "metadata": {
        "id": "dbd28174-1836-44ba-b6c0-7e0be774fadc"
      },
      "source": [
        "- 기울기가 아래쪽으로 향하고 있으므로 모델이 잘 학습하고 있음을 알 수 있습니다.\n",
        "- 또한, 훈련 손실과 검증 손실이 매우 가깝다는 사실은 모델이 훈련 데이터에 과대적합되는 경향이 없음을 나타냅니다.\n",
        "- 마찬가지로, 아래에서 정확도를 그래프로 표시할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "yz8BIsaF0TUo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "yz8BIsaF0TUo",
        "outputId": "52638e06-3613-4c90-85e9-c0b023f6e0d8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAEiCAYAAADONmoUAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXQdJREFUeJzt3XlYVNX/wPH3DDjsqyCCIqLirogbYW65hEskZmlmiUv601wz0yz3FsrKLDVNLW1zT81vuES47ysqLuSCogi4y6JsM/f3x+ToCCqD6CB8Xs8zzzNz7rnnfuaIfLj3nnuOSlEUBSGEEEI8dWpzByCEEEKUVJKEhRBCCDORJCyEEEKYiSRhIYQQwkwkCQshhBBmIklYCCGEMBNJwkIIIYSZSBIWQgghzESSsBBCCGEmkoSFEHlq2bIlw4cPN3cYQhRrkoSFeEJ69eqFSqXK9WrXrp25QxNCFBGW5g5AiOKsXbt2zJ8/36jMysrKTNEIIYoaORMW4gmysrKibNmyRi8XFxcANm3ahEajYevWrYb6U6ZMoUyZMiQnJwOwbt06mjZtirOzM6VLl+all17i9OnThvpnz55FpVKxdOlSmjVrho2NDY0aNeLff/9l7969NGzYEHt7e9q3b8/ly5cN+/Xq1YvQ0FAmTZqEu7s7jo6ODBgwgKysrAd+l8zMTEaOHEm5cuWws7MjMDCQTZs2GbafO3eOkJAQXFxcsLOzo1atWqxZs+aB7X3//ff4+flhbW2Nh4cHr776qmGbTqcjPDwcX19fbGxs8Pf3Z/ny5Ub7x8TE0L59e+zt7fHw8OCtt97iypUrhu0tW7Zk6NChjBo1CldXV8qWLcvEiRMfGI8Q5iBJWAgzuXPP9a233uLmzZscPHiQcePGMW/ePDw8PABIT09nxIgR7Nu3j6ioKNRqNZ07d0an0xm1NWHCBMaOHcuBAwewtLTkjTfeYNSoUXz77bds3bqVU6dOMX78eKN9oqKiOH78OJs2bWLRokWsWLGCSZMmPTDewYMHs3PnThYvXszhw4d57bXXaNeuHSdPngRg0KBBZGZmsmXLFo4cOcIXX3yBvb19nm3t27ePoUOHMnnyZGJjY1m3bh3Nmzc3bA8PD+eXX35h9uzZHD16lHfffZc333yTzZs3A3Djxg1atWpFQEAA+/btY926dSQnJ9O1a1ej4/z888/Y2dmxe/dupkyZwuTJk4mMjMznv5AQT4EihHgiwsLCFAsLC8XOzs7o9emnnxrqZGZmKvXq1VO6du2q1KxZU+nXr99D27x8+bICKEeOHFEURVHi4uIUQJk3b56hzqJFixRAiYqKMpSFh4cr1apVM4rN1dVVSU9PN5TNmjVLsbe3V7RaraIoitKiRQtl2LBhiqIoyrlz5xQLCwslISHBKJ7WrVsrY8aMURRFUerUqaNMnDgxX33zxx9/KI6OjkpKSkqubRkZGYqtra2yY8cOo/K+ffsq3bt3VxRFUT7++GPlxRdfNNp+/vx5BVBiY2MN8Tdt2tSoTqNGjZTRo0fnK0Yhnga5JyzEE/TCCy8wa9YsozJXV1fDe41Gw++//07dunXx8fHhm2++Map78uRJxo8fz+7du7ly5YrhDDg+Pp7atWsb6tWtW9fw/s5ZdJ06dYzKLl26ZNS2v78/tra2hs9BQUGkpaVx/vx5fHx8jOoeOXIErVZL1apVjcozMzMpXbo0AEOHDmXgwIH8/ffftGnThi5duhjFda+2bdvi4+NDpUqVaNeuHe3ataNz587Y2tpy6tQpbt26Rdu2bY32ycrKIiAgAIBDhw6xcePGPM+0T58+bYjz/uN7enrm6gchzEmSsBBPkJ2dHVWqVHlonR07dgBw7do1rl27hp2dnWFbSEgIPj4+zJ07Fy8vL3Q6HbVr185177ZUqVKG9yqVKs+y+y9hmyItLQ0LCwv279+PhYWF0bY7ifDtt98mODiYiIgI/v77b8LDw/n6668ZMmRIrvYcHBw4cOAAmzZt4u+//2b8+PFMnDiRvXv3kpaWBkBERATlypUz2u/OoLa0tDRCQkL44osvcrXt6elpeH9vH8Dj94MQhU2SsBBmdPr0ad59913mzp3LkiVLCAsL459//kGtVnP16lViY2OZO3cuzZo1A2Dbtm2FduxDhw5x+/ZtbGxsANi1axf29vZ4e3vnqhsQEIBWq+XSpUuGWPLi7e3NgAEDGDBgAGPGjGHu3Ll5JmEAS0tL2rRpQ5s2bZgwYQLOzs5s2LCBtm3bYmVlRXx8PC1atMhz3/r16/PHH39QsWJFLC3l15h4dslPrxBPUGZmJklJSUZllpaWuLm5odVqefPNNwkODqZ37960a9eOOnXq8PXXX/P+++/j4uJC6dKlmTNnDp6ensTHx/PBBx8UWmxZWVn07duXsWPHcvbsWSZMmMDgwYNRq3OP16xatSo9evSgZ8+efP311wQEBHD58mWioqKoW7cuHTt2ZPjw4bRv356qVaty/fp1Nm7cSI0aNfI89l9//cWZM2do3rw5Li4urFmzBp1OR7Vq1XBwcGDkyJG8++676HQ6mjZtys2bN9m+fTuOjo6EhYUxaNAg5s6dS/fu3Q2jn0+dOsXixYuZN29errN1IYoqScJCPEHr1q0zujwKUK1aNU6cOMGnn37KuXPn+OuvvwD9ZdQ5c+bQvXt3XnzxRfz9/Vm8eDFDhw6ldu3aVKtWje+++46WLVsWSmytW7fGz8+P5s2bk5mZSffu3R/6CM/8+fP55JNPeO+990hISMDNzY3nnnuOl156CQCtVsugQYO4cOECjo6OtGvXLtc97jucnZ1ZsWIFEydOJCMjAz8/PxYtWkStWrUA+Pjjj3F3dyc8PJwzZ87g7OxM/fr1+fDDDwHw8vJi+/btjB49mhdffJHMzEx8fHxo165dnn9ECFFUqRRFUcwdhBDi6erVqxc3btxg1apV5g5FiBJN/mQUQgghzESSsBBCCGEmcjlaCCGEMBM5ExZCCCHMRJKwEEIIYSaShIUQQggzkSRcQDNnzqRixYpYW1sTGBjInj17zB3SE7FlyxZCQkLw8vJCpVLleqRFURTGjx+Pp6cnNjY2tGnTxrCqzh3Xrl2jR48eODo64uzsTN++fQ1TE95x+PBhmjVrhrW1Nd7e3kyZMuVJf7XHFh4eTqNGjXBwcKBMmTKEhoYSGxtrVCcjI4NBgwZRunRp7O3t6dKli2GZwjvi4+Pp2LEjtra2lClThvfff5+cnByjOps2baJ+/fpYWVlRpUoVFixY8KS/3mOZNWsWdevWxdHREUdHR4KCgli7dq1he0ntlwf5/PPPUalUDB8+3FBWkvto4sSJqFQqo1f16tUN24tV35h1+Yhn1OLFixWNRqP89NNPytGjR5V+/fopzs7OSnJysrlDK3Rr1qxRPvroI2XFihUKoKxcudJo++eff644OTkpq1atUg4dOqS8/PLLiq+vr3L79m1DnXbt2in+/v7Krl27lK1btypVqlQxrIajKIpy8+ZNxcPDQ+nRo4cSExOjLFq0SLGxsVF++OGHp/U1CyQ4OFiZP3++EhMTo0RHRysdOnRQKlSooKSlpRnqDBgwQPH29laioqKUffv2Kc8995zSpEkTw/acnByldu3aSps2bZSDBw8qa9asUdzc3AwrEymKopw5c0axtbVVRowYoRw7dkyZPn26YmFhoaxbt+6pfl9TrF69WomIiFD+/fdfJTY2Vvnwww+VUqVKKTExMYqilNx+ycuePXuUihUrKnXr1jWsWqUoJbuPJkyYoNSqVUtJTEw0vC5fvmzYXpz6RpJwATRu3FgZNGiQ4bNWq1W8vLyU8PBwM0b15N2fhHU6nVK2bFnlyy+/NJTduHFDsbKyUhYtWqQoiqIcO3ZMAZS9e/ca6qxdu1ZRqVSGZfG+//57xcXFRcnMzDTUGT16tNHSe8+CS5cuKYCyefNmRVH0fVGqVCll2bJlhjrHjx9XAGXnzp2Kouj/yFGr1UpSUpKhzqxZsxRHR0dDf4waNUqpVauW0bG6deumBAcHP+mvVKhcXFyUefPmSb/cIzU1VfHz81MiIyONlo4s6X00YcIExd/fP89txa1v5HK0ibKysti/fz9t2rQxlKnVatq0acPOnTvNGNnTFxcXR1JSklFfODk5ERgYaOiLnTt34uzsTMOGDQ112rRpg1qtZvfu3YY6zZs3R6PRGOoEBwcTGxvL9evXn9K3eXw3b94E7i5VuH//frKzs436p3r16lSoUMGof+rUqWNYfhD03z0lJYWjR48a6tzbxp06z8rPm1arZfHixaSnpxMUFCT9co9BgwbRsWPHXN9D+ki/jKeXlxeVKlWiR48exMfHA8WvbyQJm+jKlStotVqjf1zQr9d6/0T9xd2d7/uwvkhKSqJMmTJG2y0tLXF1dTWqk1cb9x6jqNPpdAwfPpznn3/esM5vUlISGo0GZ2dno7r398+jvvuD6qSkpHD79u0n8XUKxZEjR7C3t8fKyooBAwawcuVKatasWeL75Y7Fixdz4MABwsPDc20r6X0UGBjIggULWLduHbNmzSIuLo5mzZqRmppa7PpGFnAQohAMGjSImJiYQl1q8FlXrVo1oqOjuXnzJsuXLycsLIzNmzebO6wi4fz58wwbNozIyEisra3NHU6R0759e8P7unXrEhgYiI+PD0uXLjUsvVlcyJmwidzc3LCwsMg1Ei85OZmyZcuaKSrzuPN9H9YXZcuW5dKlS0bbc3JyuHbtmlGdvNq49xhF2eDBg/nrr7/YuHEj5cuXN5SXLVuWrKwsbty4YVT//v551Hd/UB1HR8ci/QtJo9FQpUoVGjRoQHh4OP7+/nz77bclvl9Af0n10qVL1K9fH0tLSywtLdm8eTPfffcdlpaWeHh4lPg+upezszNVq1bl1KlTxe7nR5KwiTQaDQ0aNCAqKspQptPpiIqKIigoyIyRPX2+vr6ULVvWqC9SUlLYvXu3oS+CgoK4ceMG+/fvN9TZsGEDOp2OwMBAQ50tW7aQnZ1tqBMZGUm1atVwcXF5St/GdIqiMHjwYFauXMmGDRvw9fU12t6gQQNKlSpl1D+xsbHEx8cb9c+RI0eM/lCJjIzE0dGRmjVrGurc28adOs/az5tOpyMzM1P6Bf0ykkeOHCE6OtrwatiwIT169DC8L+l9dK+0tDROnz6Np6dn8fv5earDwIqJxYsXK1ZWVsqCBQuUY8eOKf3791ecnZ2NRuIVF6mpqcrBgweVgwcPKoAydepU5eDBg8q5c+cURdE/ouTs7Kz8+eefyuHDh5VOnTrl+YhSQECAsnv3bmXbtm2Kn5+f0SNKN27cUDw8PJS33npLiYmJURYvXqzY2toW+UeUBg4cqDg5OSmbNm0yepTi1q1bhjoDBgxQKlSooGzYsEHZt2+fEhQUpAQFBRm233mU4sUXX1Sio6OVdevWKe7u7nk+SvH+++8rx48fV2bOnFnkHzP54IMPlM2bNytxcXHK4cOHlQ8++EBRqVTK33//rShKye2Xh7l3dLSilOw+eu+995RNmzYpcXFxyvbt25U2bdoobm5uyqVLlxRFKV59I0m4gKZPn65UqFBB0Wg0SuPGjZVdu3aZO6QnYuPGjQqQ6xUWFqYoiv4xpXHjxikeHh6KlZWV0rp1ayU2NtaojatXryrdu3dX7O3tFUdHR6V3795KamqqUZ1Dhw4pTZs2VaysrJRy5copn3/++dP6igWWV78Ayvz58w11bt++rbzzzjuKi4uLYmtrq3Tu3FlJTEw0aufs2bNK+/btFRsbG8XNzU157733lOzsbKM6GzduVOrVq6doNBqlUqVKRscoivr06aP4+PgoGo1GcXd3V1q3bm1IwIpScvvlYe5PwiW5j7p166Z4enoqGo1GKVeunNKtWzfl1KlThu3FqW9kFSUhhBDCTOSesBBCCGEmkoSFEEIIM5EkLIQQQpiJJGEhhBDCTCQJCyGEEGYiSVgIIYQwE0nCjyEzM5OJEyeSmZlp7lCKJOmfB5O+eTjpn4eT/nmwZ61v5Dnhx5CSkoKTkxM3b97E0dHR3OEUOdI/DyZ983DSPw8n/fNgz1rfyJmwEEIIYSaShIUQQggzKXHrCefk5HDw4EE8PDxQqx/vb5DU1FQAEhISSElJKYzwihXpnweTvnk46Z+Hk/55sKLQNzqdjuTkZAICArC0fHiaLXH3hPfu3Uvjxo3NHYYQQohibs+ePTRq1OihdUrcmbCHhweg7xxPT08zRyOEEKK4SUxMpHHjxoZ88zAlLgnfuQTt6elJ+fLlzRyNEEKI4io/tzxlYJYQQghhJmZNwlu2bCEkJAQvLy9UKhWrVq165D6bNm2ifv36WFlZUaVKFRYsWPDE4xRCCCGeBLMm4fT0dPz9/Zk5c2a+6sfFxdGxY0deeOEFoqOjGT58OG+//Tbr169/wpEKIYQQhc+s94Tbt29P+/bt811/9uzZ+Pr68vXXXwNQo0YNtm3bxjfffENwcHChxqbVasnOzi7UNoUoCjQazWM/nieEKBzP1MCsnTt30qZNG6Oy4OBghg8fXmjHUBSFpKQkbty4UWhtClGUqNVqfH190Wg05g5FPEBGtpZ9Z6+TrdWZO5QSx93BitrlnJ7a8Z6pJJyUlJRryLeHhwcpKSncvn0bGxubXPtkZmYaTeR950Huhx3jxo0blClTBltbW1QqVeEEL0QRoNPpuHjxIomJiVSoUEF+vougDSeSmbD6KOev3TZ3KCXSS3U9mfFG/ad2vGcqCRdEeHg4kyZNylddrVZrSMClS5d+wpEJYR7u7u5cvHiRnJwcSpUqZe5wxH8uXL/FpP8dI/JYMgBu9hq8nHOfWIgnq4Kr7VM93jOVhMuWLUtycrJRWXJyMo6OjnmeBQOMGTOGESNGGD4nJCRQs2bNPOveuQdsa/t0/xGEeJruXIbWarWShIuAzBwt87bGMX3DSTKydViqVfRt6svQ1n7YWT1Tv6JFATxT/8JBQUGsWbPGqCwyMpKgoKAH7mNlZYWVlZXhc37mEpVLdKI4k5/vomP7qSuM+zOGM5fTAQj0deXj0NpU9XAwc2TiaTFrEk5LS+PUqVOGz3FxcURHR+Pq6kqFChUYM2YMCQkJ/PLLLwAMGDCAGTNmMGrUKPr06cOGDRtYunQpERER5voKQghhsuSUDD7+6xh/HU4EwM3eirEda9Cpnpf8kVTCmPU5hX379hEQEEBAQAAAI0aMICAggPHjxwP6+Tfj4+MN9X19fYmIiCAyMhJ/f3++/vpr5s2bV+iPJwm9ihUrMm3atHzX37RpEyqVSkaWC/EAOVod87aeofXXm/nrcCJqFfRqUpGo91oQGlBOEnAJZNYz4ZYtW/KwRZzymg2rZcuWHDx48AlG9ex51H/cCRMmMHHiRJPb3bt3L3Z2dvmu36RJExITE3FyenrD+4V4Vuw9e41xq2I4kaR/QiOggjMfd6r9VB+HEUXPM3VPWOQtMTHR8H7JkiWMHz+e2NhYQ5m9vb3hvaIoaLXaR65xCfpRtKbQaDSULVvWpH2Ki6ysLHnuVuTpSlom4WtO8MeBCwC42Jbig/bVea2BN2q1nPmWdDJtTjFQtmxZw8vJyQmVSmX4fOLECRwcHFi7di0NGjTAysqKbdu2cfr0aTp16oSHhwf29vY0atSIf/75x6jd+y9Hq1Qq5s2bR+fOnbG1tcXPz4/Vq1cbtt9/OXrBggU4Ozuzfv16atSogb29Pe3atTP6oyEnJ4ehQ4fi7OxM6dKlGT16NGFhYYSGhj7w+169epXu3btTrlw5bG1tqVOnDosWLTKqo9PpmDJlClWqVMHKyooKFSrw6aefGrZfuHCB7t274+rqip2dHQ0bNmT37t0A9OrVK9fxhw8fTsuWLQ2fW7ZsyeDBgxk+fDhubm6GWyJTp06lTp062NnZ4e3tzTvvvENaWppRW9u3b6dly5bY2tri4uJCcHAw169f55dffqF06dJGz7UDhIaG8tZbbz2wP0TRpNUp/LrrHK2+2mRIwN0be7PhvZZ0a1RBErAAJAk/kqIo3MrKMcvrYZfqTfXBBx/w+eefc/z4cerWrUtaWhodOnQgKiqKgwcP0q5dO0JCQozuwedl0qRJdO3alcOHD9OhQwd69OjBtWvXHlj/1q1bfPXVV/z6669s2bKF+Ph4Ro4cadj+xRdf8PvvvzN//ny2b99OSkrKIxfyyMjIoEGDBkRERBATE0P//v1566232LNnj6HOmDFj+Pzzzxk3bhzHjh1j4cKFhole0tLSaNGiBQkJCaxevZpDhw4xatQodDrTZif6+eef0Wg0bN++ndmzZwP62ai+++47jh49ys8//8yGDRsYNWqUYZ/o6Ghat25NzZo12blzJ9u2bSMkJAStVstrr72GVqs1+sPm0qVLRERE0KdPH5NiE+Z16PwNOn+/nXGrYkjJyKGWlyMr3mlC+Ct1cbGTKybiLrkc/Qi3s7XUHG+eBSKOTQ7GVlM4/0STJ0+mbdu2hs+urq74+/sbPn/88cesXLmS1atXM3jw4Ae206tXL7p37w7AZ599xnfffceePXto165dnvWzs7OZPXs2lStXBmDw4MFMnjzZsH369OmMGTOGzp07AzBjxoxcj6Hdr1y5ckaJfMiQIaxfv56lS5fSuHFjUlNT+fbbb5kxYwZhYWEAVK5cmaZNmwKwcOFCLl++zN69e3F1dQWgSpUqDz1mXvz8/JgyZYpR2b1TqFasWJFPPvmEAQMG8P333wMwZcoUGjZsaPgMUKtWLcP7N954g/nz5/Paa68B8Ntvv1GhQgWjs3BRdN24lcWX62NZuCceRQEHa0tGvliNN5/zwULOfEUeJAmXEA0bNjT6nJaWxsSJE4mIiCAxMZGcnBxu3779yDPhunXrGt7b2dnh6OjIpUuXHljf1tbWkIABPD09DfVv3rxJcnIyjRs3Nmy3sLCgQYMGDz0r1Wq1fPbZZyxdupSEhASysrLIzMw0TLJy/PhxMjMzad26dZ77R0dHExAQYEjABdWgQYNcZf/88w/h4eGcOHGClJQUcnJyyMjI4NatW9ja2hIdHW1IsHnp168fjRo1IiEhgXLlyrFgwQJ69eolo2aLOJ1OYfmBC3y+9gTX0rMAeCWgHGM61MDdweoRe4uSTJLwI9iUsuDYZPM8AmVTyqLQ2rp/lPPIkSOJjIzkq6++okqVKtjY2PDqq6+SlZX10Hbun2FJpVI9NGHmVf9xL7N/+eWXfPvtt0ybNs1w/3X48OGG2B80e9odj9quVqtzxZjXilr39+nZs2d56aWXGDhwIJ9++imurq5s27aNvn37kpWVha2t7SOPHRAQgL+/P7/88gsvvvgiR48elefgi7hjF1MY92cM+89dB6Cqhz0fd6pNYCWZ+lY8miThR1CpVIV2Sbgo2b59O7169TJcBk5LS+Ps2bNPNQYnJyc8PDzYu3cvzZs3B/RnuQcOHKBevXoP3G/79u106tSJN998E9APwvr3338N05H6+flhY2NDVFQUb7/9dq7969aty7x587h27VqeZ8Pu7u7ExMQYlUVHRz9yisf9+/ej0+n4+uuvDUsFLl26NNexo6KiHjqf+dtvv820adNISEigTZs2eHt7P/S4wjxSM7L5JvIkP+88i1anYKuxYHgbP3o/70spi8ccbqPTwfU40OaxnKpTObD6b0at2zcgNQk0tuBc4W6dy/+CYuIKTA4eYOOif5+ZBjcvgKUVuPrerXP1dN4xPYydO9j99wdJ9m24fg7UluB2zy2g62chO8O0dm1c9DGDPqarp0GlAvdqd+vcOA9Z6flv09oJHD1Ni+MxFb/sIvLFz8+PFStWEBISgkqlYty4cSYPTCoMQ4YMITw8nCpVqlC9enWmT5/O9evXH3r51c/Pj+XLl7Njxw5cXFyYOnUqycnJhiRsbW3N6NGjGTVqFBqNhueff57Lly9z9OhR+vbtS/fu3fnss88IDQ0lPDwcT09PDh48iJeXF0FBQbRq1Yovv/ySX375haCgIH777TdiYmIMk8o8SJUqVcjOzmb69OmEhIQYDdi6Y8yYMdSpU4d33nmHAQMGoNFo2LhxI6+99hpubm6A/r7wyJEjmTt3rmG2OFF0KIrC6kMX+TTiOJdS9SPZO9bxZOxLNfB0eswFF7Iz4MhS2DEDrsTmXaf7Yqj23zrs/66Dlf8HlVvDWyvu1pn7AmSl5b3/g7w8Her31L+P3wW/dwFPf/i/LXfr/PaKPmGaovUEaPbf/P2XT8CcluBYDkYcu1tneV9I2Gdau0GDIfi/Jx7SkuH7QLCwgnH33B5bM1LfR/kV8CZ0mmlaHI9JknAJNXXqVPr06UOTJk1wc3Nj9OjR+ZpXu7CNHj2apKQkevbsiYWFBf379yc4OBgLiwdfih87dixnzpwhODgYW1tb+vfvT2hoKDdv3jTUGTduHJaWlowfP56LFy/i6enJgAEDAP3zzH///TfvvfceHTp0ICcnh5o1azJzpv4/X3BwMOPGjWPUqFFkZGTQp08fevbsyZEjRx76Xfz9/Zk6dSpffPEFY8aMoXnz5oSHh9OzZ09DnapVq/L333/z4Ycf0rhxY2xsbAgMDDQMdgP9FYIuXboQERHx0Ee1xNN36lIq4/88yo7TVwHwdbNj0su1aF7VtGfqc7l1Dfb9CLvnQPp/ScTCCqzsc9e1uOeKjIUGbEuDtaNxHRtX/VmsKSyt72nX8r9275tIxMYFMh++HGwupe75w0T9X7t3zrjvsHbSl5vU7j0L7ajU+v0t7vvOVg6mtavJo7+fMJVSmM/BPAMuXLiAt7c358+fp3z58kbbMjIyiIuLw9fXF2tr6we0IJ4knU5HjRo16Nq1Kx9//LG5wzGb1q1bU6tWLb777rtCb1t+zk13KyuH6RtOMW/rGbK1ClaWaga/UIX+LSphZfkYYzeun4Wd38PBXyH7lr7MsTw8N1B/Vnp/chXPhIflmfvJmbAwq3PnzvH333/TokULMjMzmTFjBnFxcbzxxhvmDs0srl+/zqZNm9i0aZPRY0zCPBRFYf3RZD7+6xgJN24D0KZGGSaE1MK7MNad3TED9s7Vv/eoA88PhVqdjc92RbEmSViYlVqtZsGCBYwcORJFUahduzb//PMPNWrUMHdoZhEQEMD169f54osvqFat2qN3EE/MuavpTFh9lE2xlwEo52zDxJdr0bamR8Ea1OngVKT+fmjZ2vqyoHf0A7CCBkOllvqBRaJEkSQszMrb25vt27ebO4wi42mPUBe5ZWRrmb35NN9vOk1Wjo5SFir+r3llBr1QBRvNY1x63vAxbJsKNV6Gbr/qy1wrwZt/FE7g4pkkSVgIIf6zMfYSE1cf5dxV/f3ZplXcmNSpFpXdCzBg59Y1yMm8+8hL3a6w90d94lUUOesVgCRhIYTg4o3bTP7fMdYdTQLAw9GKcS/VpGMdT9NnK7t+FnbNggO/Qo0QeOUHfXmZGjAy1ni0sCjxJAkLIUqsrBwdP26L47uok9zO1mKhVtHn+YoMa1MVeysTfz0mHIAd0+HYqrsTZVyJBW2O/pEfkAQscpEkLIQokXacvsL4P49y6pJ+UovGFV2ZHFqL6mVNeCzozmCrHdPh7Na75ZVbQZOhMthKPJIkYSFEiXIpJYNP1xznz+iLALjZaxjTvgav1C+X/0vPOZlweCnsnKGfBQr0E1HUfhWaDLk7+lmIR5AkLIQoEXK0On7ZeY5vIv8lNTMHlQrees6H916shpNNPp/LvX0d9v0Eu3/QT5UIYOUIDXpB4AD9vM5CmOAxZxkXxUnLli1zrYc7bdq0h+6jUqlYtWrVYx+7sNoRIi/7z10nZMZ2Jv91jNTMHPy9nVk9qCmTO9XOfwIGWNEfoibrE7BjOXjxE3g3Bl78WBKwKBA5Ey4GQkJCyM7OZt263BOVb926lebNm3Po0CGjtYDzY+/evbmW63tcEydOZNWqVURHRxuVJyYm4uLikvdOQhTQ1bRMvlh3gqX7LgDgZFOK0e2q83ojb9TqfFx6vngQnLzBTr+4Bo36QUqi/pJz7VdkZivx2CQJFwN9+/alS5cuXLhwIdc8pfPnz6dhw4YmJ2DQL+n3tJQtW/apHasoycrKQqPRmDuMYkenU1i0N54p62K5eVu/9F63ht6Mbl8dV7t89veaUbDnB2gxGl74UF/m11b/ksFWopDI5ehi4KWXXsLd3Z0FCxYYlaelpbFs2TL69u3L1atX6d69O+XKlcPW1pY6deqwaNGih7Z7/+XokydP0rx5c6ytralZsyaRkZG59hk9ejRVq1bF1taWSpUqMW7cOLKz9b8EFyxYwKRJkzh06BAqlQqVSmWI+f7L0UeOHKFVq1bY2NhQunRp+vfvT1ra3aXZevXqRWhoKF999RWenp6ULl2aQYMGGY6Vl9OnT9OpUyc8PDywt7enUaNG/PPPP0Z1MjMzGT16NN7e3lhZWVGlShV+/PFHw/ajR4/y0ksv4ejoiIODA82aNeP06dNA7sv5AKGhofTq1cuoTz/++GN69uyJo6Mj/fv3f2S/3fG///2PRo0aYW1tjZubm2Et6MmTJ1O7du6BQPXq1WPcuHEP7I/i6siFm3SetYOPVsZw83Y2NTwd+WNgEF+8WvfhCTgnE7Ju3f3sE6QfbJVxd3UuVCpJwKJQyZlwfpmyMPQdFlZ3nw/U5oA2U7/k1r3PCj6oXU3+LwNbWlrSs2dPFixYwEcffWQY4bls2TK0Wi3du3cnLS2NBg0aMHr0aBwdHYmIiOCtt96icuXKNG7c+JHH0Ol0vPLKK3h4eLB7925u3ryZK+EAODg4sGDBAry8vDhy5Aj9+vXDwcGBUaNG0a1bN2JiYli3bp0h+Tk5OeVqIz09neDgYIKCgti7dy+XLl3i7bffZvDgwUZ/aGzcuBFPT082btzIqVOn6NatG/Xq1aNfv355foe0tDQ6dOjAp59+ipWVFb/88gshISHExsZSoYJ+QfSePXuyc+dOvvvuO/z9/YmLi+PKlSsAJCQk0Lx5c1q2bMmGDRtwdHRk+/bt5OTkPLL/7vXVV18xfvx4JkyYkK9+A4iIiKBz58589NFH/PLLL2RlZbFmzRoA+vTpw6RJk9i7dy+NGjUC4ODBgxw+fJgVK1bkDqCYunkrm6/+juW33edQFLC3suS9F6vy1nM+WFo85Hzj3sFWzw2Epu/qy2u8DMMOy71e8WQpJcz58+cVQDl//nyubbdv31aOHTum3L59O/eOExxNf8WsuLt/zAp92U8djNv9wjfvfU10/PhxBVA2btxoKGvWrJny5ptvPnCfjh07Ku+9957hc4sWLZRhw4YZPvv4+CjffPONoiiKsn79esXS0lJJSEgwbF+7dq0CKCtXrnzgMb788kulQYMGhs8TJkxQ/P39c9W7t505c+YoLi4uSlpammF7RESEolarlaSkJEVRFCUsLEzx8fFRcnJyDHVee+01pVu3bg+MJS+1atVSpk+friiKosTGxiqAEhkZmWfdMWPGKL6+vkpWVlae2+/vP0VRlE6dOilhYWGGzz4+PkpoaOgj47q/34KCgpQePXo8sH779u2VgQMHGj4PGTJEadmyZZ51H/pz/gzS6XTK8n3nlfqT/1Z8Rv+l+Iz+Sxm66ICSfPMR3+/aWUVZM1pRPvG8+//uh5aKotM9ncBFsfWwPHM/ORMuJqpXr06TJk346aefaNmyJadOnWLr1q1MnjwZAK1Wy2effcbSpUtJSEggKyuLzMxMbG3ztxzb8ePH8fb2xsvLy1AWFBSUq96SJUv47rvvOH36NGlpaeTk5ODoaNqaqMePH8ff399oUNjzzz+PTqcjNjYWDw/9Kja1atXCwuLuhPqenp4cOXLkge2mpaUxceJEIiIiSExMJCcnh9u3bxMfHw9AdHQ0FhYWtGjRIs/9o6OjadasGaVKPd5gnIYNG+Yqe1S/RUdHP/AMH6Bfv3706dOHqVOnolarWbhwId98881jxfksOJGUwvhVR9lz9hoAVcrYM7lTLZpUdnvwThcP6ifXOLoKFK2+rEyt/5YRfEUuN4unSpJwfn140fR9LKzuvq8eom9Ddd9lseEPThqm6tu3L0OGDGHmzJnMnz+fypUrGxLKl19+ybfffsu0adOoU6cOdnZ2DB8+nKysrEI7/s6dO+nRoweTJk0iODgYJycnFi9ezNdff11ox7jX/clQpVKh0+keWH/kyJFERkby1VdfUaVKFWxsbHj11VcNfWBj8/ApBR+1Xa1WoyiKUVle96jvH3Gen3571LFDQkKwsrJi5cqVaDQasrOzefXVVx+6z7MsLTOHaZH/Mn/HWbQ6BZtSFgxr40ef533RWOZx6Vmng1P/wI7vjGe2qtRSP7NV5VaSfIVZSBLOLxPu0ebJwvLu/eHCbPceXbt2ZdiwYSxcuJBffvmFgQMHGu4Pb9++nU6dOvHmm28C+nu8//77LzVr1sxX2zVq1OD8+fMkJibi6alfFWbXrl1GdXbs2IGPjw8fffSRoezcuXNGdTQaDVqt9pHHWrBgAenp6YaEtX37dtRq9WOtsbt9+3Z69eplGNCUlpZmtHRgnTp10Ol0bN68mTZt2uTav27duvz8889kZ2fneTbs7u5OYmKi4bNWqyUmJoYXXnjhoXHlp9/q1q1LVFQUvXv3zrMNS0tLwsLCmD9/PhqNhtdff/2RiftZpCgKEUcS+fivYySnZALQrlZZxoXUpJxzHt83JxOOLNOf+d6Z2UplAbW76B8z8jT9qQEhCpOMji5G7O3t6datG2PGjCExMdFoVK6fnx+RkZHs2LGD48eP83//938kJyfnu+02bdpQtWpVwsLCOHToEFu3bjVKGneOER8fz+LFizl9+jTfffcdK1euNKpTsWJF4uLiiI6O5sqVK2RmZuY6Vo8ePbC2tiYsLIyYmBg2btzIkCFDeOuttwyXogvCz8+PFStWEB0dzaFDh3jjjTeMzpwrVqxIWFgYffr0YdWqVcTFxbFp0yaWLl0KwODBg0lJSeH1119n3759nDx5kl9//ZXY2FgAWrVqRUREBBEREZw4cYKBAwdy48aNfMX1qH6bMGECixYtYsKECRw/fpwjR47wxRdfGNV5++232bBhA+vWraNPnz4F7qei6vTlNN76cQ+DFx4kOSUTn9K2LOjdiNlvNcg7AQP81A7+HKRPwBp7CBoMww5Bl7mSgEWRIEm4mOnbty/Xr18nODjY6P7t2LFjqV+/PsHBwbRs2ZKyZcsSGhqa73bVajUrV67k9u3bNG7cmLfffptPP/3UqM7LL7/Mu+++y+DBg6lXrx47duzI9YhMly5daNeuHS+88ALu7u55PiZla2vL+vXruXbtGo0aNeLVV1+ldevWzJgxw7TOuM/UqVNxcXGhSZMmhISEEBwcTP369Y3qzJo1i1dffZV33nmH6tWr069fP9LT9SPYS5cuzYYNG0hLS6NFixY0aNCAuXPnGs6K+/TpQ1hYGD179qRFixZUqlTpkWfBkL9+a9myJcuWLWP16tXUq1ePVq1asWfPHqM6fn5+NGnShOrVqxMYGPg4XVWk3M7S8tX6WNpN28K2U1fQWKoZ3saP9cOb07JaGePKN+L1TyLcUSsUHDyh7WR49ygEfwrO3k81fiEeRqXcfxOrmLtw4QLe3t6cP38+18QWGRkZxMXF4evri7W1tZkiFKJgFEXBz8+Pd955hxEjRjyw3rP0cx55LJmJq4+ScOM2AC9Uc2fiy7XwKZ3HbZw178PeH/VnubW76Muyb+svP1vKhCji6XlYnrmf3BMWohi4fPkyixcvJikp6YH3jZ8l56/dYuLqo0SduARAOWcbxofU5MWaHndXOrpz/nDns21p/Wjn83vuJmFZv1cUcZKEhSgGypQpg5ubG3PmzHmm5+DOzNHyw+YzzNx4iswcHaUsVLzdrBJDWlXBVvPfr6ucLP1gq50zoPUEqNZOX964P1RrD57+5vsCQphIkrAQxUBxuKu05d/LTFh9lLgr+nvwTSqXZnKn2lQpY6+vcPsG7J+vn9kq9b9R6Hvn3k3Ctq76lxDPEEnCQgizSrx5m4//OsaaI0kAlHGwYuxLNQmp66m/9HwjHnbNhgM/Q9Z/84c7eOrX723Qy3yBC1EIJAkLIcwiW6tj/vY4pv1zkltZWizUKsKCKvJuWz8crEtB4iH9870xK4xntmoyRH/PVwZbiWJAknAeHjbrkhDPuqJw6XrXmauM/zOGf5P1Z7YNfVyY3Kk2NT0d4FSUfmaruM13d6jUUp98K7eWma1EsSJJ+B4ajQa1Ws3Fixdxd3dHo9HcHYkpRDGgKAqXL19GpVI99hzYBXEpNYPwNSdYeTABAFc7DWPaV6dL/fKoFS3MaQmJ0frKhpmtBstgK1FsSRK+h1qtxtfXl8TERC5eLMBc0UI8A1QqFeXLlzda/OJJ0+oUftt1jq/Wx5KamYNKBW80rsD7L5TH2fnOaG5LKFMTrp7S3+sNHCATa4hiT5LwfTQaDRUqVCAnJ+eRcxwL8SwqVarUU03AB+KvM25VDEcvpgBQp5wTn3Sqhf+Jr+H7BdBnHZStra/cZgK0Cwcb56cWnxDmJEk4D3cu1Znjcp0QxcX19CymrD/Boj3nAXC0tuT9dtV5o3EFLNQq2BUPWakQs/xuEnYoa8aIhXj6JAkLIQqVTqewdN95vlh3guu3sgGFD6sl0ov/ofH7BtT/jbNo8QEE9IQqrc0arxDmJElYCFFoYhJuMu7PGA7G36AUOQx2PcA7mrXYntOvNMXOmfDSVP17j5r6lxAlmCRhIcRjS8nIZurf//LLzrPYK+kM0WxkgE0kdrcuwy30ywjWD4PnBpo7VCGKFEnCQogCUxSFVdEJfBpxAk1aAmMs1/GmZhM2uluQifHMVjLYSohcJAkLIQrk3+RUxq2KIe3sAT6yjOBl651YoAMd+keNmgyB2q/KzFZCPITa3AHMnDmTihUrYm1tTWBgYK6Fyu+VnZ3N5MmTqVy5MtbW1vj7+7Nu3bqnGK0QIj0zh/A1x+n67XqGXHiPCKsP6WyxXZ+AfVtAjz9g4A6o94YkYCEewaxnwkuWLGHEiBHMnj2bwMBApk2bRnBwMLGxsZQpUyZX/bFjx/Lbb78xd+5cqlevzvr16+ncuTM7duwgICDADN9AiJJDURTWHknk44jjJN7MAKwp75CDkmWBqvYrEDQYvOqZO0whnikqxYwTyQYGBtKoUSNmzJgB6Ods9vb2ZsiQIXzwwQe56nt5efHRRx8xaNAgQ1mXLl2wsbHht99+y9cxL1y4gLe3N+fPn6d8+fKF80WEKObikq+za+EnNLy+li5ZE3FydWPSy7Vo5ZioXz7QuYK5QxSiyDAlz5h8JlyxYkX69OlDr169qFCh4P/xsrKy2L9/P2PGjDGUqdVq2rRpw86dO/PcJzMzE2tra6MyGxsbtm3b9sDjZGZmkpmZaficmppa4JiFKFFysriYpuWnbXH8svMs/7NYh586gW9rHCPojXFYl7IAPMwdpRDPNJPvCQ8fPpwVK1ZQqVIl2rZty+LFi42SXH5duXIFrVaLh4fxf2IPDw+SkpLy3Cc4OJipU6dy8uRJdDodkZGRrFixgsTExAceJzw8HCcnJ8OrZk15LlGIB0pJhH3zSf3pFTI+8+GlKf9j3rY4srQKEWX6c7n1N7zQY8x/CVgI8bgKlISjo6PZs2cPNWrUYMiQIXh6ejJ48GAOHDjwJGI0+Pbbb/Hz86N69epoNBoGDx5M7969Uasf/DXGjBnDzZs3Da9jx4490RiFeKYoCiQdgc1TUOa8AFOrw1/DcYiPwlp3i8YcJahSaeb3bsS7g4bi3qwPWFqZO2ohio0CD8yqX78+9evX5+uvv+b7779n9OjRzJo1izp16jB06FB69+790GUA3dzcsLCwIDk52ag8OTmZsmXznj/W3d2dVatWkZGRwdWrV/Hy8uKDDz6gUqVKDzyOlZUVVlZ3f2mkpKSY+E2FKGZyMuHsNohdq3+lXADgzv/WaF1lonQNyKzSjkGtW1PH29lsoQpR3BU4CWdnZ7Ny5Urmz59PZGQkzz33HH379uXChQt8+OGH/PPPPyxcuPCB+2s0Gho0aEBUVBShoaGAfmBWVFQUgwcPfuixra2tKVeuHNnZ2fzxxx907dq1oF9DiJLj6Er961QUZKUZijPQsFVbh3909dlp0YA2jfzp/XxFvF1tzRisECWDyUn4wIEDzJ8/n0WLFqFWq+nZsyfffPMN1atXN9Tp3LkzjRo1emRbI0aMICwsjIYNG9K4cWOmTZtGeno6vXv3BqBnz56UK1eO8PBwAHbv3k1CQgL16tUjISGBiRMnotPpGDVqlKlfQ4ji79oZcL3nKtGR5XDiLwBSS7mxLsuftdkB7NDVwsHBkd7PV+TDxj442crqYUI8LSYn4UaNGtG2bVtmzZpFaGhonsv9+fr68vrrrz+yrW7dunH58mXGjx9PUlIS9erVY926dYbBWvHx8Ub3ezMyMhg7dixnzpzB3t6eDh068Ouvv+Ls7Gzq1xCi+NLmwOymcPk4DN4PblUAiPfpwonLrsxKqkp0RkUU1PiVsWdy80p0queFlaUMthLiaTP5OeFz587h4+PzpOJ54uQ5YVGsZKTAqX/g0nFo9dHd8p9fhnM7UF6Zy1ZNU+ZuPcPWk1cMm4MqlaZ/80q0qOqOWv3gsRtCCNM90eeEL126RFJSEoGBgUblu3fvxsLCgoYNG5rapBDCFDfiIXYdxK7RD7DSZevLG/UFB/2gxqz237AuLpvv/7nEiST9VLAWahUd6njSr5kvdcs7myl4IcS9TE7CgwYNYtSoUbmScEJCAl988QW7d+8utOCEEIBOBxcPwr//jWZOjjHeXroKVGsPikJKRjaL98Tz07azJKVkAGCrsaBbI2/6PO8rg62EKGJMTsLHjh2jfv36ucoDAgLkGVwhCkvWLYjbrE+6/66DtHse5VOpoUIQVG2nT75ufly8cZsF286ycPdh0jJzAHB3sKJXk4q8GSiDrYQoqkxOwlZWViQnJ+d6NjcxMRFLS1kZUYjHpigwo5Hh+V0ANA5QpTVU6wB+bfXzNQPHLqYwd0k0/zt0kRydfniHXxl7+slgKyGeCSZnzRdffJExY8bw559/4uTkBMCNGzf48MMPadu2baEHKESxlpECe36AC/uh+yJQqfSvik3h3Hb9mW619uDT1LAsoKIobDt5mTlbjAdbPVfJlf9rXlkGWwnxDDE5CX/11Vc0b94cHx8fw/KB0dHReHh48OuvvxZ6gEIUKzlZ+jPcO8/vWmhg61TIvgVJh8HTX1/e8WvQ2OkT8n+ytTr+d+gic7ac4USSfiEStQo61vWSwVZCPKNMTsLlypXj8OHD/P777xw6dAgbGxt69+5N9+7d83xmWIgS79Y1OBmpH1h1KgocvWDQfwMYS1lD85FgWxqcvO/uY2VveJuakc2iPfHM3372v3V8ZbCVEMVFgW7i2tnZ0b9//8KORYji48qpu6OZ43eBor277Za1PjH/d1+XZu/l2UTizdvM336WRbvjSb1vsFWPwAo422qe9LcQQjxhBR5JdezYMeLj48nKyjIqf/nllx87KCGeOdocuLDn7qIIV08aby9T67/7ux3AKwAesvLXsYspzNt6htX3DLaqUsae/s0q0SlABlsJUZyYnITPnDlD586dOXLkCCqVijsTbt1ZMUmr1T5sdyGKl8xUiBgJJ/+G29fulqtL6QdXVWuvf5TI5eGzzCmKwrZTV3INtgr0deX/WlSiZdUyMthKiGLI5CQ8bNgwfH19iYqKwtfXlz179nD16lXee+89vvrqqycRoxBFx43zcPUUVH5B/1ljD2e36hOwtTNUDdYn3sqtwdrxkc1la3X8dfgic7bEcTxRv8ymWsV/M1tVwl+WERSiWDM5Ce/cuZMNGzbg5uaGWq1GrVbTtGlTwsPDGTp0KAcPHnwScQphfhf2w7xWYOMK758CtYV+9HK7z/UDq7wDwSJ//6VSM7JZvOc8P22PMwy2simlH2zVt6kMthKipDA5CWu1WhwcHABwc3Pj4sWLVKtWDR8fH2JjYws9QCGeuuzbcGazfmCVgye0/EBf7ukPtm7g5gfplw3zNFMz/+MgEm/eZsH2syy8Z7CVm70VvZ+XwVZClEQmJ+HatWtz6NAhfH19CQwMZMqUKWg0GubMmZNrFi0hnhlpl/TTQ8auhdMbIee2vtzJG1qM1p/xWljC8COgMf0s9XhiCnO3nmF19N3BVpXd7ejfvBKd6pXDupQMthKiJDI5CY8dO5b09HQAJk+ezEsvvUSzZs0oXbo0S5YsKfQAhXgiFAUuHbs7mjlhP3DPqp6O5e/OVqUodyfNMCEBK4rC9lNXmbP1DFv+vWwoD/R1pX/zSrxQTQZbCVHSmZyEg4ODDe+rVKnCiRMnuHbtGi4uLoYR0kIUSTlZ+qkg//1vGcAb8cbbvQL0jxBVaw8etY1mqzJFtlZHxOFE5mw5w7F7Blu1r+NJfxlsJYS4h0lJODs7GxsbG6Kjo6ldu7ah3NXVtdADE6JQ6HR3n8m9eR5+Db27zdIafFvcfYzI0fOxDpWakc2Svef5aVscF2WwlRAiH0xKwqVKlaJChQryLLAo+s7vgajJYOcGry3Ql5WurF8IwbWi/oy3Ukv9/MyPKelmBvO3x8lgKyGEyUy+HP3RRx/x4Ycf8uuvv8oZsCgadFq4sFf/zG7Z/67QWJTSP79byk5/Gfq/FYjoHVFohz2RlMKcLTLYSghRcCYn4RkzZnDq1Cm8vLzw8fHBzs74TOLAgQOFFpwQD5SZCqc3QOw6OLkebl0F/zeg8yz9ds960HGqfg1ey8I7E5XBVkKIwmRyEg4NDX0CYQiRT8f+hAO/QNwW0N4zb7m1E1g53P2sUkGjvoV22IcNturXrBL1ZLCVEKIATE7CEyZMeBJxCPFw2bdhzftw8J41q118745mrvCc/hJ0IXvYYKs+z/tSobQMthJCFFyBV1ES4qm5cgqWhUFyDKCCJkMg4E1wq1rgx4geJelmBvN3/DfYKuPuYKteTXzoEeiDi50MthJCPD6Tk7BarX7o88AycloUqpgVsHooZKWCnTt0macf1fyEnEhKYe6WOFYfSiBbe3ewVb9mlQgNkMFWQojCZXISXrlypdHn7OxsDh48yM8//8ykSZMKLTAh2DUb1o3Wv/d5Hrr8+NjP8uZFURR2nL7KnC1n2HzPYKvGvq70b1aJVtVlsJUQ4skwOQl36tQpV9mrr75KrVq1WLJkCX37Ft5gGFHC1XgJtkyB+j3hhbH5XqEov7K1OtYc0Q+2OnrxnsFWtT15u5kvARVcCvV4Qghxv0L7rfbcc8/Rv3//wmpOlFSXY8G9mv69U3kYvA9sC/d59LTMHBbviWf+9rMk3NAv1GBTyoKuDcvTp6kvPqUffwIPIYTIj0JJwrdv3+a7776jXLlyhdGcKIkUBSLHw47p8PpCqN5BX16ICTg5JYOftt8/2EpDWFBF3nxOBlsJIZ4+k5Pw/Qs1KIpCamoqtra2/Pbbb4UanChBVCrQ5QAKXDx4NwkXgtikVOZuPcOf0XcHW1X6b7BVZxlsJYQwI5OT8DfffGOUhNVqNe7u7gQGBuLiIvfQhIm0OXfv9baZBH5toXKrx25WURR2nr7KD/cPtqqon9lKBlsJIYoCk5Nwr169nkAYosTRaWFTOJzbCT3/1CdiS81jJ+A7g63mbj1DTMLdwVbtapelX7NKMthKCFGkmJyE58+fj729Pa+99ppR+bJly7h16xZhYWGFFpwoplKT4Y+++gUWAP5dCzVCHqvJvAZbWZdS062htwy2EkIUWSYn4fDwcH744Ydc5WXKlKF///6ShMXDxW2B5X0h/ZJ+haOQbx8rASenZDB/+1l+331OBlsJIZ45Jifh+Ph4fH19c5X7+PgQHx9fKEGJYking21fw8bPQNGBew3o+gu4Vy1QczLYSghRHJichMuUKcPhw4epWLGiUfmhQ4coXbp0YcUlipP0q7CiH5yO0n+u1wM6fAUa0xc/2H/uOtM3nGRTrPFgq37NK9FaBlsJIZ4xJifh7t27M3ToUBwcHGjevDkAmzdvZtiwYbz++uuFHqB4xsXvhuW9ISUBLG2g41f6xRdMpNMpfL/pFFMj/0WnyGArIUTxYHIS/vjjjzl79iytW7fG0lK/u06no2fPnnz22WeFHqB4RikK7JwB/0zUP/9b2g+6/gwetUxu6lp6FsOXRLPlv0eNQut58W7bqjLYSgjxzDM5CWs0GpYsWcInn3xCdHQ0NjY21KlTBx8fnycRn3gW3b4Bq96B2Aj959pd9AOwrBxMbmrf2WsMXniQpJQMrEupmdypNl0behduvEIIYSYFnrbSz88PPz+/woxFFBdqC7gSCxYaaPc5NOxj8rq/iqIwb2scn687gVanUMndju971Kd6WccnFLQQQjx9JifhLl260LhxY0aPHm1UPmXKFPbu3cuyZcsKLTjxDFH0I5RRqfRnvF1/BW0WeNUzuambt7IZufwQkceSAXjZ34vPXqmDvVXhrqIkhBDmpjZ1hy1bttChQ+55fdu3b8+WLVsKJSjxjMlI0Q++2jXrbplHzQIl4MMXbtBx+lYijyWjsVDzSWhtvn29niRgIUSxZPJvtrS0NDSa3BMglCpVipSUlEIJSjxjjv8Pjq6E2HVQtyvYuZnchKIo/LrrHJ/8dZwsrY4KrrZ836M+tcs5PYGAhRCiaDD5TLhOnTosWbIkV/nixYupWbNmoQQlnjH13oDAgRC2ukAJODUjm8GLDjL+z6NkaXUE1/Lgf0OaSgIWQhR7Jp8Jjxs3jldeeYXTp0/TqpV+sv2oqCgWLlzI8uXLCz1AUQRlpcOmz6H5SLB20t8Hbv95gZo6djGFQQsPEHclHUu1ijEdatDn+YpGK3UJIURxZXISDgkJYdWqVXz22WcsX74cGxsb/P392bBhA66uhbcAuyiiLsfC0jC4fBxuxOuf/S0ARVFYuu884/88SmaODi8na2b0qE99mXhDCFGCmHw5GqBjx45s376d9PR0zpw5Q9euXRk5ciT+/v4mtzVz5kwqVqyItbU1gYGB7Nmz56H1p02bRrVq1bCxscHb25t3332XjIyMgnwNYarDS2HOC/oEbO8BjfsVqJlbWTm8t+wQo/84QmaOjhequRMxtJkkYCFEiVPgIadbtmzhxx9/5I8//sDLy4tXXnmFmTNnmtTGkiVLGDFiBLNnzyYwMJBp06YRHBxMbGwsZcqUyVV/4cKFfPDBB/z00080adKEf//9l169eqFSqZg6dWpBv4p4lOwMWDca9i/Qf/ZtAV3mgX3uf6NHOXUplYG/HeDkpTTUKhgZXI0BzSvLnM9CiBLJpCSclJTEggUL+PHHH0lJSaFr165kZmayatWqAg3Kmjp1Kv369aN3794AzJ49m4iICH766Sc++OCDXPV37NjB888/zxtvvAFAxYoV6d69O7t37zb52CKfrp6GZWGQdARQQYtR0GK0fkIOE606mMCHK49wK0tLGQcrvusewHOVZNEPIUTJle/L0SEhIVSrVo3Dhw8zbdo0Ll68yPTp0wt84KysLPbv30+bNm3uBqNW06ZNG3bu3JnnPk2aNGH//v2GS9ZnzpxhzZo1eT63LArBsT9hTkt9ArYtDW/+AS98aHICzsjWMmbFEYYvieZWlpbnq5QmYmgzScBCiBIv32fCa9euZejQoQwcOLBQpqu8cuUKWq0WDw8Po3IPDw9OnDiR5z5vvPEGV65coWnTpiiKQk5ODgMGDODDDz984HEyMzPJzMw0fE5NTX3s2Iu9nCyIHA+7/5t8o0IQvPoTOHqZ3NTZK+m88/sBjiWmoFLB0FZ+DG3th4VcfhZCiPyfCW/bto3U1FQaNGhAYGAgM2bM4MqVK08ytlw2bdrEZ599xvfff8+BAwdYsWIFERERfPzxxw/cJzw8HCcnJ8NLnmV+hBvxML/d3QT8/DAI+1+BEvDaI4m8NH0bxxJTKG2n4Zc+jXm3bVVJwEII8R+VotyZ9Dd/0tPTWbJkCT/99BN79uxBq9UydepU+vTpg4ND/lfJycrKwtbWluXLlxMaGmooDwsL48aNG/z555+59mnWrBnPPfccX375paHst99+o3///qSlpaFW5/6b4v4z4YSEBGrWrMn58+cpX758vuMtMZa8BcdXg7UzdJ4N1dqb3ERWjo7wtceZv/0sAI0qujC9e33KOlkXbqxCCFEEXbhwAW9v73zlGZMfUbKzs6NPnz5s27aNI0eO8N577/H5559TpkwZXn755Xy3o9FoaNCgAVFRUYYynU5HVFQUQUFBee5z69atXInWwkJ/f/JBf0tYWVnh6OhoeJnyh0KJ1OErqNYB/m9LgRLwheu3eO2HnYYEPKBFZRb1e04SsBBC5KFAzwnfUa1aNaZMmcKFCxdYtGiRyfuPGDGCuXPn8vPPP3P8+HEGDhxIenq6YbR0z549GTNmjKF+SEgIs2bNYvHixcTFxREZGcm4ceMICQkxJGNhopRE2P3D3c8OHtB9EbiYvj501PFkOn63jUPnb+BkU4ofwxryQfvqWFo81o+ZEEIUW4WyNI2FhQWhoaFGl5Xzo1u3bly+fJnx48eTlJREvXr1WLdunWGwVnx8vNGZ79ixY1GpVIwdO5aEhATc3d0JCQnh008/LYyvUfJk3IQfmkP6Jf3o5zqvFqiZHK2OL/+O5YfNZwDw93Zm5hsBlHexLcxohRCi2DH5nvCzzpRr9SVC1Mfw73r99JOlK5u8e9LNDIYuOsies9cA6P18Rca0r4HGUs5+hRAlkyl5RhZpLWnSLkNOBjh76z+3HKNfiKGUjclNbT15meGLo7manoW9lSVTXq1LhzqehRywEEIUX5KES5Kz22F5H3AoC33/BksrsLDUv0yg1Sl8G3WS6RtOoihQ09OR73vUp6Kb3RMKXAghiidJwiWBTgc7vtVfela0+uUH0y+Dk+mX4y+nZjJ8yUG2n7oKQPfGFZgQUhPrUjIwTgghTCVJuLi7dQ1W/h+c/Fv/ue7r8NJU0Jh+1rr7zFWGLDrIpdRMbDUWfNa5DqEB5Qo5YCGEKDkkCRdn5/fCsl6QcgEsraH9FKjfE1SmzVil0ynM3nKar9bHolPAr4w9s96sT5Uy8sy1EEI8DknCxZGiwK5ZEDkOdDngWgm6/gJl65jc1PX0LEYsjWZj7GUAXgkoxyeda2OrkR8dIYR4XPKbtLi5fQP+HAQn/tJ/rhkKL08Ha0eTmzoQf53Bvx/g4s0MrCzVTO5Ui64NvVGZeCYthBAib5KEi5OL0fq1f6+fBXUpCP4MGvcz+fKzoij8tP0s4WuOk6NT8HWzY+Yb9anpZXoiF0II8WCShIuLuK3wWxfQZoJTBei6AMo1MLmZm7ezGbX8EOuPJgPQsY4nn3epg4N1qUIOWAghhCTh4qJ8Q3DzAydvCP0ebF1NbiIm4Sbv/H6A+Gu3KGWhYtxLNXnrOR+5/CyEEE+IJOFn2bUz4FwR1Gr9jFdh/wMblwJdfv59dzyT/3eMLK2O8i42zHyjPv7ezk8kbCGEEHoywe+z6tAS+L4JbP36bpmtq8kJOC0zh2GLoxm7KoYsrY42NTyIGNJMErAQQjwFcib8rNLlQM5tOL9bPyOW2vS/p04kpfDO7wc4czkdC7WKD9pV5+1mvnL5WQghnhJJws8SnRbU/00PGdBDf+m5anCBEvCyfecZ92cMGdk6yjpaM+ONABpWNP0+shBCiIKTy9HPipg/4PsgSL96t6x6h7tJOZ9uZ2l5f9kh3l9+mIxsHc2ruhMxtKkkYCGEMAM5Ey7qcjJh/Yewd57+866Z0Hp8gZo6fTmNQb8f4ERSKmoVjGhblXdaVkGtlsvPQghhDpKEi7Jrcfq5nxOj9Z+bjdSv/1sAqw9dZMwfh0nP0uJmb8V33evRpLJboYUqhBDCdJKEi6rjf8GqdyDzJti4witzwK+tyc1kZGv5JOIYv+2KB+C5Sq581z2AMg7WhR2xEEIIE0kSLmq02fDPRNg5Q/+5fGN4bX6B1v6Nv3qLdxbuJyYhBYAhraowrLUflhYyFEAIIYoCScJFyc0LsKw3XNij/xw0GNpMBAvTp4xcfzSJkcsOkZqRg4ttKb7pVo+W1coUbrxCCCEeiyThouJkJKzoD7evgZWTfurJGi+Z3Ey2VscXa08wb1scAA18XJjePQAvZ5vCjlgIIcRjkiRsbjotbPz07sxXnvXgtQXg6mtyUwk3bjN44QEOxt8AoF8zX0a1q04pufwshBBFkiRhs1NB8lH920Zv65cftLQyuZWNsZd4d0k0N25l42htyVev+fNirbKFHKsQQojCJEnYXBRFP8+zWg2hs+DsVqjZyeRmcrQ6vvnnX2ZuPA1A3fJOzHyjPt6utoUdsRBCiEImSfhp0+n0l56vn4VOM/SJ2Na1QAn4UkoGQxYdZHfcNQB6BvnwUccaWFmaNouWEEII85Ak/LQlH4FNn4Gig3rdoWLTAjWz49QVhi4+yJW0LOw0FnzepS4h/l6FHKwQQognSZLw0+bpD20/1i++UIAErNMpzNh4im/++RdFgeplHfi+R30quds/gWCFEEI8SZKEnzRFgZ0zwe9FcK+qL2syuEBNXU3LZPiSaLaevAJAt4beTOpUC+tScvlZCCGeRZKEn6Tb12HlQPh3LRz8DfpvglIFmy5y79lrDFl4kKSUDKxLqfkktA6vNjB9Fi0hhBBFhyThJyVhv37xhRvxYKGBwP4FevRIp1OYu/UMU9bHotUpVHa34/seDahW1qHwYxZCCPFUSRIubIoCe+bqlx/UZYNLRXjtZ/CqZ3JTN25lMXLZIf45fgmATvW8+KxzHeys5J9NCCGKA/ltXpgyUmD1EDi2Sv+5Rgh0mgnWTiY3FX3+BoN+P0DCjdtoLNVMDKlF98beqFSy9q8QQhQXkoQLS9IRWBoG106D2hJe/AQCB+ifAzaBoij8vOMsn645TrZWwae0LTPfqE/tcqYnciGEEEWbJOHHpShw4BdYOwpyMsCxvH7uZ+9GJjeVkpHNB38cZs2RJADa1y7LF6/WxdHa9FWUhBBCFH2ShB9HVjr8NQIOL9Z/9nsROv+gnwHLREcv3mTQ7wc4e/UWpSxUfNihBr2aVJTLz0IIUYxJEn4cu2frE7DKAlqPgybD9HNBm0BRFBbvPc+E1UfJytFRztmGGW8EEFDB5QkFLYQQoqiQJPw4goZAwgF47h2o+LzJu6dn5jB2VQwrDyYA0Kp6GaZ29cfZVlPYkQohhCiCJAk/DksNvP57gXY9mZzKwN8PcOpSGhZqFe8HV6N/s0qo1XL5WQghSgpJwmaw4sAFPloZw+1sLR6OVkzvXp/GvqbfRxZCCPFskyT8FGVka5n0v6Ms2nMegKZV3Jj2ej3c7E2fSUsIIcSzT5LwUxJ3JZ13fj/A8cQUVCoY1tqPIa38sJDLz0IIUWJJEn4KIg4nMvqPw6Rl5lDaTsO3rwfQ1M/N3GEJIYQwM0nCT1BmjpbPIo7z885zADT2dWV69wA8HAu2kpIQQojiRZLwE3L+2i0GLzzAoQs3ARjYsjLvta2KpYVpzxELIYQoviQJPwGRx5J5b2k0KRk5ONmU4ptu/rSq7mHusIQQQhQxkoQLUbZWx1frY/lhyxkA6nk7M+ONAMq72Jo5MiGEEEVRkbg2OnPmTCpWrIi1tTWBgYHs2bPngXVbtmyJSqXK9erYseNTjDi3xJu36T5nlyEB93nel6X/FyQJWAghxAOZ/Ux4yZIljBgxgtmzZxMYGMi0adMIDg4mNjaWMmXK5Kq/YsUKsrKyDJ+vXr2Kv78/r7322tMM28iWfy8zfEk019KzcLCy5MvX6tKutqfZ4hFCCPFsMPuZ8NSpU+nXrx+9e/emZs2azJ49G1tbW3766ac867u6ulK2bFnDKzIyEltbW7MkYa1OYerfsYTN38O19CxqeTny19CmkoCFEELki1nPhLOysti/fz9jxowxlKnVatq0acPOnTvz1caPP/7I66+/jp2dXZ7bMzMzyczMNHxOTU19vKD/cyk1g2GLotl55ioAPQIrMO6lmliXsiiU9oUQQhR/Zj0TvnLlClqtFg8P45HDHh4eJCUlPXL/PXv2EBMTw9tvv/3AOuHh4Tg5ORleNWvWfOy4Ac5fu83es9ew1Vjw7ev1+LRzHUnAQgghTGL2y9GP48cff6ROnTo0btz4gXXGjBnDzZs3Da9jx44VyrEb+Lgw5dW6rB7clE71yhVKm0IIIUoWs16OdnNzw8LCguTkZKPy5ORkypYt+9B909PTWbx4MZMnT35oPSsrK6ys7i6QkJKSUvCA7/NK/fKF1pYQQoiSx6xnwhqNhgYNGhAVFWUo0+l0REVFERQU9NB9ly1bRmZmJm+++eaTDlMIIYR4Isz+iNKIESMICwujYcOGNG7cmGnTppGenk7v3r0B6NmzJ+XKlSM8PNxovx9//JHQ0FBKly5tjrCFEEKIx2b2JNytWzcuX77M+PHjSUpKol69eqxbt84wWCs+Ph612viEPTY2lm3btvH333+bI2QhhBCiUKgURVHMHcTTdOHCBby9vTl//jzly8s9XSGEEIXLlDzzTI+OFkIIIZ5lZr8c/bTpdDoAEhMTzRyJEEKI4uhOfrmTbx6mxCXhO49DPezZYiGEEOJxJScnU6FChYfWKXH3hHNycjh48CAeHh65BnyZKjU1lZo1a3Ls2DEcHBwKKcLiR/op/6Sv8k/6Kn+kn/KvsPpKp9ORnJxMQEAAlpYPP9ctcUm4MKWkpODk5MTNmzdxdHQ0dzhFlvRT/klf5Z/0Vf5IP+WfOfpKBmYJIYQQZiJJWAghhDATScKPwcrKigkTJhjNTS1yk37KP+mr/JO+yh/pp/wzR1/JPWEhhBDCTORMWAghhDATScJCCCGEmUgSFkIIIcxEknABzZw5k4oVK2JtbU1gYCB79uwxd0hF0pYtWwgJCcHLywuVSsWqVavMHVKRFB4eTqNGjXBwcKBMmTKEhoYSGxtr7rCKnFmzZlG3bl0cHR1xdHQkKCiItWvXmjusIu/zzz9HpVIxfPhwc4dS5EycOBGVSmX0ql69+lM7viThAliyZAkjRoxgwoQJHDhwAH9/f4KDg7l06ZK5Qyty0tPT8ff3Z+bMmeYOpUjbvHkzgwYNYteuXURGRpKdnc2LL75Ienq6uUMrUsqXL8/nn3/O/v372bdvH61ataJTp04cPXrU3KEVWXv37uWHH36gbt265g6lyKpVqxaJiYmG17Zt257ewRVhssaNGyuDBg0yfNZqtYqXl5cSHh5uxqiKPkBZuXKlucN4Jly6dEkBlM2bN5s7lCLPxcVFmTdvnrnDKJJSU1MVPz8/JTIyUmnRooUybNgwc4dU5EyYMEHx9/c32/HlTNhEWVlZ7N+/nzZt2hjK1Go1bdq0YefOnWaMTBQnN2/eBMDV1dXMkRRdWq2WxYsXk56eTlBQkLnDKZIGDRpEx44djX5fidxOnjyJl5cXlSpVokePHsTHxz+1Y5e4VZQe15UrV9BqtXh4eBiVe3h4cOLECTNFJYoTnU7H8OHDef7556ldu7a5wylyjhw5QlBQEBkZGdjb27Ny5Upq1qxp7rCKnMWLF3PgwAH27t1r7lCKtMDAQBYsWEC1atVITExk0qRJNGvWjJiYmKey4IUkYSGKmEGDBhETE/N070s9Q6pVq0Z0dDQ3b95k+fLlhIWFsXnzZknE9zh//jzDhg0jMjISa2trc4dTpLVv397wvm7dugQGBuLj48PSpUvp27fvEz++JGETubm5YWFhYViX+I7k5GTKli1rpqhEcTF48GD++usvtmzZQvny5c0dTpGk0WioUqUKAA0aNGDv3r18++23/PDDD2aOrOjYv38/ly5don79+oYyrVbLli1bmDFjBpmZmVhYWJgxwqLL2dmZqlWrcurUqadyPLknbCKNRkODBg2IiooylOl0OqKiouS+lCgwRVEYPHgwK1euZMOGDfj6+po7pGeGTqcjMzPT3GEUKa1bt+bIkSNER0cbXg0bNqRHjx5ER0dLAn6ItLQ0Tp8+jaen51M5npwJF8CIESMICwujYcOGNG7cmGnTppGenk7v3r3NHVqRk5aWZvQXZVxcHNHR0bi6ulKhQgUzRla0DBo0iIULF/Lnn3/i4OBAUlISAE5OTtjY2Jg5uqJjzJgxtG/fngoVKpCamsrChQvZtGkT69evN3doRYqDg0Ou8QR2dnaULl1axhncZ+TIkYSEhODj48PFixeZMGECFhYWdO/e/akcX5JwAXTr1o3Lly8zfvx4kpKSqFevHuvWrcs1WEvAvn37eOGFFwyfR4wYAUBYWBgLFiwwU1RFz6xZswBo2bKlUfn8+fPp1avX0w+oiLp06RI9e/YkMTERJycn6taty/r162nbtq25QxPPqAsXLtC9e3euXr2Ku7s7TZs2ZdeuXbi7uz+V48sqSkIIIYSZyD1hIYQQwkwkCQshhBBmIklYCCGEMBNJwkIIIYSZSBIWQgghzESSsBBCCGEmkoSFEEIIM5EkLIQQQpiJJGEhRKFRqVSsWrXK3GEI8cyQJCxEMdGrVy9UKlWuV7t27cwdmhDiAWTuaCGKkXbt2jF//nyjMisrKzNFI4R4FDkTFqIYsbKyomzZskYvFxcXQH+peNasWbRv3x4bGxsqVarE8uXLjfY/cuQIrVq1wsbGhtKlS9O/f3/S0tKM6vz000/UqlULKysrPD09GTx4sNH2K1eu0LlzZ2xtbfHz82P16tWGbdevX6dHjx64u7tjY2ODn59frj8ahChJJAkLUYKMGzeOLl26cOjQIXr06MHrr7/O8ePHAUhPTyc4OBgXFxf27t3LsmXL+Oeff4yS7KxZsxg0aBD9+/fnyJEjrF69mipVqhgdY9KkSXTt2pXDhw/ToUMHevTowbVr1wzHP3bsGGvXruX48ePMmjULNze3p9cBQhQ1ihCiWAgLC1MsLCwUOzs7o9enn36qKIqiAMqAAQOM9gkMDFQGDhyoKIqizJkzR3FxcVHS0tIM2yMiIhS1Wq0kJSUpiqIoXl5eykcfffTAGABl7Nixhs9paWkKoKxdu1ZRFEUJCQlRevfuXThfWIhiQO4JC1GMvPDCC4a1ie9wdXU1vA8KCjLaFhQURHR0NADHjx/H398fOzs7w/bnn38enU5HbGwsKpWKixcv0rp164fGULduXcN7Ozs7HB0duXTpEgADBw6kS5cuHDhwgBdffJHQ0FCaNGlSoO8qRHEgSViIYsTOzi7X5eHCYmNjk696pUqVMvqsUqnQ6XQAtG/fnnPnzrFmzRoiIyNp3bo1gwYN4quvvir0eIV4Fsg9YSFKkF27duX6XKNGDQBq1KjBoUOHSE9PN2zfvn07arWaatWq4eDgQMWKFYmKinqsGNzd3QkLC+O3335j2rRpzJkz57HaE+JZJmfCQhQjmZmZJCUlGZVZWloaBj8tW7aMhg0b0rRpU37//Xf27NnDjz/+CECPHj2YMGECYWFhTJw4kcuXLzNkyBDeeustPDw8AJg4cSIDBgygTJkytG/fntTUVLZv386QIUPyFd/48eNp0KABtWrVIjMzk7/++svwR4AQJZEkYSGKkXXr1uHp6WlUVq1aNU6cOAHoRy4vXryYd955B09PTxYtWkTNmjUBsLW1Zf369QwbNoxGjRpha2tLly5dmDp1qqGtsLAwMjIy+Oabbxg5ciRubm68+uqr+Y5Po9EwZswYzp49i42NDc2aNWPx4sWF8M2FeDapFEVRzB2EEOLJU6lUrFy5ktDQUHOHIoT4j9wTFkIIIcxEkrAQQghhJnJPWIgSQu48CVH0yJmwEEIIYSaShIUQQggzkSQshBBCmIkkYSGEEMJMJAkLIYQQZiJJWAghhDATScJCCCGEmUgSFkIIIcxEkrAQQghhJv8PprMItsj3ae0AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_accs))\n",
        "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_accs))\n",
        "\n",
        "plot_values(epochs_tensor, examples_seen_tensor, train_accs, val_accs, label=\"accuracy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90aba699-21bc-42de-a69c-99f370bb0363",
      "metadata": {
        "id": "90aba699-21bc-42de-a69c-99f370bb0363"
      },
      "source": [
        "- 위의 정확도 그래프를 기반으로 에포크 4와 5 이후 모델이 비교적 높은 훈련 및 검증 정확도를 달성했음을 알 수 있습니다.\n",
        "- 하지만 이전에 훈련 함수에서 `eval_iter=5`를 지정했던 것을 기억해야 합니다. 이는 훈련 및 검증 세트의 일부만 사용해 성능을 추정했음을 의미합니다.\n",
        "- 아래와 같이 전체 데이터셋에 대한 훈련, 검증 및 테스트 세트 성능을 계산할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "UHWaJFrjY0zW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHWaJFrjY0zW",
        "outputId": "736bc493-b456-4226-d6c1-61f3aad2637d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 정확도: 97.21%\n",
            "검증 정확도: 97.32%\n",
            "테스트 정확도: 95.67%\n"
          ]
        }
      ],
      "source": [
        "train_accuracy = calc_accuracy_loader(train_loader, model, device)\n",
        "val_accuracy = calc_accuracy_loader(val_loader, model, device)\n",
        "test_accuracy = calc_accuracy_loader(test_loader, model, device)\n",
        "\n",
        "print(f\"훈련 정확도: {train_accuracy*100:.2f}%\")\n",
        "print(f\"검증 정확도: {val_accuracy*100:.2f}%\")\n",
        "print(f\"테스트 정확도: {test_accuracy*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6882649f-dc7b-401f-84d2-024ff79c74a1",
      "metadata": {
        "id": "6882649f-dc7b-401f-84d2-024ff79c74a1"
      },
      "source": [
        "- 훈련 세트와 검증 세트의 성능이 거의 동일한 것을 확인할 수 있습니다.\n",
        "- 그러나 테스트 세트 성능이 약간 낮은 것을 보면 모델이 훈련 데이터에 대해 아주 작은 정도로 과적합되었음을 알 수 있으며, 학습률과 같은 일부 하이퍼파라미터를 조정하는 데 사용된 검증 데이터에도 과적합되었음을 알 수 있습니다.\n",
        "- 하지만 이는 정상적인 현상이며, 모델의 드롭아웃 비율(`drop_rate`)이나 옵티마이저 설정의 `weight_decay`를 높여 이러한 차이를 줄일 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0",
      "metadata": {
        "id": "a74d9ad7-3ec1-450e-8c9f-4fc46d3d5bb0"
      },
      "source": [
        "## 6.8 LLM을 스팸 분류기로 사용하기\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72ebcfa2-479e-408b-9cf0-7421f6144855",
      "metadata": {
        "id": "72ebcfa2-479e-408b-9cf0-7421f6144855"
      },
      "source": [
        "<img src=\"https://sebastianraschka.com/images/LLMs-from-scratch-images/ch06_compressed/18.webp\" width=700px>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31",
      "metadata": {
        "id": "fd5408e6-83e4-4e5a-8503-c2fba6073f31"
      },
      "source": [
        "- 마지막으로, 미세 튜닝된 GPT 모델을 실제로 사용해 보겠습니다.\n",
        "- 아래 `classify_review` 함수는 이전에 구현한 `SpamDataset`과 유사한 데이터 전처리 단계를 구현합니다.\n",
        "- 그런 다음, 이 함수는 모델에서 예측된 정수 클래스 레이블을 반환하고 해당 클래스 이름을 반환합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "aHdn6xvL-IW5",
      "metadata": {
        "id": "aHdn6xvL-IW5"
      },
      "outputs": [],
      "source": [
        "def classify_review(text, model, tokenizer, device, max_length=None, pad_token_id=50256):\n",
        "    model.eval()\n",
        "\n",
        "    # 모델에 대한 입력 준비\n",
        "    input_ids = tokenizer.encode(text)\n",
        "    supported_context_length = model.pos_emb.weight.shape[0]\n",
        "\n",
        "    # 너무 긴 시퀀스 자르기\n",
        "    input_ids = input_ids[:min(max_length, supported_context_length)]\n",
        "    assert max_length is not None, (\n",
        "        \"max_length가 지정되지 않았습니다. 모델의 최대 문맥 길이를 사용하려면\"\n",
        "        \"max_length=model.pos_emb.weight.shape[0]로 지정하세요.\"\n",
        "    )\n",
        "    assert max_length <= supported_context_length, (\n",
        "        f\"max_length({max_length})가 모델이 지원하는 문맥 길이({supported_context_length})를 초과했습니다.\"\n",
        "    )\n",
        "    # 또는 max_length=None인 경우를 안정적으로 처리하는 방법은 다음과 같습니다.\n",
        "    # max_len = min(max_length, supported_context_length) if max_length else supported_context_length\n",
        "    # input_ids = input_ids[:max_len]\n",
        "\n",
        "    # 가장 긴 시퀀스로 패딩하기\n",
        "    input_ids += [pad_token_id] * (max_length - len(input_ids))\n",
        "    input_tensor = torch.tensor(input_ids, device=device).unsqueeze(0) # 배치 차원 추가\n",
        "\n",
        "    # 모델 추론\n",
        "    with torch.no_grad():\n",
        "        logits = model(input_tensor)[:, -1, :]  # 마지막 출력 토큰의 로짓\n",
        "    predicted_label = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "    # 분류 결과 반환\n",
        "    return \"스팸\" if predicted_label == 1 else \"스팸아님\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c",
      "metadata": {
        "id": "f29682d8-a899-4d9b-b973-f8d5ec68172c"
      },
      "source": [
        "- 몇 개의 샘플로 시험해 보겠습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "apU_pf51AWSV",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apU_pf51AWSV",
        "outputId": "959959cb-5f2a-4816-82b7-f47b58302c1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스팸\n"
          ]
        }
      ],
      "source": [
        "text_1 = (\n",
        "    \"You are a winner you have been specially\"\n",
        "    \" selected to receive $1000 cash or a $2000 award.\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "1g5VTOo_Ajs5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g5VTOo_Ajs5",
        "outputId": "b1ebfdea-e8a2-4d43-fd32-482c55817eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "스팸아님\n"
          ]
        }
      ],
      "source": [
        "text_2 = (\n",
        "    \"Hey, just wanted to check if we're still on\"\n",
        "    \" for dinner tonight? Let me know!\"\n",
        ")\n",
        "\n",
        "print(classify_review(\n",
        "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
        "))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e",
      "metadata": {
        "id": "bf736e39-0d47-40c1-8d18-1f716cf7a81e"
      },
      "source": [
        "- 마지막으로, 나중에 다시 훈련하지 않고 모델을 재사용할 수 있도록 모델을 저장합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "mYnX-gI1CfQY",
      "metadata": {
        "id": "mYnX-gI1CfQY"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), \"review_classifier.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6",
      "metadata": {
        "id": "ba78cf7c-6b80-4f71-a50e-3ccc73839af6"
      },
      "source": [
        "- 그런 다음 새 세션에서 다음과 같이 모델을 로드할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc4e68a5-d492-493b-87ef-45c475f353f5",
        "outputId": "61cc88cb-1da2-4ca0-a567-09b30a5c6cf2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "model_state_dict = torch.load(\"review_classifier.pth\", map_location=device, weights_only=True)\n",
        "model.load_state_dict(model_state_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4",
      "metadata": {
        "id": "5b70ac71-234f-4eeb-b33d-c62726d50cd4"
      },
      "source": [
        "## 요약\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e",
      "metadata": {
        "id": "dafdc910-d616-47ab-aa85-f90c6e7ed80e"
      },
      "source": [
        "- 연습 문제 풀이는 [./exercise-solutions.ipynb](./exercise-solutions.ipynb)에서 찾을 수 있습니다.\n",
        "- 또한 관심 있는 독자는 [부록 E](../../appendix-E)에서 LoRA를 사용한 파라미터 효율적인 훈련에 대한 소개를 찾을 수 있습니다.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}